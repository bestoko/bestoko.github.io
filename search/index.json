[{"content":"netstat 查看网络状态\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@tianyun ~]# netstat -tnlp # 查看正在监听的，且使用tcp协议的进程 -t tcp协议 -u udp协议 -l listen -p 进程信息 PID/Program name -n 不反解，不将IP地址解析为主机名，不将端口号解析成协议名（80 ---\u0026gt; http） [root@localhost ~]# netstat -an |grep :22 [root@localhost ~]# netstat -an |grep :80 [root@localhost ~]# lsof -i:22 -a 显示所有连接（包括监听和非监听） 常用组合 netstat -tunalp proc 文件系统\rtop命令统计的cpu状态信息就是从/proc/stat中取，系统所有进程的运行状态都在/proc下\n文件/目录 说明 /proc/cpuinfo CPU 详细信息（型号、核心数、频率、缓存等） /proc/meminfo 内存使用情况（总内存、空闲内存、缓存、Swap 等） /proc/version 内核版本和 GCC 编译版本 /proc/loadavg 系统负载（1/5/15 分钟的平均负载，运行中的进程数/总进程数） /proc/filesystems 当前内核支持的文件系统类型（如 ext4、xfs、proc 等） /proc/mounts 当前挂载的文件系统（等效于 mount 命令输出） /proc/diskstats 磁盘 I/O 统计信息（读写次数、扇区数等） /proc/net/ 网络相关数据（如 net/tcp、net/udp、net/route 等） /proc/sys/ 内核运行时参数（可通过 sysctl 修改，如 vm.swappiness） /proc/interrupts 中断请求（IRQ）分配情况 /proc/ioports 当前使用的 I/O 端口范围 /proc/modules 已加载的内核模块（等效于 lsmod 命令） /proc/stat 系统综合统计（CPU 使用率、上下文切换次数、启动时间等） /proc/uptime 系统运行时间（单位：秒）和空闲时间 /proc/devices 已注册的字符设备和块设备列表 /proc/cmdline 内核启动时传递的参数 /proc/swaps Swap 分区使用情况 /proc/partitions 磁盘分区信息（主设备号、次设备号、块数等） 1 2 3 4 5 6 7 8 9 需要注意当卸载/proc后 umount /proc -l # 下述命令都不可用 free -m uptime lscpu top 进程间通信 管道\r管道操作符号 “|” ，主要用来连接左右两个命令, 将左侧的命令的标准输出, 交给右侧命令的标准输入\nPS: 无法传递标准错误输出至后者命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 统计当前/etc/passwd中用户使用的shell类型 awk -F: \u0026#39;{print $7}\u0026#39; /etc/passwd | sort |uniq -c # 统计网站的访问情况 netstat -an |grep :80 |awk -F\u0026#34;:\u0026#34; \u0026#39;{print $8}\u0026#39;|sort |uniq -c # 打印当前所有IP ip addr |grep \u0026#39;inet \u0026#39; |awk \u0026#39;{print $2}\u0026#39; |awk -F\u0026#34;/\u0026#34; \u0026#39;{print $1}\u0026#39; # 打印根分区已用空间的百分比（仅打印数字） df -P|grep \u0026#39;/$\u0026#39; |awk \u0026#39;{print $5}\u0026#39;|awk -F\u0026#34;%\u0026#34; \u0026#39;{print $1}\u0026#39; # 统计网站的访问最多的ip top 10 awk \u0026#39;{print $1}\u0026#39; access.log |sort |uniq -c |sort -rn|head -n 10 管道中的tee技术\rtee -a # 追加 重定向与 tee 在使用过程中有什么区别\n1 2 3 date \u0026gt; date.txt # 直接将内容写入date.txt文件中 date |tee date.txt # 命令执行会输出至屏幕，但会同时保存一份至date.txt文件中 xargs 参数传递\r主要让一些不支持管道的命令可以使用管道技术\n1 2 3 4 5 6 7 which cat|xargs ls -l ls |xargs rm -fv ls |xargs cp -rvt /tmp/ -或-\u0026gt; ls | xargs -I {} cp -rv {} /tmp/ ls |xargs mv -t /tmp/ -或-\u0026gt; ls | xargs -I {} mv {} /tmp 网卡\r网卡名字\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #1、传统命名 CentOS6之前采用的都是传统的命名方式，如以太网：eth1，eth0.... #2、可预知的命名方案 Centos7提供了不同的命名规则，默认是基于固件、拓扑、位置信息来分配。这样做的优点是命名是全自动的、可预知的，缺点是比eth0更难读。比如ens33 可预知的命名方案例如： ①如果Fireware或BIOS为主板上集成的设备提供索引信息可用，则根据此索引进行命名，如：eno1, eno2, ... ②如果Fireware或BIOS为PCI-E扩展槽所提供的索引信息可用，且可预测，则根据此索引进行命名，如ens1, ens2, ... ③如果硬件接口的物理位置信息可用，则根据此信息命名，如enp2s0, ... ④如果用户显示定义，也可根据MAC地址命名，例如：enx122161ab212 #上述均不可用时，则仍使用传统方式命名； 可预知的命名方案，如本机网卡名为ens33，命名格式的组成如下： en：ethernet wl：wlan #无线局域网 ww：wwan #无线广域网 名称类型： o\u0026lt;index\u0026gt; #集成设备的设备索引号； s\u0026lt;slot\u0026gt; #扩展槽对的索引号； x\u0026lt;MAC\u0026gt; #基于MAC地址的命名； p\u0026lt;bus\u0026gt;s\u0026lt;slot\u0026gt; #基于总线及槽的拓扑结构进行命名； 基本网络配置\r查看网卡信息\r1 2 3 4 5 6 7 8 9 10 # 查看当前系统所连接的所有以太网卡 [root@localhost ~]# lspci |grep -i ethernet # 确认网线已经连接好，以eth0 为例 [root@localhost ~]# mii-tool eth0 # 该命令需要安装有net-tools才能用 eth0:negotiated 1000baseT-FD flow-control,link ok # link ok网卡能够被识别，并且接了有效的网线 [root@localhost ~]# mii-tool eth1 SIOCGMIIPHY on \u0026#39;eth1\u0026#39; failed: Invalid argument 网卡虽然能够被识别（网卡已经被驱动了，但不能用：网卡配置错误，网线没接等） ifconfig 命令\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 1、ifconfig -a 查看所有网卡信息(包括未激活的网卡) 2、ifconfig eth0 查看单个网卡信息 3、ifconfig eth0 192.168.1.122 netmask 255.255.255.0 临时设定IP和掩码（重启服务或者系统都失效） 4、ifconfig eth0 192.168.1.122/24 5、ifconfig eth0:1 192.168.0.2 netmask 255.255.255.0 配置子接口 # 删除：下述两种方式都可以 ifconfig eth0:0 down ifconfig eth0:1 del 192.168.0.2 # 删除，不必加掩码 6、开启与关闭 ifconfig eth0 down|up # 不加载网卡配置文件 ifdown eth0 |ifup eth0 # 加载网卡配置文件-centos7.9带 7、设置网卡最大传输单元 ifconfig eth0 mtu 1500 8、开启关闭模式(了解) 网卡的繁杂模式（Promiscuous mode）和多播（Multicast）是网络通信中两种非常重要的概念。 1.网卡的繁杂模式：在默认情况下，网卡只会接收发给自己MAC地址的数据帧，其它的数据帧则会被过滤丢弃。 但是当我们把网卡设置为繁杂模式时，网卡将接收通过该网卡的所有数据帧， 无论这些数据帧的目标MAC地址是什么。这个特性在一些特定的情况下很有用， 例如网络监听（sniffing）和网络调试。 2.多播：多播是一种网络传输技术，它允许一个网络节点将数据发送到多个接收节点， 但又不像广播那样向所有网络节点发送。多播通过使用特定的IP地址范围（224.0.0.0到239.255.255.255）和 MAC地址范围，来标示一组特定的接收节点。当发送节点发送数据时， 只有加入了相应多播组的节点会接收和处理这份数据，其它未加入的节点则会忽略这份数据。 多播技术可有效减少网络流量，提升网络的利用效率，因此在一些需要数据共享的场景， 例如视频直播和在线游戏，多播技术得到了广泛的应用。 ifconfig eth0 promisc # 开启繁杂模式 ifconfig eth0 -promisc # 关闭繁杂模式 ifconfig ens33 multicast # 开启多播 ifconfig ens33 -multicast # 关闭多播 这条命令将网络设备ens33配置为接收多播流。这意味着，如果多播流被发送到与ens33关联的多播IP地址， 只要设备在这个多播组中，那么ens33就能接收到这个多播流。 ifconfig eth0 allmulti # 开启 ifconfig eth0 -allmulti # 关闭 条命令启用了网络设备eth0上的全多播模式。全多播模式是指，网络设备接收所有来自网络的多播流， 而不仅仅是它已经订阅的流。这对于一些需要接收所有多播流的特殊应用， 例如路由器或者一些网络调试工具，是非常有用的。 9、添加、删除ipv6地址 ifconfig eth0 add 3ffe:3240:800:1005::2/64 ifconfig eth0 del 3ffe:3240:800:1005::2/64 ifconfg 命令查看到的结果解释\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 [root@localhost ~]# ifconfig ens33 ens33: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 # 从flags可知该接口已启用，支持广播、组播，MTU:1500（最大传输单元）：1500字节 # 其他了解知识： // UP：表示“接口已启用”。 // BROADCAST ：表示“主机支持广播”。 // RUNNING：表示“接口在工作中”。 // MULTICAST：表示“主机支持多播”。 // 可以了解一下繁杂模式：https://www.cnblogs.com/linhaifeng/articles/13949611.html inet 192.168.12.42 netmask 255.255.255.0 broadcast 192.168.12.255 # IPv4地址 子网掩码 广播地址 inet6 fe80::499e:c2c1:f5ed:3900 prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt; # IPv6地址 掩码长度 作用域，link表示仅该接口有效 ether 00:0c:29:86:f8:59 txqueuelen 1000 (Ethernet) #网卡接口的MAC地址 传输队列长度 接口类型为Ethernet RX packets 5708 bytes 1061424 (1.0 MiB) # 表示开机后此接口累积接收的报文个数，总字节数 RX errors 0 dropped 833 overruns 0 frame 0 # 表示开机后此接口累积接收报文错误数，丢弃数，溢出数（由于速度过快而丢失的数据包数），冲突的帧数 TX packets 102 bytes 16768 (16.3 KiB) # 表示开机后此接口累积发送的报文个数，总字节数 TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 # 表示开机后此接口累积发送报文错误数，丢弃数，溢出数（由于速度过快而丢失的数据包数）， # carrier 载荷数(发生carrier错误而丢失的数据包数) # collisions 冲突数 基本网络配置\rcentos 7.9\r使用 network 服务，相关配置文件\n网卡的配置文件\r/etc/sysconfig/network-scripts/ifcfg-ethX\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 打开网卡配置文件，完成静态ip配置，修改完毕后重启网络服务即可：systemctl restart network DEVICE=eth0 \u0026lt;-- 网卡名字 BOOTPROTO=static \u0026lt;---- dhcp 动态获取IP \u0026lt;---- none 根据其他选项决定动态还是静态 \u0026lt;---- static肯定是手工指定IP NM_CONTROLLED=no \u0026lt;---如果NetworkManager服务启用，该网卡配置文件也不受该服务管理 ONBOOT=yes \u0026lt;---- 网络服务启动的时候，yes代表激活状态 ， no 代表禁用 TYPE=Ethernet IPADDR=10.1.1.11 \u0026lt;-- IP 地址 NETMASK=255.255.255.0 \u0026lt;-- 子网掩码 GATEWAY=10.1.1.1 \u0026lt;-- 默认网关 DNS1=10.1.1.1 \u0026lt;-- DNS1 服务器 DNS2=8.8.8.8 \u0026lt;-- DNS2 服务器 HWADDR=14:da:e9:eb:a9:61 \u0026lt;---MAC地址 USERCTL=no \u0026lt;---是否允许普通用户启动或者停止该网卡 IPV6INIT=no \u0026lt;---是否在该网卡上启动IPV6的功能 PEERDNS=yes \u0026lt;---是否允许网卡在启动时向DHCP服务器查询DNS信息， # 设置为yes时，此文件设置的DNS将覆盖/etc/resolv.conf， # 若开启了DHCP，则默认为yes，所以dhcp的dns也会覆盖/etc/resolv.conf dns 配置文件\r/etc/resolv.conf DNS解析文件 1 2 3 [root@localhost ~]# cat /etc/resolv.conf # 设置DNS指向，最多3个 nameserver 8.8.8.8 # 对应网卡配置文件中的配置项DNS1 nameserver 192.168.12.1 # 对应网卡配置文件中的配置项DNS2 /etc/hosts 本地名称解析文件，优先于DNS dns检索优先级\n浏览器DNS缓存-\u0026gt;本地系统DNS缓存-\u0026gt;本地计算机HOSTS文件-\u0026gt;ISP DNS缓存-\u0026gt;递归or迭代搜索 在NetworkManager服务开启的情况下，你在centos7中也可以用nmcli命令，使用该命令修改的就是 /etc/sysconfig/network-scripts下的文件 而在centos9中修改的则是/etc/NetworkManager/system-connections/下的文件\ncentos 9\rcentos9中使用NetworkManager服务，与该服务相关的配置文件 用命令直接设置静态ip，不用改配置文件，非常方便\n1 2 3 4 5 6 7 nmcli con mod ens33 ipv4.addresses \u0026#34;192.168.1.100/24\u0026#34; nmcli con mod ens33 ipv4.gateway \u0026#34;192.168.1.1\u0026#34; nmcli con mod ens33 ipv4.dns \u0026#34;8.8.8.8,8.8.4.4\u0026#34; # 多个dns nmcli con mod ens33 ipv4.method manual nmcli con down ens33 nmcli con up ens33 详细命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 # 1、新增两个块桥接网卡 # 2、查看设备信息，发现刚添加的两块网卡都是disconnected [root@rockylinux ~]# nmcli device DEVICE TYPE STATE CONNECTION ens160 ethernet connected ens160 lo loopback connected (externally) lo ens224 ethernet disconnected -- ens256 ethernet disconnected -- # 3、创建一个名为\u0026#39;ens224\u0026#39;的新以太网连接，该连接对应的网络接口（ifname）也是\u0026#39;ens224\u0026#39;。 [root@rockylinux ~]# nmcli con add type ethernet con-name ens224 ifname ens224 Connection \u0026#39;ens224\u0026#39; （xxxx）successfully added. [root@rockylinux ~]# nmcli device DEVICE TYPE STATE CONNECTION ens160 ethernet connected ens160 ens224 ethernet connected ens224 lo loopback connected (externally) lo ens256 ethernet disconnected -- 另外一个也添加一下：nmcli con add type ethernet con-name ens256 ifname ens256 # 4、上述命令会自动添加配置文件到该目录下 [root@rockylinux ~]# ll /etc/NetworkManager/system-connections total 16 -rw-------. 1 root root 229 Mar 15 18:17 ens160.nmconnection -rw-------. 1 root root 184 Mar 17 15:59 ens224.nmconnection -rw-------. 1 root root 184 Mar 17 16:01 ens256.nmconnection 如果你重复执行上面3中命令则会重复创建带uuid的文件，需要删掉，否则冲突 ens224-85d88cca-2cb2-491d-bc7c-7e216c9128cc.nmconnection 删掉方式请用命令 nmcli con delete connection_name 会删除 connection_name的所有，所以需要重新创建一下，总之以后记住不要重复创建就没这么麻烦啦 # 5、用命令操作ip配置，一边操作，会自动写入对应的配置文件中 cat /etc/NetworkManager/system-connections/ens224.nmconnection # 配置 IPv4 地址 [root@localhost ~]# nmcli connection modify ens224 ipv4.addresses 192.168.11.172/24 # 配置 IPv4网关 [root@localhost ~]# nmcli connection modify ens18 ipv4.gateway 192.168.11.254 # 配置 IPv4 DNS，多个 DNS IP 之间使用双引号 + 空格 [root@localhost ~]# nmcli connection modify ens18 ipv4.dns \u0026#34;114.114.114.114 223.6.6.6\u0026#34; # 设置 DNS 基础搜索，多个域名之间使用双引号 + 空格 [root@localhost ~]# nmcli connection modify ens18 ipv4.dns-search \u0026#34;rockylinux.cn rockylinux.org\u0026#34; ==================================================================================== ipv4.dns和ipv4.dns-search两个选项用于指定DNS相关的配置。 1、ipv4.dns：这个选项用来指定DNS服务器的IP地址。这基本上就是你想让系统使用的DNS解析服务器。 你可以指定一个或多个IP地址，多个IP地址之间用逗号,分隔。 2、ipv4.dns-search：这个选项用来指定搜索域。这在你处于一个大型网络环境（比如公司网络）时特别有用。 搜索域是一种简化DNS解析的方式，它允许你只输入主机名（不包括域部分）来访问同一域中的计算机。 例如，如果你的完全限定域名（FQDN）是mycomputer.mydomain.com，并且你的搜索域设置为mydomain.com， 那么你只需要输入mycomputer就能访问这台计算机。 例如 nmcli con mod con-name ipv4.dns \u0026#34;8.8.8.8,8.8.4.4\u0026#34; nmcli con mod con-name ipv4.dns-search \u0026#34;mydomain.com\u0026#34; 在这个例子中，我们设置了Google的DNS服务器8.8.8.8和8.8.4.4为解析服务器，同时设置搜索域为mydomain.com。这样，当你在浏览器或命令行中输入mycomputer时，系统会自动尝试解析mycomputer.mydomain.com。 ==================================================================================== # 默认获取ip信息的method为auto，即DHCP模式，此处需要改为手动模式，不然会出现网络连接一会正常，一会中断的情况。这一点非常重要 [root@localhost ~]# nmcli connection modify ens18 ipv4.method manual # 重新加载网络配置 如果你上面没有设置为manual，则你执行up也会发现ip不变 [root@localhost ~]# nmcli connection down ens18; nmcli connection up ens18 # 查看接口配置信息 [root@localhost ~]# nmcli device show ens18 # 查看配置文件，如果需要配置多IP，可以修改此配置文件。 [root@localhost ~]# cat /etc/NetworkManager/system-connections/ens18.nmconnection [connection] id=ens18 uuid=7f49fd62-02d9-323e-8f35-0c8249647a74 type=ethernet autoconnect-priority=-999 interface-name=ens18 timestamp=1669365850 [ethernet] [ipv4] address1=192.168.11.172/24,192.168.11.254 # 第一个ip地址：前一个地址是ip，后一个是网关 # address2=192.168.11.145/24,192.168.11.254 # 第二个ip地址：同上 dns=114.114.114.114;223.6.6.6; dns-search=rockylinux.cn;rockylinux.org; method=manual [ipv6] addr-gen-mode=eui64 method=disabled [proxy] # 查看网络连接 [root@localhost ~]# nmcli connection NAME UUID TYPE DEVICE ens18 7f49fd62-02d9-323e-8f35-0c8249647a74 ethernet ens18 # 重启网络 [root@localhost ~]# systemctl restart NetworkManager [root@localhost ~]# systemctl status NetworkManager ● NetworkManager.service - Network Manager Loaded: loaded (/usr/lib/systemd/system/NetworkManager.service; enabled; vendor preset: enabled) Active: active (running) since Fri 2022-11-25 03:52:19 EST; 5s ago Docs: man:NetworkManager(8) Main PID: 2002 (NetworkManager) Tasks: 4 (limit: 48930) Memory: 2.9M CPU: 105ms CGroup: /system. slice/NetworkManager. service └─2002 /usr/sbin/NetworkManager --no-daemon``` ## 路由 route ### 路由与交换 **路由**: 指跨网络访问的路径选择 **交换**: 指同网络访问。两台机器连在同一个交换机上，配置同网段的不同ip就可以直接通迅 (这里不讨论三层交换). ### Linux 处理数据包的过程 当向外界主机发送数据时，数据从网卡流入后需要对它做路由决策，根据其目标决定是流入本机的用户空间还是在内核空间就直接转发给其他主机 1、如果是流入本机用户空间的数据， 则数据会从内核空间进入用户空间 (被应用程序接收并处理)； 此时如果本机用户空间的应用程序不需要产生新的数据包对外发送，那便不再涉及到从某个网卡流出数据； 但是如果本机用户空间的应用程序需要产生新的数据包对外发送，那便需要从某个网卡流出数据，但在流出之前，也需要做路由决策：根据目标决定从哪个网卡流出。 2、如果不是流入本机用户空间的数据，仅仅只是要经由本机把数据包转发给其他主机 则必然涉及到从某个网卡流出，此时数据包必须从流入网卡完整地转发给流出网卡，这要求 Linux 主机能够完成这样的转发。但 Linux 主机默认未开启 ip_forward 功能，这使得数据包无法转发而被丢弃。 临时开启linux主机的路由转发功能，重启网络服务则失效： ```bash # 方式1： echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward # 方式2： sysctl -w net.ipv4.ip_forward=1 若要永久生效，则应该写入配置文件\n1 2 3 4 5 6 7 # 在CentOS 6中: 将/etc/sysctl.conf文件中的\u0026#34;net.ipv4.ip_forward\u0026#34;值改为1即可 #在CentOS 7中: systemd管理了太多的功能，sysctl的配置文件也分化为多个，包括/etc/sysctl.conf、/etc/sysctl.d/*.conf和/usr/lib/sysctl.d/*.conf，并且这些文件中默认都没有net.ipv4.ip_forward项。当然，直接将此项写入到这些配置文件中也都是可以的，建议写在/etc/sysctl.d/*.conf中，这是systemd提供自定义内核修改项的目录。例如： echo \u0026#34;net.ipv4.ip_forward=1\u0026#34; \u0026gt; /etc/sysctl.d/ip_forward.conf 查看是否开启转发功能\n1 2 3 sysctl net.ipv4.ip_forward cat /proc/sys/net/ipv4/ip_forward sysctl -a | grep ip_forward **只有当本机被别人当成网关并且本机开启路由转发功能时，别人发来的请求包，本机才会帮忙转发\n如果Linux主机有多块网卡，如果不开启数据包转发功能，则这些网卡之间是无法互通的。\n主机1———————\u0026gt;eth0 主机2 etht1——————————\u0026gt;主机3\n172.16.10.11/24 \u0026mdash;\u0026mdash;-172.16.10.12/24 ,192.168.100.12/24 \u0026mdash;\u0026mdash;\u0026mdash;192.168.100.11/24\n到达该Linux主机2的数据包无法从eth0交给eth1或者从eth1交给eth0，除非Linux主机开启了数据包转发功能。\n另外，IP地址是属于内核的(不仅如此，整个tcp/ip协议栈都属于内核，包括端口号)，只要能和其中一个地址通信，就能和另一个地址通信，而不需要开启数据包转发功能\n但是前提本机一定要有匹配的路由，\n例如主机1上要访问主机2的172.16.10.24/24\n主机1上就必须配置一条可以匹配目标地址172.16.10.24/24的路由，这个路由可以是默认路由、网络路由、主机路由都行，只要路由能匹配上保证数据包能送出去就行，否则内核层面发现本机匹配不到路由就会直接在本机就把包扔了\n网关/路由 （⭐）\rLinux上分为3种路由：\n主机路由：掩码位32位，Destination精确到某一台主机，直接指明到某台具体的主机怎么走，主机路由也就是所谓的静态路由 网络路由：掩码小于32位，Destination精确到某一个网段的主机，指明到某类网络怎么走 默认路由：掩码通常为0，不走主机路由的和网络路由的、全部都走默认路由。操作系统上设置的默认路由一般也称为网关。 路由是区分优先级的：若Linux上到某主机有多条路由可以选择，这时候会挑选优先级高的路由 主机范围越小、越精确、优先级越高，而缩小主机范围的恰恰就是子网掩码，掩码越长范围越小、越精确、优先级越高 route 命令\r需要安装 net-tools route命令用于显示和管理路由表。当使用了add或del选项时，route命令将设置路由条目，否则route命令将显示路由表。 要显示路由表信息，只需简单的route -n即可，其中-n选项表示不解析主机名。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [root@localhost ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.100.2 0.0.0.0 UG 100 0 0 eth0 172.16.10.0 0.0.0.0 255.255.255.0 U 100 0 0 eth1 192.168.0.0 192.168.100.70 255.255.0.0 UG 0 0 0 eth0 192.168.100.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0 192.168.100.78 0.0.0.0 255.255.255.255 UH 0 0 0 eth0 各字段含义 # 1、Destination：目标网络或目标主机 # 2、Gateway：要达到目标所需要经过的网关。如果没有通过网关，这部分将显示为0.0.0.0。 # 3、Genmask：和目标IP配对使用的网络掩码 # 4、Flags：：表示特定的路由信息，有三个字符 U 表示该路由处于up状态、该路由可用 G 表示通过网关，路由项指向了一个网关 H 表示路由项指向一个主机，而非整个网络 管理路由表\n操作类型 命令示例 说明 查看路由表 route -n 以数字格式显示路由表（不解析主机名），包含目标网络、网关、子网掩码、接口等信息。 添加网络路由 sudo route add -net 192.168.2.0 netmask 255.255.255.0 gw 192.168.1.1 eth0 指定目标网络、子网掩码、网关和网卡，将流量路由到特定子网。 添加默认网关 sudo route add default gw 192.168.1.1 设置默认路由，所有未匹配的流量通过此网关转发。 删除特定路由 sudo route del -net 192.168.2.0 netmask 255.255.255.0 删除指定目标网络和子网掩码的路由规则。 删除默认网关 sudo route del default 移除当前默认网关配置。 修改临时生效，重启后丢失 想要永久生效需将路由规则写入配置文件（如 /etc/network/interfaces 或通过 netplan / nmcli 工具）\n配置永久路由\rcentos 7.9\r根据接口创建路由配置文件/etc/syconfig/network-scripts/route-ethX，要从那个接口出去X就是几。\n路由配置文件的配置格式非常简单，每一行一个路由条目，先是要到达的目标，然后是via关键字，最后是下一跳地址。要求下一跳必须能到达，且一般都和ethX同网段。\nDEST via nexthop\n1 2 3 4 5 6 7 8 9 10 #默认路由 default via 192.168.100.1 0.0.0.0/0 via 192.168.100.1 #网段路由 192.168.10.0/24 via 192.168.100.1 #主机路由 192.168.100.52/32 via 192.168.100.33 dev eth1 配置完后，重启network服务即可立即生效 systemctl restart network 需要注意：\n(1).route-ethX的对应网卡配置文件ifcfg-ethX必须存在，否则路由无效。(注意：对于虚拟机，通常新添加的网卡都没有对应的ifcfg-ethX文件，但ifconfig却能找到该网卡)\n(2).如果在文件中配置永久默认路由，则必须保证所有使用了DHCP服务的网卡配置文件ifcfg-ethX中的DEFROUTE指令设置为”no”，表示DHCP不设置默认路由。\n(3).如果在route-ethX文件中配置永久路由，且该网卡使用了DHCP服务分配地址，则必须保证该网卡的ifcfg-ethX文件中的PEERROUTES指令设置为”no”，表示DHCP设置的路由允许被覆盖。\ncentos 9\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 nmcli的改动会直接自动改到配置文件中， centos7改的是/etc/sysconfig/network-scripts/route-ens33 centos9改的是/etc/NetworkManager/system-connections/ens160.nmconnection，新增一条类似route1=0.0.0.0/32,192.168.71.10 “nmcli connection up 网卡“后可以在route -n中看到 强调：+号代表增加路由条目，-号代表删除，如果不带任何符号代表覆盖 # 1、添加默认路由：“0.0.0.0/0”代表所有IP地址，“192.168.1.1”代表路由的网关。 nmcli connection modify eth0 +ipv4.routes \u0026#34;0.0.0.0/0 192.168.1.1\u0026#34; # 注意在centos7中该命令的掩码不允许设置为0 nmcli connection up eth0 # 使更改生效 # 2、添加网络路由：“192.0.2.0/24”是目标网络，“192.168.1.1”是网关。 nmcli connection modify eth0 +ipv4.routes \u0026#34;192.0.2.0/24 192.168.1.1\u0026#34; nmcli connection up eth0 # 3、添加主机路由：“192.0.2.2/32”是目标主机的网络地址， “192.168.1.1”是网关。 nmcli connection modify eth0 +ipv4.routes \u0026#34;192.0.2.2/32 192.168.1.1\u0026#34; nmcli connection up eth0 删除它们也很简单，只需要将上述命令中的+ipv4.routes更改为-ipv4.routes即可： nmcli connection modify eth0 -ipv4.routes \u0026#34;0.0.0.0/0 192.168.1.1\u0026#34; nmcli connection modify eth0 -ipv4.routes \u0026#34;192.0.2.0/24 192.168.1.1\u0026#34; nmcli connection modify eth0 -ipv4.routes \u0026#34;192.0.2.2/32 192.168.1.1\u0026#34; nmcli connection up eth0 网络命令补充\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 arp -n -v -i # 查看arp缓存 选项说明： -n：不解析ip地址为名称 -v：详细信息 -i：指定操作的接口 -d：删除一个arp条目 arping 用于发送arp请求报文，解析并获取目标地址的MAC。默认将先发送广播报文，收到回复后再发送单播报文，局域网内所有主机都能收到广播报文，但只有目标主机才会回复自己的MAC地址。 ip 命令 ip addr ip addr show ip route 网络问题排查思路\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 ## 定位网络问题工具 mii-tool eth0 # 判断物理网卡是否接了网线 ping命令 telnet 目标ip 端口 tcpdump + wireshark抓包分析 ## 测试网络连通性 1、判断网卡是否能识别，是否接了有效的网线 mii-tool eth0 # 判断物理网卡是否接了网线 有可能明明连接了有效的网线，但是还是看不到link ok,可以先确定网卡配置文件是正确的，并且ONBOOT=yes ，然后重启network服务（systemctl restart network ） 2、**ping 127.0.0.1** 通，代表系统能够支持tcp/ip通信。 不通，原因： 相关驱动损坏或者没有。防火墙iptables拦截了。 3、**ping 网卡的ip** 假设eth0配置10.1.1.22 ping 10.1.1.22 通，说明网卡是能够正常工作 不通，可能是网卡驱动工作不正常，或iptables防火墙问题。 或者是网卡未激活，可以尝试重启网络服务 4、**ping 网关** 不通 原因： 网关有问题，或者IP冲突 解决方法：ping 同一个网段中其他IP,或者用其他计算机也ping网关，如果能通，那就是自己机器的原因了 5、**ping 外网（IP或域名）** # ping 外网IP 通，只能说明通信没问题，网关是ok的。 不通，很可能就是网关无法联网 # ping 域名 如果连域名对应的IP都无法返回，说明域名解析失败，原因：DNS设定有问题。 7、**ping的错误类型** **network unreachable (网络不可达)： 一般没有设定正确的网关** **unknow host xxxx : 设定DNS无效** ======================\u0026gt;Ping命令返回错误信息说明\u0026lt;====================== # 1.Request timed out 这是大家经常碰到的提示信息，很多文章中说这是对方机器置了过滤ICMP数据包，从上面工作过程来看，这是不完全正确的，至少有下几种情况。 （1） 对方已关机，或者网络上根本没有这个地址：比如在上图中主机A中PING 192.168.0.7 ，或者主机B关机了，在主机A中PING 192.168.0.5 都会得到超时的信息。 （2）对方与自己不在同一网段内，通过路由也无法找到对方，但有时对方确实是存在的，当然不存在也是返回超时的信息。 （3）对方确实存在，但设置了ICMP数据包过滤（比如防火墙设置）。 怎样知道对方是存在，还是不存在呢，可以用带参数 -a 的Ping命令探测对方，如果能得到对方的NETBIOS名称，则说明对方是存在的，是有防火墙设置，如果得不到，多半是对方不存在或关机，或不在同一网段内。 （4）错误设置IP地址 正常情况下，一台主机应该有一个网卡，一个IP地址，或多个网卡，多个IP地址（这些地址一定要处于不同的IP子网）。但如果一台电脑的“拨号网络适配器”（相当于一块软网卡）的TCP/IP设置中，设置了一个与网卡IP地址处于同一子网的IP地址，这样，在IP层协议看来，这台主机就有两个不同的接口处于同一网段内。当从这台主机Ping其他的机器时，会存在这样的问题： A.主机不知道将数据包发到哪个网络接口，因为有两个网络接口都连接在同一网段。 B.主机不知道用哪个地址作为数据包的源地址。因此，从这台主机去Ping其他机器，IP层协议会无法处理，超时后，Ping 就会给出一个“超时无应答”的错误信息提示。但从其他主机Ping这台主机时，请求包从特定的网卡来，ICMP只须简单地将目的、源地址互换，并更改一些标志即可，ICMP应答包能顺利发出，其他主机也就能成功Ping通这台机器了。 # 2.Destination host Unreachable （1） 对方与自己不在同一网段内，而自己又未设置默认的路由，比如上例中A机中不设定默认的路由，运行Ping192.168.0.1.4就会出现“Destination host Unreachable”。 （2）网线出了故障 这里要说明一下“destination host unreachable”和 “time out”的区别，如果所经过的路由器的路由表中具有到达目标的路由，而目标因为其他原因不可到达，这时候会出现“time out”，如果路由表中连到达目标的路由都没有，那就会出现“destination host unreachable”。 # 3.Bad IP address 这个信息表示您可能没有连接到DNS服务器，所以无法解析这个IP地址，也可能是IP地址不存在。 # 4.Source quench received 这个信息比较特殊，它出现的机率很少。它表示对方或中途的服务器繁忙无法回应。 # 5.Unknown host——不知名主机 这种出错信息的意思是，该远程主机的名字不能被域名服务器（DNS）转换成IP地址。故障原因可能是域名服务器有故障，或者其名字不正确，或者网络管理员的系统与远程主机之间的通信线路有故障。 # 6.No answer——无响应 这种故障说明本地系统有一条通向中心主机的路由，但却接收不到它发给该中心主机的任何信息。故障原因可能是下列之一：中心主机没有工作；本地或中心主机网络配置不正确；本地或中心的路由器没有工作；通信线路有故障；中心主机存在路由选择问题。 # 7.Ping 127.0.0.1 127.0.0.1是本地循环地址.如果本地址无法Ping通，则表明本地机TCP/IP协议不能正常工作。 # 8.no rout to host 网卡工作不正常。 # 9.transmit failed，error code：10043 网卡驱动不正常。 # 10.unknown host name DNS配置不正确 ","date":"2025-05-28T13:01:59+08:00","image":"https://bestoko.cc/p/linux-basics-9/linux_hu_50fb11894fe3fd8d.png","permalink":"https://bestoko.cc/p/linux-basics-9/","title":"Linux基础（九）：网络管理"},{"content":"储备知识\r同步与异步：任务的启动/调用方式\r程序：存放代码的文件=》静态\n进程：程序的运行过程=》动态\n同步： 多个任务是同步执行的指的是启动一个任务之后，必须在原地等待该任务运行完毕之后，才能启动下一个任务并且运行\n异步： 提交完一个任务之后，不用在原地等待该任务运行完毕 就能立即提交下一个任务执行\n补充\u0026amp;符号： \u0026amp;作用：在bash命令后加\u0026amp;符号，可以把该命令放到后台运行\n并发与并行：指的是任务给人展现出的运行的效果\r并发/并行：多个任务是”同时“运行的\n串行：一个任务运行完毕，才能运行下一个\n阻塞与非阻塞：任务在操作系统中的运行状态\n会引起阻塞的事项： 1、硬盘io 2、网络io 3、sleep 4、read命令\n进程的结构：树形结构\r0 号：整个系统的祖宗进程\n0号进程会产生两个进程1号和2号\n1号：是所有用户态进程的祖宗 2号：是所有内核态进程的祖宗 进程的状态（R、S、D、T、Z、X）\r活着的\r运行、就绪着的 R 正在执行：手里拿着cpu正在运行 就绪（随时可以投入运行）：正在等待操作系统分配cpu，一旦分配到，就可以立即投入运行 阻塞着的 S 或 D S：可中断的睡眠 可以用例如ctrl+c, kill -9 pid号命令来终止 D: 不可中断睡眠（因为存储设备太忙了响应不过来了） 不可以被中止（linux系统为了防止数据丢失的一种保护机制） 死了的\r僵尸进程 Z 僵尸进程是操作系统的一种优化机制 一个进程死掉之后，会把其占用的 cpu、内存资源都释放掉，但是会保留该进程的状态信息 例如 pid 号、存在过的一些运行信息 这些保留下来的信息都是操作系统给父进程准备的 每个进程死掉之前都会进入僵尸进程的状态 僵尸进程通常由父进程来回收 退出的进程 X 进程已完全终止，仅在内核态短暂出现。 用户态工具（如 ps）通常看不到此状态。 补充： +号：前台运行的进程 s：表示该进程是会话（session）的领导/领导进程，用来接收用户请求，然后自己不干给儿子进程去干 l：当前进程是多线程模式 \u0026lt;: 高优先级的进程 T：暂停\n给进程发送一个SIGSTOP信号，进程就会响应信号进入T状态， 再通过发送SIGCONT信号让进程继续运行。 kill -SIGSTOP pid号 kill -SIGCONT pid号\nps aux 命令解析\r1 2 3 4 5 6 [root@localhost ~]# ps aux |head -5 USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.3 128400 7104 ? Ss 8月12 0:05 /usr/lib/systemd/systemd --switched-root --system --deserialize 22 root 2 0.0 0.0 0 0 ? S 8月12 0:00 [kthreadd] root 4 0.0 0.0 0 0 ? S\u0026lt; 8月12 0:00 [kworker/0:0H] root 5 0.0 0.0 0 0 ? S 8月12 0:01 [kworker/u256:0] USER: 运行进程的用户\nPID： 进程ID\n%CPU: CPU占用率\n%MEM: 内存占用率，指的是实际内存RSS占用率\nVSZ： 占用虚拟内存，单位：KB（killo Bytes） VSZ是指已分配的线性空间大小，这个大小通常并不等于程序实际用到的内存大小，产生这个的可能性很多 比如内存映射，共享的动态库，或者向系统申请了更多的堆，都会扩展线性空间大小。\nRSS: 占用实际内存，单位：KB（killo Bytes） RSZ是Resident Set Size，常驻内存大小，即进程实际占用的物理内存大小\nTTY： 进程运行的终端\nSTAT： 进程状态 man ps (/STATE) R 运行 S 可中断睡眠 Sleep，即在睡眠的过程中可以接收信号唤醒=》执行的IO操作可以得到硬件设备的响应 D 不可中断睡眠，即在睡眠的过程中不可以接收信号唤醒=》执行的IO操作得不到硬件设备的响应 T 停止的进程 Z 僵尸进程 X 死掉的进程(几乎看不见，因为死了就立即回收了)\n\u0026lt; 标注了\u0026lt;小于号代表优先级较高的进程 N N代表优先级较低的进程\ns 该进程包含子进程，该进程自己是整个会话的领导者\n+ +表示是前台的进程组 l 小写字母l，代表以线程的方式运行，即多线程 | 管道符号代表多进程 START: 进程的启动时间 TIME： 进程占用CPU的总时间\nCOMMAND： 进程文件，进程名 带[]号的代表内核态进程 不带[]号的代表用户态进程 补充Centos9中还有一个大写字母I的进程状态 大写字母\u0026quot;I\u0026quot;代表的进程状态是\u0026quot;Idle kernel thread\u0026quot;，这意味着该进程是一个空闲的内核线程，不是用户模式下的空闲进程。这个状态通常只应用于内核线程，用户进程通常不会有这个状态。\nVSZ 虚拟内存与 RSS 物理内存\rVSZ（Virtual Memory Size） 含义：进程可访问的全部内存（包括实际占用+预留的共享库/映射文件）。 特点： 包含未实际使用的内存（如申请但未写入的堆空间）。 单位通常为 KB（ps aux 中显示的值）。 示例：\n若进程申请 1GB 堆但仅写入 100MB，VSZ ≈ 1GB。 RSS（Resident Set Size） 含义：进程实际占用的物理内存（不含交换分区 Swap）。 特点： 包含共享库中已被加载的部分。 直接反映进程对物理内存的压力。 示例：\n上述进程中，RSS ≈ 100MB（实际写入的物理内存）。 pstree 查看进程树\ntop 命令解析\r基本用法\n1 2 3 4 5 6 7 [root@localhost ~]# top [root@localhost ~]# top -d 1 # 1秒刷新一次 [root@localhost ~]# top -d 1 -p 进程的pid [root@localhost ~]# top -d 1 -p `pgrep nginx | head -1` [root@localhost ~]# top -d 1 -p `pgrep sshd | head -1`,33 # 查看sshd以及pid为33的进程 [root@localhost ~]# top -d 1 -u nginx # 查看指定用户进程 [root@localhost ~]# top -b -n 2 \u0026gt; top.txt # 将2次top信息写入到文件 显示信息解释\r第1行（系统状态）：\ntop - 15:30:02 up 10 days, 3 users, load average: 0.5, 0.3, 0.2 15:30:02：当前时间 up 10 days：系统运行时间 load average：1/5/15分钟的平均负载（核心数≤1为正常）。 第2行（任务统计）：\nTasks: 100 total, 2 running, 98 sleeping, 0 stopped, 0 zombie running：运行中的进程数 zombie：僵尸进程数（需警惕）。 第3行（CPU使用率）：\n%Cpu(s): 5.3 us, 2.0 sy, 0.0 ni, 92.7 id, 0.0 wa, 0.0 hi, 0.0 si us：用户态CPU sy：内核态CPU ni： Nice Time 低优先级进程（Nice 值 \u0026gt; 0）占用的 CPU 时间百分比 wa：I/O等待（高则磁盘瓶颈） id：空闲CPU。 hi：Hardware Interrupt Time 硬件中断占用 CPU（如键盘/磁盘）占用的 CPU 时间百分比 si：Software Interrupt Time 软中断处理占用 CPU（网络、多核任务调度）占用的 CPU 时间百分比 第4行（物理内存）：\nMiB Mem : 8000 total, 200 free, 5000 used, 2800 buff/cache used：已用内存（含缓存） free：完全空闲内存。 第5行（交换分区）：\nMiB Swap: 2000 total, 1500 free, 500 used used：Swap使用量（高则物理内存不足）。 交互快捷键\nP：按CPU%排序 M：按内存%排序 k：终止进程（输入PID） q：退出 1：展开多核CPU详情 average 平均负载（负载指的是几个活跃的活要干）：在一段时间内，处于 R 状态的进程数+不可中断 D 睡眠的进程数 平均负载是用来要衡量系统的繁忙程度 4 个 cpu： 平均负载为 3，代有个 3 个活跃进程，\u0026mdash;》低负载 平均负载为 4，代有个 4 个活跃进程，\u0026mdash;》满负载 平均负载\u0026gt;4， \u0026mdash;》超负载 cpu 的利用率：反应的是 cpu 的使用情况\n特殊进程\r僵尸进程、孤儿进程\r僵尸进程：进程已终止，但其退出状态未被父进程回收（残留内核中的 task_struct）。\n状态码 Z 产生原因： 父进程未调用 wait() 或 waitpid()。 父进程异常退出（如被 kill -9）。 影响： 占用 PID（可能导致 PID 耗尽）。 不消耗 CPU/内存。 解决： 终止父进程（内核会回收其所有僵尸子进程）。 重启服务或系统。 孤儿进程：父进程已终止，子进程被 init（PID 1）接 管。\n状态码：正常（ S 或 R） 产生原因： 父进程主动/被动退出（如崩溃）。 子进程仍在运行。 影响： 无害，init 会负责回收资源。 可能长期运行（如后台服务）。 用途： 实现守护进程（如 nginx、sshd） 守护进程\rDaemon Process 守护进程是 在后台长期运行的特殊进程，脱离终端控制，通常作为系统服务（如 sshd、nginx） 以下几点是守护进程的一些主要特征：\n1、守护进程在后台运行，通常不需要与用户交互。\n2、守护进程通常长时间运行，直到系统关闭。\n3、守护进程没有控制终端，也不拥有标准输入设备，标准输出设备或标准错误设备。\n守护进程与普通进程的区别主要体现在：\n1、生命周期：普通进程通常由用户启动，任务完成后结束；而守护进程在系统启动后自动运行，直到系统关闭。\n2、控制：普通进程通常有控制终端，可以直接与用户交互；而守护进程没有控制终端，通常通过系统日志、配置文件等方式进行管理和配置。\n管理进程\r给进程发信号\rkill -l 列出所有支持的信号 最常用的八个信号：\n信号编号 信号名 默认行为 典型用途 1 SIGHUP 终止进程 重新加载配置（如 nginx -s reload 发送 SIGHUP 给主进程） 2 SIGINT 终止进程 Ctrl+C 触发，优雅终止前台进程 3 SIGQUIT 终止 + 核心转储 Ctrl+ 触发，用于调试（生成 core 文件） 9 SIGKILL 强制终止 立即杀死进程（不可被捕获/忽略），救急用 15 SIGTERM 终止进程 默认信号，允许进程清理资源（如 kill \u0026lt;PID\u0026gt;） 18 SIGCONT 继续运行 恢复被 SIGSTOP 暂停的进程（如 kill -18 \u0026lt;PID\u0026gt;） 19 SIGSTOP 暂停进程 立即暂停进程（不可被捕获/忽略），Ctrl+Z 触发 20 SIGTSTP 暂停进程 可被捕获的暂停（如 Ctrl+Z 时程序可先执行清理） kill -15杀死进程（该信号可以被捕获、忽略和阻塞，有时候会被进程捕获然后忽略导致无法终止，则需要用-9）\n杀死所有：根据进程名杀所有\nkillall -9 vim pkill -9 vim\nHUP 信号\rHUP信号，主要涉及两种应用场景： 1、终端关闭时，系统会向与该终端相连的所有进程发送SIGHUP信号，这会导致这些进程被关闭（所有才有了脱离终端运行的需求） 2、用kill命令给进程发送SIGHUP信号实现该进程的平滑重启 需要注意的是，并非所有的进程或应用都能处理SIGHUP信号，只有程序内写过专门的捕获并处理该信号的代码才行， nginx的源代码里就写了，并且会响应该信号来实现平滑重启\n脱离终端运行来规避 HUP 信号影响\r当用户注销（logout）或者网络断开或者终端关闭，时，终端都会收到Linux HUP信号（hangup）信号，然后终端在结束前会关闭其所有子进程。 注意注意注意，一定是终端整体关闭，不是单纯的exit，就是说你要点击窗口的×号关闭\n如果我们想让我们的进程在后台一直运行，不要因为用户注销（logout）或者网络断开或者终端关闭而一起被干掉，那么我们有两种解决方案\n方案1：让进程忽略Linux HUP信号 方案2：让进程运行在新的会话里，从而成为不属于此终端的子进程，就不会在当前终端挂掉的情况下一起被带走。 1. nohup 命令\r针对方案1，我们可以使用nohup命令，nohup 的用途就是让提交的命令忽略 hangup 信号，该命令通常与\u0026amp;符号一起使用\nnohup 的使用是十分方便的，只需在要处理的命令前加上 nohup 即可，但是 nohup 命令会从终端解除进程的关联，进程会丢掉STDOUT，STDERR的链接。标准输出和标准错误缺省会被重定向到 nohup.out 文件中。一般我们可在结尾加上\u0026quot;\u0026amp;\u0026ldquo;来将命令同时放入后台运行，也可用\u0026rdquo;\u0026gt;filename 2\u0026gt;\u0026amp;1\u0026quot;来更改缺省的重定向文件名。\n2. setsid命令\r针对方案1，我们还可以用setsid命令实现，原理与3.1是一样的，setid是直接将进程的父pid设置成1，即让运行的进程归属于init的子进程，那么除非init结束，该子进程才会结束，当前进程所在的终端结束后并不会影响进程的运行\n1 2 3 4 5 6 7 8 # 1、在终端2中执行命令 [root@localhost ~]# setsid ping www.baidu.com # 也可以在后面加\u0026amp;符号 # 2、关闭终端2 # 3、在终端1中查看 [root@localhost ~]# ps -ef |grep [p]ing root 102335 1 0 17:53 ? 00:00:00 ping www.baidu.com 3. 在子shell中提交任务\r1 2 3 4 5 6 7 8 9 10 # 1、在终端2中执行命令 [root@localhost ~]# (ping www.baidu.com \u0026amp;) # 提交的作业并不在作业列表中 # 2、关闭终端2 # 3、在终端1中查看 [root@localhost ~]# ps -ef |grep [p]ing root 102361 1 0 17:55 ? 00:00:00 ping www.baidu.com 可以看到新提交的进程的父 ID（PPID）为1（init 进程的 PID），并不是当前终端的进程 ID。因此并不属于当前终端的子进程，从而也就不会受到当前终端的Linux HUP信号的影响了。 ","date":"2025-05-27T21:26:41+08:00","image":"https://bestoko.cc/p/linux-basics-8/linux_hu_50fb11894fe3fd8d.png","permalink":"https://bestoko.cc/p/linux-basics-8/","title":"Linux基础（八）：进程管理"},{"content":"现象\r今天在做nginx 负载均衡实现动静分离实验的时候，终端curl命令可以正常访问动态请求打到指定的后端服务器，但是浏览器的请求返回400\n原因\r经过排查后发现是nginx 转发给后端服务器的名字不支持下划线\n具体到 The character [_] is never valid in a domain name. 错误，这是 Tomcat 8.5.6（或更早一点）之后引入的更严格的 Host 头解析机制的结果。\n修改\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 [root@localhost ~]# cat /etc/nginx/nginx.conf user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { upstream frontend_server { server 10.0.0.117:8080 max_fails=3 fail_timeout=5s; } upstream file_server { server 10.0.0.118:8080 max_fails=3 fail_timeout=5s; } upstream backend-server { server 10.0.0.119:8080 max_fails=3 fail_timeout=5s; } server { listen 9090; location / { proxy_pass http://frontend_server; } location ~* \\.(css|js|jpg|png|gif)$ { proxy_pass http://file_server; } location ~* \\.jsp$ { proxy_pass http://backend-server; } } } 将原 backend_server 改成 backend-server\nsystemctl reload nginx 即可\n","date":"2025-05-26T16:32:22+08:00","image":"https://bestoko.cc/p/nginx-tomcat-host-error/nginx_logo_hu_a78ac966b3842cb5.png","permalink":"https://bestoko.cc/p/nginx-tomcat-host-error/","title":"nginx 负载均衡代理 tomcat 站点 400 错误"},{"content":"磁盘在系统中的命名\r设备名称 分区信息 设备类型 /dev/sda /dev/sda1 第一块物理硬盘第一分区 /dev/sdb /dev/sdb2 第二块硬盘第二个分区 /dev/vdd /dev/vdd4 第四块虚拟硬盘的第四个分区 sd开头，sda代表第一块盘，sdb代表第二块，sda1代表第一块盘的第一个分区\nsd中的d代表disk，s 代表 sata 或 sas 接口\n我们知道硬盘的接口标准还有 Nvme（Non-Volatile Memory Express，非易失性内存主机控制器接口规范），如果你是固态盘那建议用 Nvme，如果是 Nvme 接口，那么硬盘的命名规则为 \u0026ldquo;nvmeXnY\u0026rdquo;\n1、\u0026ldquo;nvme\u0026rdquo; 是 NVMe 协议的缩写；\n2、\u0026ldquo;X\u0026rdquo; 代表 NVMe 控制器 / 插槽的编号；0 代表第一个控制器或插槽, 1 代表第二个 3、\u0026ldquo;nY\u0026rdquo; 代表 NVMe 命名空间的编号。n1 代表某一个控制器的第 1 个命名空间，命名空间 namespace 相当于对硬盘做了虚拟化，一个命名空间就是一块逻辑盘，通常情况一个硬盘就一个命名空间\n所以关于完全可以这么记忆 nvme 代表协议： nvme0：代表主板上的第一个控制或插槽编号，用来插入硬盘的 nvme1：代表主板上的第二个控制或插槽编号，用来插入硬盘的\nnvme0—n1：代表 0 号插槽里插入了第一块硬盘，连在一起叫 nvme0n1 nvme0—n2：代表 0 号插槽里插入了第二块硬盘\nnvme0—n1—-p1：代表 0 号控制器插槽插入的第一块硬盘的第一个分区， nvme0—n1—-p2：代表 0 号控制器插槽插入的第一块硬盘的第二个分区 nvme0—n1—-p2：代表 0 号控制器插槽插入的第一块硬盘的第二个分区\nnvme1—n1—-p1：代表 1 号控制器插槽插入的第一块硬盘的第一个分区 nvme1—n1—-p2：代表 1 号控制器插槽插入的第一块硬盘的第二个分区 nvme1—n1—-p2：代表 1 号控制器插槽插入的第一块硬盘的第二个分区\n例如 1、Nvme0：第一块 2、Nvme1：第二块硬盘 3、Nvme0n1：第一块硬盘的第一个 namespace 命名空间，这是一个逻辑概念，一个名空间就相当于一块隔离的硬盘，当今世界都在谈虚拟化，这就相当于硬盘的虚拟化技术，这种 namespace 隔离设计思想在很多地方都会用，包括后面学习到的 docker、k8s 等\nNVMe 是一种硬盘接口技术，它是专为固态硬盘（SSD）设计的，比传统的 SATA 和 SAS 接口有更高的性能。 （Namespace）命名空间是 NVMe 设备数据存储的一个重要的逻辑概念，一个 NVMe 存储设备可以被分成多个独立的命名空间， 每一个命名空间被操作系统视为一个独立的硬盘。\n命名空间的一个主要作用就是数据隔离。这意味着不同的命名空间之间的数据互不干扰，可以独立地进行管理。 这种隔离功能有助于保护数据安全，防止不同应用之间的数据混淆或篡改。\n在一些特殊的场景下，命名空间的功能非常有用。例如，在数据中心环境中，一台物理服务器可能会被虚拟化为多个虚拟机， 每个虚拟机都运行着自己的操作系统和应用程序。如果这台服务器上有一块 NVMe 硬盘，我们可以为每个虚拟机分配一个命名空间。 每个虚拟机会认为自己独占了一块 NVMe 硬盘，而实际上，这些虚拟机都在共享同一块物理硬盘。 这样，就实现了物理硬盘资源的共享，同时保证了每个虚拟机之间的数据隔离。\n分区主要分为三类：主分区 \u0026lt;—扩展分区 \u0026lt;—逻辑分区\n1、逻辑分区属于扩展分区，扩展分区属于主分区 2、主分区又叫做引导分区，是可以安装系统的分区\n常见的磁盘分区格式有两张，MBR 分区和 GPT 分区：\nMBR 分区，MBR 的意思是 \u0026ldquo;主引导记录\u0026rdquo;。MBR 最大支持 2 TB 容量，在容量方面存在着极大的瓶颈。并且只支持创建最多 4 个主分区，。而 GPT 分区方式就没有这些限制 GPT 分区（ubuntu 装系统默认就是 GPT 分区），GPT 意为 GUID 分区表，它支持的磁盘容量比 MBR 大得多。这是一个正逐渐取代 MBR 的新标准，它是由 UEFI 辅住而形成的，将来 UEFI 用于取代老旧的 BIOS，而 GPT 则取代老旧的 MBR。 1 2 fdisk # 用于 MBR 格式 gdisk # 用于 GPT 格式 查看设备详情, 以及分区的情况\r1 2 3 4 5 6 7 8 9 10 11 12 [root@localhost ~]# lsblk /dev/sda NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 10G 0 disk ├─sda1 8:1 0 500M 0 part /boot ├─sda2 8:2 0 1G 0 part [SWAP] └─sda3 8:3 0 8.5G 0 part / [root@localhost ~]# lsblk /dev/sdb NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sdb 8:16 0 20G 0 disk [root@localhost ~]# lsblk /dev/sdc NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sdc 8:32 0 20G 0 disk fdisk 工具\r适用于磁盘小于 2TB 的磁盘，分区类型 MBR，主分区 4 或主分区 3 + 扩展分区（逻辑分区 +…），分区后需要保存后才能生效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 [root@localhost ~]# fdisk /dev/sdb Command (m for help): m #输入m列出常用的命令 Command action a toggle a bootable flag #切换分区启动标记 b edit bsd disklabel #编辑sdb磁盘标签 c toggle the dos compatibility flag #切换dos兼容模式 d delete a partition #删除分区 l list known partition types #显示分区类型 m print this menu #显示帮助菜单 n add a new partition #新建分区 o create a new empty DOS partition table #创建新的空白分区表 p print the partition table #显示分区表的信息 q quit without saving changes #不保存退出 s create a new empty Sun disklabel #创建新的Sun磁盘标签 t change a partitions system id #修改分区ID,可以通过l查看id u change display/entry units #修改容量单位,磁柱或扇区 v verify the partition table #检验分区表 w write table to disk and exit #保存退出 x extra functionality (experts only) #拓展功能 1 2 3 4 5 优先掌握 n p d # 删除一个已有的分区，保存退出后需要执行partprobe命令刷新一下分区表 w 主分区最多四个，一般设置三个以内，剩下空间都给扩展分区\ngdisk 工具\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # 需要安装命令 [root@localhost ~]# yum install gdisk -y [root@localhost ~]# gdisk /dev/sdc ...... Command (? for help): m b back up GPT data to a file #将GPT数据备份到文件中 c change a partition\u0026#39;s name #更改分区的名称 d delete a partition #删除分区 i show detailed information on a partition #显示分区的详细信息 l list known partition types #列出已知的分区类型 n add a new partition #添加一个新的分区 o create a new empty GUID partition table (GPT) #创建一个新的空GUID分区表(GPT) p print the partition table #打印分区表 q quit without saving changes #没有保存更改就退出 r recovery and transformation options (experts only) #恢复和转换选项(仅限专家使用) s sort partitions #年代分类分区 t change a partition\u0026#39;s type code #不要更改分区的类型代码 v verify disk #验证磁盘 w write table to disk and exit #将表写入磁盘并退出 x extra functionality (experts only) #额外功能(仅限专家使用) ? print this menu #打印菜单 1 2 3 4 5 6 优先掌握 gdisk 创建分区 n p d w 格式化制作文件系统与挂载\r磁盘必须格式化制作文件系统，然后挂载才能使用 针对一块硬盘/dev/sdb 可以不分区，直接格式化制作文件系统\n1 mkfs.xfs /dev/sdb # /dev/sdb整体就是一个分区 也可以基于 mbr 或者 gpt 分区方式分区完毕后，针对某一个分区比如 / dev/sdb1 制作文件系统\n1 mkfs.xfs /dev/sdb1 centos7选择xfs格式作为默认文件系统，而且不再使用以前的ext，仍然支持ext4，xfs专为大数据产生，每个单个文件系统最大可以支持8eb，单个文件可以支持16tb，不仅数据量大，而且扩展性高。还可以通过xfsdump，xfsrestore来备份和恢复。\n挂载与卸载\r以 / dev/sdb1 为例演示\n1 2 3 4 5 6 7 [root@localhost ~]# mount /dev/sdb1 /opt/ 卸载 umount /dev/sdb1 # 或者umount /opt 强制卸载 umount -l /dev/sdb1 # 或者umount -l /opt 设置开机自动挂载\r将挂载命令写入文件/etc/rc.local(注意这是一个软连接，目标文件初始并没有x执行权限，需要加才行) 编辑文件/etc/fstab 1 2 3 [root@localhost ~]# sed -i \u0026#39;$a /dev/sdb1 /opt xfs defaults 0 0\u0026#39; /etc/fstab [root@localhost ~]# tail -1 /etc/fstab /dev/sdb1 /opt xfs defaults 0 0 补充：磁盘挂载mount\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -t 指定文件系统 -a 挂载/etc/fstab中配置的所有 [root@localhost ~]# mount -t xfs /dev/sdb1 /db1 可以查看到文件系统的uuid并挂载 [root@localhost ~]# blkid | grep sdb1 /dev/sdb1: UUID=\u0026#34;10a939a8-d17c-4a0f-9a89-8066ac013855\u0026#34; TYPE=\u0026#34;xfs\u0026#34; [root@localhost ~]# mount UUID=\u0026#34;10a939a8-d17c-4a0f-9a89-8066ac013855\u0026#34; /opt 建议配置文件/etc/fstab用uuid [root@localhost ~]# tail -1 /etc/fstab # 编辑文件，新增一行 UUID=\u0026#34;10a939a8-d17c-4a0f-9a89-8066ac013855\u0026#34; /opt xfs defaults 0 0 [root@localhost ~]# mount -a [root@localhost ~]# df # 查看挂载情况 补充：/etc/fstab配置文件编写格式\r要挂载的设备 挂载点（入口） 文件系统类型 挂载参数 是否备份 是否检查 /dev/sdb1 /data xfs defaults 0 0 第一列：device: 这里用来指定你要挂载的文件系统的设备名称或块信息，除了指定设备文件外，也可以使用 UUID、LABEL 来指定分区。 第二列：dir: 指定挂载点的路径; 第三列：type: 指定文件系统的类型, 如 ext3,ext4,xfs 等; 第四列：options: 指定挂载的参数, 默认为 defaults;\n参数 含义 async/sync 是否同步方式运行，默认 async（异步）。 user/nouser 是否允许普通用户使用 mount 命令挂载，默认 nouser。 exec/noexec 是否允许可执行文件执行，默认 exec。 suid/nosuid 是否允许存在 suid 属性的文件，默认 suid。 auto/noauto 执行 mount -a 时，此文件系统是否被主动挂载，默认 auto。 rw/ro 是否只读或者读写模式进行挂载。默认 rw。 defaults 具有 rw，suid，exec，auto，nouser，async 等默认参数的设定。 第五列：dump: 表示该挂载后的文件系统能否被 dump 备份命令作用;\n选项 含义 0 代表不做备份。 1 代表要每天进行备份操作。 2 代表不定日期的进行备份操作。 第六列：pass: 这里用来指定如何使用 fsck 来检查硬盘。\n选项 含义 0 代表不检查 1 检查，挂载点为 / 的（即根分区）时候，必须在这里填写 1，其他的都不能填写 1。 2 检查 (当 1 级别检验完成之后进行 2 级别检验) 制作 swap 分区\r查看\n1 2 3 4 [root@localhost ~]# free -m total used free shared buff/cache available Mem: 1980 186 1571 9 222 1600 Swap: 1023 0 1023 制作 swap 分区\n1 2 [root@localhost ~]# fdisk /dev/sdb # 分出一个1G的硬盘空间 [root@localhost ~]# mkswap /dev/sdb1 # 格式化为swap 激活 swap 分区\n1 2 3 4 5 6 7 8 9 10 [root@localhost ~]# free -m total used free shared buff/cache available Mem: 1980 185 1568 9 225 1601 Swap: 1023 0 1023 [root@localhost ~]# swapon /dev/sdb1 # 激活 [root@localhost ~]# free -m total used free shared buff/cache available Mem: 1980 186 1567 9 225 1600 Swap: 2047 0 2047 [root@localhost ~]# 关闭swap分区\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@localhost ~]# free -m total used free shared buff/cache available Mem: 1980 186 1567 9 225 1600 Swap: 2047 0 2047 [root@localhost ~]# swapon -s 文件名 类型 大小 已用 权限 /dev/sda2 partition 1048572 0 -2 /dev/sdb1 partition 1048572 0 -3 [root@localhost ~]# swapoff /dev/sdb1 # 关闭某一个 [root@localhost ~]# swapon -s [root@localhost ~]# free -m total used free shared buff/cache available Mem: 1980 185 1570 9 224 1601 Swap: 0 0 0 如果磁盘没有过多的分区可用，也可以通过文件增加SWAP空间，本质上还是磁盘\n1 2 3 4 5 6 7 8 9 10 11 12 [root@localhost ~]# dd if=/dev/zero of=/swap_file bs=1M count=200 [root@localhost ~]# chmod 0600 /swap_file [root@localhost ~]# free -m total used free shared buff/cache available Mem: 1980 185 1364 9 430 1598 Swap: 0 0 0 [root@localhost ~]# mkswap -f /swap_file [root@localhost ~]# swapon /swap_file [root@localhost ~]# free -m total used free shared buff/cache available Mem: 1980 222 1300 9 458 1550 Swap: 199 0 199 开机自动挂载新增的swap分区\n1 2 3 4 5 [root@localhost ~]# blkid | grep /dev/sdb1 /dev/sdb1: UUID=\u0026#34;91d30c2d-2b43-40b1-b2b5-6f828c585f97\u0026#34; TYPE=\u0026#34;swap\u0026#34; PARTUUID=\u0026#34;d3b7649d-54aa-45eb-8bef-dccfe6915413\u0026#34; [root@localhost ~]# vim /etc/fstab [root@localhost ~]# tail -1 /etc/fstab UUID=\u0026#34;91d30c2d-2b43-40b1-b2b5-6f828c585f97\u0026#34; swap swap defaults 0 0 XFS 文件系统备份与恢复\r命令与软件包\n1 2 3 4 [root@localhost ~]# rpm -qf `which xfsdump` xfsdump-3.1.7-1.el7.x86_64 [root@localhost ~]# rpm -qf `which xfsrestore` xfsdump-3.1.7-1.el7.x86_64 xfsdump的备份级别有以下两种，默认为0（即完全备份）\n1 2 3 4 5 0 完全备份 1 \u0026lt;= level \u0026lt;= 9 增量备份： # ps：增量备份是和第一次的备份（level 0）进行比较，仅备份有差异的文件（level 1） xfsdump 常用参数\n1 2 3 4 5 6 -l：注意不是大写字母L而是小写，就是指定level，有0~9共10个等级，默认为0，即完整备份。 -L：xfsdump会记录每次备份的session Label，这里可以填写针对此文件系统的简易说明； -M：xfsdump可以记录存储Media Label，这里可以填写此媒体的简易说明。 -f：后面接产生的文件和destination file 。例如/dev/st0设备文件名或其他一般文件文件名 -I：大写的“i”，从/var/lib/xfsdump/inventory 列出目前备份的信息状态。 xfsdump 使用限制\n必须用 root 权限 只能备份已挂载的文件系统 只能备份 XFS 文件系统 只能用 xfsrestore 解释 透过文件系统的 UUID 来分辨备份档，因此不能备份相同 UUID 的文件系统 xfsdump 备份与 xfsrestore 恢复 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 1、数据备份 # 1.1 先做全量备份，切记“备份的源路径”末尾不要加左斜杠/ 注意： （1）-L与-M后的你起的名字保持一致就行，也方便你记忆 （2）备份的源路径写/dev/sda1这种文件系统名字是通用写法，虽然在centos7.9中写挂载点路径虽然也可以，但是还是推荐用通用的靠谱一些 xfsdump -l 0 -L sdb3_bak -M sdb3_bak -f 全量备份的成果路径1 备份的源路径 # 1.2 再做增量备份 xfsdump -l 1 -L sdb3_bak -M sdb3_bak -f 增量备份的成果路径2 备份的源路径 xfsdump -l 1 -L sdb3_bak -M sdb3_bak -f 增量备份的成果路径3 备份的源路径 xfsdump -l 1 -L sdb3_bak -M sdb3_bak -f 增量备份的成果路径4 备份的源路径 # 2、数据恢复 # 2.1、先恢复全量备份 xfsrestore -f 全量备份的成果路径1 数据恢复的路径 # 2.2、再依次恢复增量 xfsrestore -f 增量备份的成果路径2 数据恢复的路径 xfsrestore -f 增量备份的成果路径2 数据恢复的路径 xfsrestore -f 增量备份的成果路径2 数据恢复的路径 LVM（⭐）\r我们在对磁盘分区的大小进行规划时，往往不能确定每个分区使用的空间大小，只能凭经验分配一个大小，而我们通常使用的 fdisk、gdisk 等工具对磁盘分区后，每个分区的大小就固定死了，这么做的问题是： 如果分区设置的过大，就白白浪费了磁盘空间； 如果分区设置的过小，就会导致空间不够用的情况出现。 对于分区过小的问题，我们可以重新划分磁盘的分区，或者通过软连接的方式将此分区的目录链接到另外一个分区。这样做虽然能够临时解决问题，但是给管理带来了麻烦 上述问题可以通过 LVM 来解决。\n逻辑卷管理LVM是硬盘的一个系统工具。无论在Linux或者其他类似的系统，都是非常的好用。传统分区使用固定大小分区，重新调整大小十分麻烦。但是，LVM可以创建和管理“逻辑”卷，而不是直接使用物理硬盘。可以让管理员弹性的管理逻辑卷的扩大缩小，操作简单，而不损坏已存储的数据。可以随意将新的硬盘添加到LVM，以直接扩展已经存在的逻辑卷。LVM并不需要重启就可以让内核知道分区的存在。\n通过 LVM 技术，可以屏蔽掉磁盘分区的底层差异，在逻辑上给文件系统提供了一个卷的概念，然后在这些卷上建立相应的文件系统。下面是 LVM 中主要涉及的一些概念。\n物理卷(PV):（physical volume）,把常规的磁盘设备通过pvcreate命令对其进行初始化，形成了物理卷。其实就是硬盘或分区。（面粉）\n卷组(VG):（volume group）,把多个物理卷组成一个逻辑的整体，这样卷组的大小就是多个硬盘之和。或者理解就是由一个或多个PV组成的整体。（面团）\n逻辑卷(LV)：（logical volume），从卷组中划分需要的空间大小出来。用户仅需对其格式化然后即可挂载使用。从VG中切割出的空间用于创建文件系统。（切成馒头）\n基本单元(PE)：(physical extend),分配的逻辑大小的最小单元，默认为4MB的基本块。（假设分配100MB逻辑空间，则需要创建25个PE）\nLVM 优缺点总结\r优点： 1、可以在系统运行的状态下动态的扩展文件系统的大小。 2、文件系统可以跨多个磁盘，因此文件系统大小不会受物理磁盘的限制。 3、可以增加新的磁盘到 LVM 的存储池中。 4、可以以镜像的方式冗余重要的数据到多个物理磁盘。 5、可以方便的导出整个卷组到另外一台机器。\n缺点： 1、因为加入了额外的操作，存取性能受到影响。 2、当卷组中的一个磁盘损坏时，整个卷组都会受到影响。 解释：LVM 如果有一个磁盘损坏, 整个 lvm 都坏了，lvm 只有动态扩展作用， 方案：底层用 RAID + 上层 LVM = 既有冗余又有动态扩展 3、在从卷组中移除一个磁盘的时候必须使用 reducevg 命令（该命令要求 root 权限, 并且不允许在快照卷组中使用）\nLVM 的基本使用\r软件包 ：lvm2\n1. 制作 PV：可以对分区做、也可以对整块盘做\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 制作 [root@localhost ~]# pvcreate /dev/sdb1 # 对分区做 [root@localhost ~]# pvcreate /dev/sdb2 # 对分区做 [root@localhost ~]# pvcreate /dev/sdb3 # 对分区做 [root@localhost ~]# pvcreate /dev/sdc # 对整块盘做 # 查看 [root@localhost ~]# pvs PV VG Fmt Attr PSize PFree /dev/sdb1 lvm2 --- 1.00g 1.00g /dev/sdb2 lvm2 --- 1.00g 1.00g /dev/sdb3 lvm2 --- 1.00g 1.00g /dev/sdc lvm2 --- 20.00g 20.00g [root@localhost ~]# pvscan PV /dev/sdb1 lvm2 [1.00 GiB] PV /dev/sdc lvm2 [20.00 GiB] PV /dev/sdb2 lvm2 [1.00 GiB] PV /dev/sdb3 lvm2 [1.00 GiB] Total: 4 [23.00 GiB] / in use: 0 [0 ] / in no VG: 4 [23.00 GiB] 2. 制作 VG：将 PV 划入 VG 中\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 制作一个vg1： [root@localhost ~]# vgcreate vg1 /dev/sdb1 /dev/sdc # 包含/dev/sdb1与/dev/sdc两个pv Volume group \u0026#34;vg1\u0026#34; successfully created [root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree vg1 2 0 0 wz--n- 20.99g 20.99g # 也可以再制作一个vg2： [root@localhost ~]# vgcreate vg2 /dev/sdb2 /dev/sdb3 # 包含/dev/sdb2与/dev/sdb3两个pv Volume group \u0026#34;vg2\u0026#34; successfully created [root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree vg1 2 0 0 wz--n- 20.99g 20.99g vg2 2 0 0 wz--n- 1.99g 1.99g [root@localhost ~]# 3. 创建逻辑卷 LVM\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 选项 -L #逻辑卷大小 -n #逻辑卷名字 # 从vg1中分出来逻辑卷lv1_from_vg1、lv2_from_vg1 [root@localhost ~]# lvcreate -L 100M -n lv1_from_vg1 vg1 [root@localhost ~]# lvcreate -L 200M -n lv2_from_vg1 vg1 # 从vg2中分出来一个建逻辑卷lv1_from_vg2、lv1_from_vg2 [root@localhost ~]# lvcreate -L 300M -n lv1_from_vg2 vg2 [root@localhost ~]# lvcreate -L 400M -n lv2_from_vg2 vg2 # 查看 [root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1_from_vg1 vg1 -wi-a----- 100.00m lv2_from_vg1 vg1 -wi-a----- 200.00m lv1_from_vg2 vg2 -wi-a----- 300.00m lv2_from_vg2 vg2 -wi-a----- 400.00m # 把vg的100%空间都给lv lvcreate -l 100%VG -n lv的名字 vg的名字 格式与挂载\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [root@localhost ~]# mkfs.xfs /dev/vg1/lv1_from_vg1 [root@localhost ~]# mkfs.xfs /dev/vg1/lv2_from_vg1 [root@localhost ~]# mkfs.xfs /dev/vg2/lv1_from_vg2 [root@localhost ~]# mkfs.xfs /dev/vg2/lv2_from_vg2 [root@localhost ~]# mount /dev/vg1/lv1_from_vg1 /test1/ [root@localhost ~]# mount /dev/vg1/lv2_from_vg1 /test2/ [root@localhost ~]# [root@localhost ~]# mount /dev/vg2/lv1_from_vg2 /test3/ [root@localhost ~]# mount /dev/vg2/lv2_from_vg2 /test4/ # 查看 [root@localhost ~]# df 文件系统 1K-块 已用 可用 已用% 挂载点 ... /dev/mapper/vg1-lv1_from_vg1 98980 5344 93636 6% /test1 /dev/mapper/vg1-lv2_from_vg1 201380 10464 190916 6% /test2 /dev/mapper/vg2-lv1_from_vg2 303780 15584 288196 6% /test3 /dev/mapper/vg2-lv2_from_vg2 406180 20704 385476 6% /test4 [root@localhost ~]# 在线动态扩容\r在不用卸载的情况下完成扩容\n1 2 lvextend -L [+]MGT /dev/VG_NAME/VL_NAME # 注意：-L 100M 与 -L +100M不是一个意思，后者代表在原有的基础上扩容 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 1、新增一块盘或者一个分区 fdisk /dev/sdb ...... partprobe ls /dev/sdb4 # 2、新增一个pv [root@localhost ~]# pvcreate /dev/sdb4 # 3、把新增的pv扩到vg2里 [root@localhost ~]# vgextend vg2 /dev/sdb4 [root@localhost ~]# vgs # 可以看到vg2扩容了 # 4、接下来对lv1_from_vg2扩容 [root@localhost ~]# lvextend -L +1000M /dev/vg2/lv1_from_vg2 [root@localhost ~]# xfs_growfs /dev/vg2/lv1_from_vg2 # 扩展逻辑卷后需要更新fs文件系统 在线缩容与删除\r不要缩容！！！并且xfs干脆不支持缩容\n1 2 3 4 5 6 7 8 9 10 11 lvreduce -L [-]MGT /dev/VG_NAME/LV_NAME 缩减逻辑卷 # 删除lv之前需要先卸载挂载点 [root@localhost ~]# umount /test3 [root@localhost ~]# lvremove /dev/vg2/lv1_from_vg2 # 删vg [root@localhost ~]# vgremove vg2 # 删pv：只能删掉那些不属于任何vg的pv [root@localhost ~]# pvremove /dev/sdb2 [root@localhost ~]# pvremove /dev/sdb3 快照\rLVM 机制还提供了对 LV 做快照的功能，也就是说可以给文件系统做一个备份，这也是设计 LVM 快照的主要目的。LVM 的快照功能采用写时复制技术(Copy-On-Write，COW)，这比传统的备份技术的效率要高很多。创建快照时不用停止服务，就可以对数据进行备份。说明：LVM 还支持 thin 类型的快照，但是本文中的快照都是指 COW 类型的快照。\nLVM 采用的写时复制，是指当 LVM 快照创建的时候，仅创建到实际数据的 inode 的硬链接(hark-link)而已。只要实际的数据没有改变，快照就只包含指向数据的 inode 的指针，而非数据本身。快照会跟踪原始卷中块的改变，一旦你更改了快照对应的文件或目录，这个时候原始卷上将要改变的数据会在改变之前拷贝到快照预留的空间。\nlvm快照的原理： 创建快照实际上也是创建了一个逻辑卷，只不过该卷的属性与普通逻辑卷的属性有些不一样。我们可以通过上图来理解快照数据卷(图中的实线框表示快照区域，虚线框表示文件系统)：\n左图为最初创建的快照数据卷状况，LVM 会预留一个区域 (比如左图的左侧三个 PE 区块) 作为数据存放处。此时快照数据卷内并没有任何数据，而快照数据卷与源数据卷共享所有的 PE 数据，因此你会看到快照数据卷的内容与源数据卷中的内容是一模一样的。等到系统运行一阵子后，假设 A 区域的数据被更新了(上面右图所示)，则更新前系统会将该区域的数据移动到快照数据卷中，所以在右图的快照数据卷中被占用了一块 PE 成为 A，而其他 B 到 I 的区块则还是与源数据卷共享！\r由于快照区与原本的 LV 共享很多 PE 区块，因此快照区与被快照的 LV 必须要在同一个 VG 上头，下面两点非常重要： 1、VG中需要预留存放快照本身的空间，不能全部被占满。 2、快照所在的 VG 必须与被备份的 LV 相同，否则创建快照会失败。\n快照的本质就是一个特殊的 lv，创建快照后，如果源数据卷中的文件被更新了，会将老数据赋给快照的空间，这就要求快照的空间也是够用的\n示例1：利用快照恢复单个文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 1、准备好初始数据 [root@localhost ~]# df 文件系统 1K-块 已用 可用 已用% 挂载点 。。。。。。 /dev/mapper/vg1-lv1_from_vg1 98980 5348 93632 6% /test1 [root@localhost ~]# echo \u0026#34;hello egon\u0026#34; \u0026gt; /test1/1.txt # 2、查看vg1容量是否充足 lv1_from_vg1 属于卷组vg1，而vg1有足够的容量来分配给快照卷 [root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree vg1 2 2 0 wz--n- 20.99g \u0026lt;20.70g [root@localhost ~]# # 3、在vg1卷组里创建一个lv1_from_vg1的逻辑卷 [root@localhost ~]# lvcreate -L 1G -s -n lv1_from_vg1_snap /dev/vg1/lv1_from_vg1 # 4、查看 [root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1_from_vg1 vg1 owi-aos--- 100.00m lv1_from_vg1_snap vg1 swi-a-s--- 104.00m lv1_from_vg1 0.01 。。。。。。 # 5、修改文件/test/1.txt [root@localhost ~]# echo \u0026#34;egon say ladygaga\u0026#34; \u0026gt;\u0026gt; /test1/1.txt [root@localhost ~]# cat /test1/1.txt hello egon egon say ladygaga # 6、恢复数据 挂载快照，注意：快照在挂载的时候由于和原来的lvm是同一个UUID，而XFS是不允许相同UUID的文件系统挂载，所以需要加选项 -o nouuid [root@localhost ~]# mount -o nouuid /dev/vg1/lv1_from_vg1_snap /opt/ [root@localhost ~]# cat /opt/1.txt hello egon [root@localhost ~]# cp /opt/1.txt /test1/1.txt cp：是否覆盖\u0026#34;/test1/1.txt\u0026#34;？ y [root@localhost ~]# cat /test1/1.txt hello egon [root@localhost ~]# 示例2：如果要恢复的文件个数过多，可以直接合并\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 mount /dev/vg1/lv1_from_vg1 /test1/ echo hello egon \u0026gt; /test1/1.txt # -L指快照的大小，不能超过源的大小，超了也没啥用 lvcreate -L 1G -s -n lv1_from_vg1_snap /dev/vg1/lv1_from_vg1 echo aaaa \u0026gt;\u0026gt; /test1/1.txtecho aaaa \u0026gt;\u0026gt; /test1/1.txt echo aaaa \u0026gt;\u0026gt; /test1/1.txt echo aaaa \u0026gt;\u0026gt; /test1/1.txt echo aaaa \u0026gt;\u0026gt; /test1/1.txt echo aaaa \u0026gt;\u0026gt; /test1/1.txt mount -o nouuid /dev/vg1/lv1_from_vg1_snap /opt/ [root@localhost ~]# cat /opt/1.txt hello egon [root@localhost ~]# cat /test1/1.txt hello egon aaaa aaaa aaaa aaaa aaaa 先卸载数据源与快照，再进行合并，快照会自动删除，一次性的 [root@localhost ~]# umount /test1 [root@localhost ~]# umount /opt [root@localhost ~]# lvconvert --mergesnapshot /dev/vg1/lv1_from_vg1_snap [root@localhost ~]# mount /dev/vg1/lv1_from_vg1 /test1/ [root@localhost ~]# cat /test1/1.txt # 数据还原回来了 hello egon ","date":"2025-05-25T23:19:42+08:00","image":"https://bestoko.cc/p/linux-basics-7/linux_hu_50fb11894fe3fd8d.png","permalink":"https://bestoko.cc/p/linux-basics-7/","title":"Linux基础（七）：存储管理"},{"content":"文件权限（⭐）\r基本权限\r文件权限的种类：\nr：可读=》4 w：可写=》2 x：可执行=》1 权限的归属：\n属主：u 属组：g 其他人：o 谁来用文件的权限\u0026mdash;》进程\n进程来用文件的时候，如何匹配权限的呢？\n进程启动（必须赋予某种身份） 进程启动时的身份是怎么来的？ （1）默认为当前登录用户 （2）在配置文件里修改指定进程启动的身份 拿着进程的用户身份，去匹配目标文件的权限 进程的用户身份会依次配文件的 u\u0026mdash;\u0026gt; 9 段权限的前三段 g\u0026mdash;\u0026gt; 9 段权限的中三段 o\u0026mdash;\u0026gt; 9 段权限的后三段 特殊权限\rsuid\r给命令文件加的权限 chmod u+s /usr/bin/passwd\n效果： passwd # \u0026mdash;-》/etc/shadow\n加了suid权限的命令在启动时的用户身份会用自己的命令文件的属主身份\nSUID 权限仅对二进制可执行文件有效 如果执行者对于该二进制可执行文件具有 x 的权限，执行者将具有该文件的所有者的权限 本权限仅在执行该二进制可执行文件的过程中有效 sgid\r当SGID 作用于普通文件时，和 SUID 类似，在执行该文件时，用户将获得该文件所属组的权限。\n当 SGID 作用于目录时，意义就非常重大了： 当一个用户对某一目录有写和执行权限时，该用户就可以在该目录下建立文件\n如果该目录同时用 SGID 修饰，则该用户在这个目录下建立的文件都是属于这个目录所属的组。\n可以给文件夹加 chmod g+s /aaa # 后续在/aaa 文件夹下创建的文件、文件夹的属组都会继承自/aaa 文件夹的属组\nsticky / sbit\rSBIT 目前只对目录有效，用来阻止非文件的所有者删除文件。 权限信息中最后一位 t 表明该目录被设置了 SBIT 权限。SBIT 对目录的作用是：当用户在该目录下创建新文件或目录时，仅有自己和 root 才有权力删除，主要作用于一个共享的文件夹。\nchmod o+t /share 在/share 文件下的文件只能被 root 用户及属主自己操作\n特殊权限的数字代号 suid\u0026mdash;-》4 sgid\u0026mdash;-》2 sticky\u0026mdash;-》1\n1 2 3 chmod 0755 a.txt chmod 7755 a.txt chmod 4755 a.txt umask 值\rumask值可以控制创建文件、文件夹时的默认权限 在 root 用户下默认创建 文件的权限：644 文件夹的权限：755\n为何默认是上述权限： 系统默认权限 文件的权限\u0026ndash;》666 文件夹的权限\u0026ndash;》777\n文件及文件夹的默认创建权限是：系统默认权限+umask值计算出来一个结果\nlinux中文件默认权限为666、目录权限默认为777，在umask的影响下\n文件权限计算方法 ：偶数位直接相减，奇数位相减后加1\r文件的起始权限值 umask值 操作 计算后文件权限 666 022 (每位如果都是偶数) 直接相减即可 644 666 033 (每位如果有奇数或偶数) 相减（奇数位相减后在其原奇数位加1） 644 666 325(每位如果有奇数或偶数) 相减（奇数位相减后在其原奇数位加1） 442 目录权限计算方法 ：直接相减即可\r文件的起始权限值 umask值 操作 计算后文件权限 777 022 相减 755 777 033 相减 744 777 325 相减 452 umask设置的越小，权限越大，慎用 1 2 3 4 5 6 7 8 9 10 11 12 # 临时设置umask [root@localhost ~]# umask 000 //设置umask权限 # 永久设置umask [root@localhost tmp]# vim /etc/profile # 或者/etc/bashrc内容一样 ...... if [ $UID -gt 199 ] \u0026amp;\u0026amp; [ \u0026#34;`id -gn`\u0026#34; = \u0026#34;`id -un`\u0026#34; ]; then umask 002 //表示uid大于等于199的默认umask值，表示普通用户 else umask 022 //表示uid小于199的默认umask值，表示root fi SU 切换用户（⭐）\r按照进入shell环境方式的不同，分为两种：\n登录shell：登录账号密码，su - egon 非登录shell：在shell环境中直接输入命令进入的shell环境，su egon 二者的区别的就是加载的配置文件不同：\n登录shell：\n​\t/etc/profile ​\t/etc/profile.d/脚本 ​\t\u0026mdash;\u0026mdash;\u0026mdash;》centos9.3会多执行1次/etc/bashrc ​\t~/.bash_profile ​\t~/.bashrc ​\t/etc/bashrc 非登录shell： ~/.bashrc\n​\t/etc/bashrc ​\t/etc/profile.d/脚本 ​ PATH=$PATH:/usr/local/nginx/sbin export PATH ​ 切换用户过程中加载的配置文件 sudo（⭐）\r让普通用户只用自己的账号密码进行认证，操作时可以临时获取管理的某种权限\n修改sudo配置文件的两种方式\nvisudo # 专门编辑文件/etc/sudoers visudo -c # 检查文件语法 vi /etc/sudoers ","date":"2025-05-24T23:13:40+08:00","image":"https://bestoko.cc/p/linux-basics-6/linux_hu_50fb11894fe3fd8d.png","permalink":"https://bestoko.cc/p/linux-basics-6/","title":"Linux基础（六）：系统权限管理进阶"},{"content":"文件系统\r文件系统filesystem是操作系统内核中负责组织管理磁盘的程序。 linux常见文件系统有xfs、ext4 和 btrfs 文件系统，它们都是日志文件系统（其特点是文件系统将没提交的数据变化保存到日志文件，以便在系统崩溃或者掉电时恢复数据） 每个硬盘分区都要有一个文件系统：\n硬盘分区\u0026mdash;-》打隔断，分割出一个个小空间 文件系统\u0026mdash;-》对一个个小空间做装修，负责把空间的数据组织好 文件系统组织好了之后带来的方便之处 使用者\u0026mdash;\u0026ndash;》\tblock 块（文件系统）\u0026mdash;\u0026ndash;》n 个扇区（硬盘的读写单位） 一个文件系统包含的三大类块： 文件有两部分数据构成：\n元数据：ls -l 的结果如权限、属主、数组\u0026mdash;\u0026mdash;-》inode block 块 内容数据：cat 看到的结果，真正的内容 \u0026mdash;\u0026mdash;-》data block superblock 超级块：记录此 filesystem 的整体信息，包括 inode/block 的总量、使用量、剩余量，以及文件系统的格式与相关信息等；\n其中： superblock 一个文件系统整体就一个 对一个文件来说： inode block 就 1 个 data block 可能有多个\n查看文件类型\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 df -T # 查看文件系统类型 df -h # 空间使用量带单位 df -i # inode号的使用量 硬盘满了，分两种情况： 假设硬盘空间10个G 1、inode号耗尽：存1000 0000个空文件，耗尽inode号 测试命令：for((i=1;i\u0026lt;=300000;i++)){ touch $i.txt; } 2、磁盘空间耗尽：只存一个文件，但是这个文件有12G 测试命令：dd if=/dev/zero of=目标路径/1.txt bs=10G count=3 补充：动态检测某个命令的结果 watch -n 1 \u0026#34;df -i |grep sda1\u0026#34; 查看一个文件内容底层流程\r文件夹也是文件： 元数据：权限、属主、属组、、、\u0026mdash;\u0026mdash;》inode block块 内容数据：存的该文件夹包含的\u0026mdash;\u0026mdash;\u0026ndash;》data block块 子文件名\u0026mdash;\u0026ndash;》inode块的编号 子文件夹名\u0026mdash;\u0026ndash;》inode块的编号\n普通文件： 元数据：权限、属主、属组、、、\u0026mdash;\u0026mdash;\u0026ndash;》inode block块 内容数据：你写的文件中的数据\u0026mdash;\u0026mdash;\u0026ndash;》data block块\ncat /etc/passwd\n硬链接、软链接\r硬链接：目标文件与源文件指向同一个 inode 号\rln /1. txt /2. txt 特点： 1、改动一个文件元数据或内容，另外一个也跟着变 2、删除源文件，仅仅只是解除了源文件名与 inode 号的关联关系 所以不会影响目标文件 3、硬链接无法跨分区 [ root@localhost ~]# ln /1. txt /boot/3. txt ln: 无法创建硬链接\u0026quot;/boot/3. txt\u0026quot; =\u0026gt; \u0026ldquo;/1. txt\u0026rdquo;: 无效的跨设备连接 4、不能对目录做硬链接\n软连接：目标文件指向的是源文件的文件名\rln -s /1. txt /4. txt 特点： 1、改动一个文件内容，另外一个也跟着变 改元数据的话，彼此之间不会互相影响 2、删除源文件/1.txt，目标文件不可用 3、软连接可以跨分区，因为是指向文件名 ln -s /1.txt /boot/5.txt 4、可以对目录做软链接\n用户、组管理（⭐）\r什么是用户 ？组？\r如果把整个系统当成一个公司 用户 指的就是一个个员工 超级管理员 就是所有员工里的老板 组 指的就是部门\n为何要有用户？组？\r为了划分权限 具体来说分成三大类： u：文件归属的主人，简称属主 g：文件归属的组，简称属组 o：不是u也不是g里的成员，统称为其他人o\n每个进程都是以某个用户 xxx 身份启动 ps aux # 第一列就是当前进程的用户身份 当该要操作某个文件时，进程会以xxx用户去依次匹配 1、xxx用户是否是目标文件的属主，若是，则直接对应属主的权限，否则继续往下对应 2、xxx用户是否是目标的文件的属组内的成员，若是，则直接对应属组的权限，否则继续往下对应 3、xxx用户归属其他人 敲命令也是在启动进程，该进程的什么是谁？ 1、如果没做过任何配置，默认用户身份是你当前登录的用户 2、可以对程序进行配置，指定其以什么用户身份启动\n如何管理用户？组？\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 用户的增删除改查 useradd egon groupadd group1 usermod -a -G group1 egon id egon uid: 用户的身份证号（系统是uid号来识别用户） 0-》超级管理的uid，通常只有一个 1-999-》系统用户所使用的uid \u0026gt;1000-\u0026gt; 后续创建的用户 gid：用户的主组gid号（创建用户会默认会创建一个与用户名同名的组，作为该用户的主组）\tgroups: 该用户所在所有的组=主组+附加组 与用户相关的一系列文件 /etc/passwd : 存放的是用户详细信息 /etc/shadow : 存放的是用户的密码（了解） /etc/group : 存放的是组信息 /etc/gshadow: 存放组密码（了解） # 了解： /etc/skel # 家目录里的隐藏的源模板 /home/egon: 家目录 /var/spool/mail/egon # 邮箱文件 查看用户（补充） who whoami pkill -KILL -u egon # 强制某个用户下线 删除用户： userdel -r tom 创建用户详细（了解） useradd lili -s /sbin/nologin -u 2000 -g it -G salve -d /abc 修改用户 usermod -g group1 lili usermod -a -G group2 lili # 在原有的基础上增加附加组 组的增删改查 groupadd group1 groupmod -n sale salve groupdel -r group1 组成员管理： groupadd it useradd user01 useradd user02 useradd user03 gpasswd -a user01 it gpasswd -M user02,user03 it gpasswd -d user01 it # 从it组里删掉成员user01 ","date":"2025-05-24T23:08:30+08:00","image":"https://bestoko.cc/p/linux-basics-5/linux_hu_50fb11894fe3fd8d.png","permalink":"https://bestoko.cc/p/linux-basics-5/","title":"Linux基础（五）：系统权限管理基础"},{"content":"文件查找\r查看命令所属文件\r1 2 root@ubuntuserver:~# which ip /usr/sbin/ip 查找文件\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 按文件名 find [options] [path...] [expression] [root@localhost ~]# find /etc -name \u0026#34;ifcfg-eth0\u0026#34; [root@localhost ~]# find /etc -iname \u0026#34;ifcfg-eth0\u0026#34; # -i忽略大小写 [root@localhost ~]# find /etc -iname \u0026#34;ifcfg-eth*\u0026#34; 按文件大小 [root@localhost ~]# find /etc -size +3M # 大于3M [root@localhost ~]# find /etc -size 3M [root@localhost ~]# find /etc -size -3M [root@localhost ~]# find /etc -size +3M -ls # -ls找到的处理动作 指定查找的目录深度： -maxdepth levels [root@localhost ~]# find / -maxdepth 5 -a -name \u0026#34;ifcfg-eth0\u0026#34; # -a并且，-o或者，不加-a，默认就是-a 按时间找(atime,mtime,ctime)： [root@localhost ~]# find /etc -mtime +3 # 修改时间超过3天 [root@localhost ~]# find /etc -mtime 3 # 修改时间等于3天 [root@localhost ~]# find /etc -mtime -3 # 修改时间3天以内 按文件属主、属组找： [root@localhost ~]# find /home -user egon # 属主是egon的文件 [root@localhost ~]# find /home -group it # 属组是it组的文件 [root@localhost ~]# find /home -user egon -group it [root@localhost ~]# find /home -user egon -a -group it # 同上意思一样 [root@localhost ~]# find /home -user egon -o -group it [root@localhost ~]# find /home -nouser # 用户还存在，在/etc/passwd中删除了记录 [root@localhost ~]# find /home -nogroup # 用户还存在，在/etc/group中删除了记录 [root@localhost ~]# find /home -nouser -o -nogroup 按文件类型 [root@localhost ~]# find /dev -type f # f普通 [root@localhost ~]# find /dev -type d # d目录 [root@localhost ~]# find /dev -type l # l链接 [root@localhost ~]# find /dev -type b # b块设备 [root@localhost ~]# find /dev -type c # c字符设备 [root@localhost ~]# find /dev -type s # s套接字 [root@localhost ~]# find /dev -type p # p管道文件 根据inode号查找：-inum n [root@localhost ~]# find / -inum 1811 按文件权限： [root@localhost ~]# find . -perm 644 -ls [root@localhost ~]# find . -perm -644 -ls [root@localhost ~]# find . -perm -600 -ls [root@localhost ~]# find /sbin -perm -4000 -ls # 包含set uid [root@localhost ~]# find /sbin -perm -2000 -ls # 包含set gid [root@localhost ~]# find /sbin -perm -1000 -ls # 包含sticky 找到后的处理动作\r1 2 3 4 5 6 7 8 9 10 11 12 -print -ls -delete -exec -ok [root@localhost ~]# find /etc -name \u0026#34;ifcfg*\u0026#34; -print # 必须加引号 [root@localhost ~]# find /etc -name \u0026#34;ifcfg*\u0026#34; -ls [root@localhost ~]# find /etc -name \u0026#34;ifcfg*\u0026#34; -exec cp -rvf {} /tmp \\; # 非交互 [root@localhost ~]# find /etc -name \u0026#34;ifcfg*\u0026#34; -ok cp -rvf {} /tmp \\; # 交互 [root@localhost ~]# find /etc -name \u0026#34;ifcfg*\u0026#34; -exec rm -rf {} \\; [root@localhost ~]# find /etc -name \u0026#34;ifcfg*\u0026#34; -delete # 同上 find 配合 xargs\r1 2 3 4 5 [root@localhost ~]# find . -name \u0026#34;egon*.txt\u0026#34; |xargs rm -rf [root@localhost ~]# find /etc -name \u0026#34;ifcfg-eth0\u0026#34; |xargs -I {} cp -rf {} /var/tmp [root@localhost ~]# find /test -name \u0026#34;ifcfg-ens33\u0026#34; |xargs -I {} mv {} /ttt [root@localhost ~]# find /ttt/ -name \u0026#34;ifcfg*\u0026#34; |xargs -I {} chmod 666 {} 文件管理之上传下载\rwget\r1 2 3 4 wget -O 本地路径 远程包链接地址 # 将远程包下载到本地，-O指定下载到哪里，可以生路-O 本地路径 # ps：如果wget下载提示无法建立SSL连接，则加上选项--no-check-certificate wget --no-check-certificate -O 本地路径 远程包链接地址 curl\r1 2 3 4 5 6 7 8 9 10 11 #curl命令是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称curl为下载工具。作为一款强力工具，curl支持包括HTTP、HTTPS、[ftp]等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。做网页处理流程和数据检索自动化，curl可以祝一臂之力。 [root@localhost ~]# curl -o 123.png https://www.xxx.com/img/hello.png # ps: 如果遇到下载提示无法简历SSL链接，使用-k选项或者--insecure curl -k -o 123.png https://www.xxx.com/img/hello.png # 下载远程脚本并直接在本地执行 # 你可以在远程在test.sh所在的文件夹下执行python3 -m http.server 8899启动一个服务，Python2则用python2 -m SimpleHTTPServer 8899 # 然后在本地执行（注意关闭防火墙与selinux） curl -s http://192.168.71.206:8899/test.sh | bash # -s代表静默模式，会屏蔽掉curl命令本身的输出 sz、rz\r1 2 3 4 5 6 7 8 9 # 系统默认没有该命令，需要下载：yum install lrzsz -y 将服务器上选定的文件下载/发送到本机 sz bak.tar.gz 弹出一个文件选择窗口，从本地选择文件上传到服务器 rz rz -E # -E如果目标文件名已经存在，则重命名传入文件。新文件名将添加一个点和一个数字(0..999） 文件管理之输出与重定向\r输出即把相关对象通过输出设备（显示器等）显示出来，输出又分正确输出和错误输出\n一般情况下标准输出设备为显示器，标准输入设备为键盘。 linux中用文件标识符\n0代表标准输入 1代表标准正确输出 2代表标准错误输出 输出重定向 ：\r正常输出是把内容输出到显示器上，而输出重定向是把内容输出到文件中，\u0026gt;代表覆盖，\u0026raquo;代表追加 Ps：标准输出的1可以省略\n例如：ifconfig \u0026gt; test.log 即把ifconfig执行显示的正确内容写入test.log.当前页面不再显示执行结果。 注意：错误输出重定向\u0026gt;与\u0026raquo;后边不要加空格\n1 2 3 4 5 6 7 8 1、下述两个命令作用相同 命令 \u0026gt;\u0026gt;file.log 2\u0026gt;\u0026amp;1 命令 \u0026amp;\u0026gt;\u0026gt;file.log 2、正确日志和错误日志分开保存 命令 \u0026gt;\u0026gt;file1.log 2\u0026gt;\u0026gt;file2.log 3、系统有个常见用法 ls \u0026amp;\u0026gt;/dev/null 正确输出或错误输出结果都不要。（null可以理解为黑洞或垃圾站） 输入重定向：\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #没有改变输入的方向，默认键盘，此时等待输入 [root@egon ~]# tr \u0026#39;N\u0026#39; \u0026#39;n\u0026#39; No no [root@egon ~]# tr \u0026#39;N\u0026#39; \u0026#39;n\u0026#39; \u0026lt; file.txt #没有改变输入的方向，默认键盘，此时等待输入 [root@egon ~]# grep \u0026#39;root\u0026#39; oldboy root root [root@egon ~]# grep \u0026#39;root\u0026#39; \u0026lt; /etc/passwd root:x:0:0:root:/root:/bin/bash # 读写块设备 [root@egon ~]# dd if=/dev/zero of=/file1.txt bs=1M count=20 [root@egon ~]# dd \u0026lt;/dev/zero \u0026gt;/file2.txt bs=1M count=20 # mysql如何恢复备份，了解即可，不用关注。 [root@qls ~]# mysql -uroot -p123 \u0026lt; bbs.sql 文件管理之字符处理命令\rsort\r用于将文件内容加以排序\n-n # 依照数值的大小排序 -r # 以相反的顺序来排序 -k # 以某列进行排序 -t # 指定分割符，默认是以空格为分隔符 1 2 3 4 5 6 7 [root@localhost ~]# sort -t \u0026#34;:\u0026#34; -n -r -k2 file.txt f:11 e:5 a:4 b:3 c:2 d:1 uniq\r用于检查及删除文本文件中重复出现的行列，一般与 sort 命令结合使用\n-c # 在每列旁边显示该行重复出现的次数。 -d # 仅显示重复出现的行列。 -u # 仅显示出一次的行列。 1 2 3 [root@localhost ~]# sort file.txt | uniq -d 123 hello cut\rcut命令用来显示行中的指定部分，删除文件中指定字段\n-d # 指定字段的分隔符，默认的字段分隔符为\u0026quot;TAB\u0026quot;； -f # 显示指定字段的内容； 1 2 3 4 [root@localhost ~]# head -1 /etc/passwd root:x:0:0:root:/root:/bin/bash [root@localhost ~]# head -1 /etc/passwd | cut -d \u0026#34;:\u0026#34; -f1,3,4,6 root:0:0:/root tr\r替换或删除命令\n-d # 删除字符 1 2 3 4 5 [root@localhost ~]# head -1 /etc/passwd |tr \u0026#34;root\u0026#34; \u0026#34;ROOT\u0026#34; ROOT:x:0:0:ROOT:/ROOT:/bin/bash [root@localhost ~]# [root@localhost ~]# head -1 /etc/passwd |tr -d \u0026#34;root\u0026#34; :x:0:0::/:/bin/bash wc\r统计，计算数字\n-c # 统计文件的Bytes数； -l # 统计文件的行数； -w # 统计文件中单词的个数，默认以空白字符做为分隔符 1 2 [root@localhost ~]# grep \u0026#34;hello\u0026#34; file.txt \\|wc -l| 2 文件管理之打包压缩/大文件切分\r打包压缩\r1. 什么是打包压缩 打包指的是将多个文件和目录合并为一个特殊文件 然后将该特殊文件进行压缩 最终得到一个压缩包 2. 为什么使用压缩包\n1.减少占用的体积 2.加快网络的传输 3. Windows的压缩和Linux的有什么不同\nwindows: zip rar(linux不支持) linux: zip tar.gz tar.bz2 .gz 如果希望windows的软件能被linux解压,或者linux的软件包被windows能识别,选择zip. PS: 压缩包的后缀不重要,但一定要携带. 4. Linux下常见的压缩包类型\n格式 压缩工具 .zip zip压缩工具 .gz gzip压缩工具，只能压缩文件，会删除源文件（通常配合tar使用） .bz2 bzip2压缩工具，只能压缩文件，会删除源文件（通常配合tar使用） .tar.gz 先使用tar命令归档打包，然后使用gzip压缩 .tar.bz2 先使用tar命令归档打包，然后使用bzip压缩 ps：windows下支持.rar，linux不支持.rar\n打包压缩与解压缩方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # 1、打包 [root@localhost test]# tar cvf etc_bak.tar /etc/ # c创建 v详细 f打包后文件路径 ps: 打包的目标路径如果是绝对路径，会提示：tar: 从成员名中删除开头的“/”，不影响打包， 添加-P选项便不再提示：tar cvPf ... 可以cd 到 /etc下然后tar cvf etc_bak.tar *打包，这样去掉了一层文件夹 # 2、压缩 [root@localhost test]# gzip etc_bak.tar # 文件体积变小，并且加上后缀.gz ps: gzip -\u0026gt; gunzip bzip2-\u0026gt; bunzip2 #3、上述两步可以合二为一 [root@localhost test]# tar czvf etc1_bak.tar.gz /etc/ # 选项z代表gzip压缩算法 [root@localhost test]# tar cjvf etc1_bak.tar.bz2 /etc/ # 选项j代表bzip2压缩算法 #zip压缩 选项： -r #递归压缩 压缩目录 -q #静默输出 # 示例1、 [root@localhost ~]# zip /test/bak.zip a.txt b.txt c.txt # zip后的第一个参数是压缩包路径，其余为被压缩的文件 adding: a.txt (stored 0%) adding: b.txt (stored 0%) adding: c.txt (stored 0%) [root@localhost ~]# ls /test/ bak.zip # 示例1、 [root@localhost ~]# zip -rq etc.zip /etc # 加上-q后压缩过程不再提示 #1、针对xxx.tar.gz 或者 xxx.tar.bz2，统一使用 [root@localhost test]# tar xvf 压缩包 -C 解压到的目录 # 无需指定解压算法，tar会自动判断 #2、针对xxx.zip，用unzip 选项： -l #显示压缩包的列表信息 -q #静默输出 -d #解压到指定的目录 [root@localhost test]# unzip -q xxx.zip -d /opt 拓展时间命令 date\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #选项 -d #根据你的描述显示日期 -s #修改日期 %H #小时，24小时制（00~23） %M #分钟（00~59） %s #从1970年1月1日00:00:00到目前经历的秒数 %S #显示秒（00~59） %T #显示时间，24小时制（hh:mm:ss） %d #一个月的第几天（01~31） %j #一年的第几天（001~366） %m #月份（01~12） %w #一个星期的第几天（0代表星期天） %W #一年的第几个星期（00~53，星期一为第一天） %y #年的最后两个数字（1999则是99） %Y #年，实际 %F #显示日期（%Y-%m-%d） 使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 [root@localhost ~]# date 2020年 08月 12日 星期三 20:55:48 CST [root@localhost ~]# date +%F 2020-08-12 [root@localhost ~]# date +%Y-%m-%d 2020-08-12 [root@localhost ~]# [root@localhost ~]# date +%y-%m-%d 20-08-12 [root@localhost ~]# date +%T 00:01:03 [root@localhost ~]# date +%H:%M:%S 00:01:11 [root@localhost ~]# [root@localhost ~]# date +%w 3 [root@localhost ~]# date +%s 1597236988 [root@localhost ~]# date +%d 12 [root@localhost ~]# date +%W 32 [root@localhost ~]# date +%j 225 [root@localhost ~]# date -d \u0026#34;-1 day\u0026#34; +%F 2020-08-11 [root@localhost ~]# date -d \u0026#34;1 day\u0026#34; +%F 2020-08-13 [root@localhost ~]# date -d \u0026#34;+1 day\u0026#34; +%F 2020-08-13 [root@localhost ~]# date -d \u0026#34;3 years\u0026#34; +%F 2023-08-12 [root@localhost ~]# date -d \u0026#34;+3 years\u0026#34; +%F 2023-08-12 [root@localhost ~]# date -d \u0026#34;+3 hours\u0026#34; +%F_%H:%M:%S 2020-08-12_23:58:06 [root@localhost ~]# date -s 20201111 2020年 11月 11日 星期三 00:00:00 CST [root@localhost ~]# date -s 11:11:11 2020年 11月 11日 星期三 11:11:11 CST [root@localhost ~]# date -s \u0026#34;20201111 11:11:11\u0026#34; 2020年 11月 11日 星期三 11:11:11 CST [root@localhost ~]# date +%F 2020-11-11 [root@localhost ~]# date +%T 11:11:29 备份使用 [root@localhost ~]# tar czvf `date +%F`_bak.tar.gz /etc [root@localhost ~]# tar czvf `date +%F_%H_%M_%S`_bak.tar.gz /etc # 如果带有时分秒，不要用冒号分隔，因为文件名的命名里不能带有冒号 大文件切分\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 生产环境中，一些文件比较大，动则几个G，有的安装包和镜像可达到十几G，但是有些平台显示传输文 件大小，所以一些比较大的文件会被切割上传再合并。 # 这里介绍了个比较常用简单的切割方式split [root@localhost ~]# split -b 1024m vgpu-0.3.6.tgz [root@localhost ~]# [root@localhost ~]# ls vgpu-0.3.6.tgz xaa xab xac [root@localhost ~]# ls -lh total 16206432 -rw-r--r-- 1 linhaifeng01 staff 2.6G 8 7 13:03 b.tar -rw-r--r--@ 1 linhaifeng01 staff 2.6G 8 5 16:22 vgpu-0.3.6.tgz -rw-r--r-- 1 linhaifeng01 staff 1.0G 8 7 13:03 xaa -rw-r--r-- 1 linhaifeng01 staff 1.0G 8 7 13:03 xab -rw-r--r-- 1 linhaifeng01 staff 582M 8 7 13:03 xac [root@localhost ~]# [root@localhost ~]# # 重新合并比对md5值是一致的 [root@localhost ~]# md5 vgpu-0.3.6.tgz MD5 (vgpu-0.3.6.tgz) = 94583a6e02508d142594701234a080ff [root@localhost ~]# [root@localhost ~]# [root@localhost ~]# [root@localhost ~]# [root@localhost ~]# cat x* \u0026gt; b.tar [root@localhost ~]# md5 b.tar MD5 (b.tar) = 94583a6e02508d142594701234a080ff ","date":"2025-05-23T17:16:25+08:00","image":"https://bestoko.cc/p/linux-basics-4/linux_hu_50fb11894fe3fd8d.png","permalink":"https://bestoko.cc/p/linux-basics-4/","title":"Linux基础（四）：文件系统管理高级"},{"content":"命令行文本编辑器 VI、VIM\r常用命令： 0 或功能键[Home]\t这是数字『 0 』：移动到这一行的最前面字符处 (常用) $ 或功能键[End]\t移动到这一行的最后面字符处 (常用) G\t移动到这个档案的最后一行 (常用)\n/word\t向光标之下寻找一个名称为 word 的字符串。 n 向下查找，N 向上查找 u 撤销上一个动作 ctrl + r 重做上一个动作 :set nu 设定行号\n查找替换 定位s@@@g :%s @/a/b/c/1.txt@/mmm/ 111.txt@g\n行定位： %：定位到所有行 1,5： 1 到 5 行 , 8 : 首先光标要移动到某一行，以这一行为起始一直到第 8 行 2,$ : 从第二行到最后一样\n比对两个文件 diff -u aaa.txt bbb.txt 以aaa.txt的内容作为参照，看一下bbb.txt有何变动 diff -u bbb.txt aaa.txt\n文本处理三剑客 sed、awk、grep\rsed\rstream editor 流式编辑器 不会一下子把文件内容全部读入内容 而是读一行到内存处理一行，然后再读下一行 非交互式编辑修改文本文件内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 # 用法 sed 选项 \u0026#39;定位+命令\u0026#39; 文件路径 # 选项 -n 取消默认输出 -r 支持扩展正则元字符(由于尚未学习正则，所以此处暂作了解，正则表达式将会在shell编程第九章第一节介绍) -i 立即编辑文件 # 定位 行定位： 1定位到第一行 1,3代表从第1行到第3行 不写定位代表定位所有行 正则表达式定位： /egon/ 包含egon的行 /^egon/ 以egon开头的行 /egon$/以egon结尾的行 数字+正则表达式定位 \u0026#34;1,8p\u0026#34;代表打印1到8行， \u0026#34;1,/egon/p\u0026#34;则代表取从第1行到首次匹配到/egon/的行 # 命令 d p s///g 命令可以用;号连接多多条，如1d;3d;5d代表删除1，3，5行 # =========================》用法示例：p与d [root@localhost ~]# sed \u0026#39;\u0026#39; a.txt egon1111 22222egon 3333egon33333 4444xxx44444 5555xxx55555xxxx555xxx 6666egon6666egon666egon [root@localhost ~]# sed -n \u0026#39;\u0026#39; a.txt [root@localhost ~]# [root@localhost ~]# sed -n \u0026#39;1,/xxx/p\u0026#39; a.txt egon1111 22222egon 3333egon33333 4444xxx44444 [root@localhost ~]# sed \u0026#39;1,/xxx/d\u0026#39; a.txt 5555xxx55555xxxx555xxx 6666egon6666egon666egon [root@localhost ~]# sed \u0026#39;1d;3d;5d\u0026#39; a.txt 22222egon 4444xxx44444 6666egon6666egon666egon # =========================》用法示例: s///g [root@localhost ~]# cat a.txt egon1111 22222egon 3333egon33333 4444xxx44444 5555xxx55555xxxx555xxx 6666egon6666egon666egon [root@localhost ~]# sed \u0026#39;s/egon/BIGEGON/g\u0026#39; a.txt # 把所有行的所有的egon都换成BIGEGON BIGEGON1111 22222BIGEGON 3333BIGEGON33333 4444xxx44444 5555xxx55555xxxx555xxx 6666BIGEGON6666BIGEGON666BIGEGON [root@localhost ~]# [root@localhost ~]# sed \u0026#39;/^egon/s/egon/GAGAGA/g\u0026#39; a.txt # 以egon开头的行中的egon换成GAGAGA GAGAGA1111 22222egon 3333egon33333 4444xxx44444 5555xxx55555xxxx555xxx 6666egon6666egon666egon [root@localhost ~]# sed \u0026#39;6s/egon/BIGEGON/\u0026#39; a.txt # 只把第6行的egon换成BIGEGON，加上g代表？？？ egon1111 22222egon 3333egon33333 4444xxx44444 5555xxx55555xxxx555xxx 6666BIGEGON6666egon666egon [root@localhost ~]# [root@localhost ~]# sed \u0026#39;1,3s/egon/BIGEGON/g\u0026#39; a.txt # 把1到3行的egon换成BIGEGON BIGEGON1111 22222BIGEGON 3333BIGEGON33333 4444xxx44444 5555xxx55555xxxx555xxx 6666egon6666egon666egon [root@localhost ~]# cat a.txt | sed \u0026#39;1,5d\u0026#39; # sed也支持管道 6666egon6666egon666egon # 加上-i选项，直接修改文件，通常会在调试完毕确保没有问题后再加-i选项 awk\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 # 用法 awk 选项 \u0026#39;pattern{action}\u0026#39; 文件路径 # 选项 -F 指定行分隔符 # 工作流程 awk -F: \u0026#39;{print $1,$3}\u0026#39; /etc/passwd 1、awk会读取文件的一行内容然后赋值给$0 2、然后awk会以-F指定的分隔符将该行切分成n段，最多可以达到100段，第一段给$1,第二段给$2,依次次类推 3、print输出该行的第一段和第三段，逗号代表输出分隔符，默认与-F保持一致 4、重复步骤1,2,3直到文件内容读完 # 内置变量 $0 一整行内容 NR 记录号，等同于行号 NF 以-F分隔符分隔的段数 # pattern可以是 /正则/ /正则/ # 该行内容匹配成功正则 $1 ~ /正则/ # 第一段内容匹配成功正则 $1 !~ /正则/ # 第一段内容没有匹配成功正则 比较运算： NR \u0026gt;= 3 \u0026amp;\u0026amp; NR \u0026lt;=5 # 3到5行 $1 == \u0026#34;root\u0026#34; # 第一段内容等于root # action可以是 print $1,$3 # 用法示例 [root@localhost ~]# cat a.txt root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin [root@localhost ~]# awk -F: \u0026#39;/^root/{print $1,$3}\u0026#39; a.txt root 0 [root@localhost ~]# awk -F: \u0026#39;$1 ~ /^d/{print $1,$3}\u0026#39; a.txt daemon 2 [root@localhost ~]# awk -F: \u0026#39;$1 !~ /^d/{print $1,$3}\u0026#39; a.txt root 0 bin 1 adm 3 lp 4 [root@localhost ~]# awk -F: \u0026#39;NR\u0026gt;3{print $1}\u0026#39; a.txt adm lp [root@localhost ~]# awk -F: \u0026#39;$1 == \u0026#34;lp\u0026#34;{print $0}\u0026#39; a.txt lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin [root@localhost ~]# [root@localhost ~]# cat a.txt | awk -F: \u0026#39;{print $1}\u0026#39; # awk也支持管道 root bin daemon adm lp [root@localhost ~]# grep\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 用法 grep 选项 \u0026#39;正则\u0026#39; 文件路径 # 选项 -n, --line-number 在过滤出的每一行前面加上它在文件中的相对行号 -i, --ignore-case 忽略大小写 --color 颜色 -l, --files-with-matches 如果匹配成功，则只将文件名打印出来，失败则不打印 通常-rl一起用，grep -rl \u0026#39;root\u0026#39; /etc -R, -r, --recursive 递归 # 示例 [root@localhost ~]# grep \u0026#39;^root\u0026#39; /etc/passwd root:x:0:0:root:/root:/bin/bash [root@localhost ~]# grep -n \u0026#39;bash$\u0026#39; /etc/passwd 1:root:x:0:0:root:/root:/bin/bash 44:egon:x:1000:1000:egon:/home/egon:/bin/bash [root@localhost ~]# grep -rl \u0026#39;root\u0026#39; /etc # grep也支持管道，我们可以发现三剑客命令都支持管道 [root@localhost ~]# ps aux |grep ssh root 968 0.0 0.2 112908 4312 ? Ss 14:05 0:00 /usr/sbin/sshd -D root 1305 0.0 0.3 163604 6096 ? Ss 14:05 0:00 sshd: root@pts/0 root 1406 0.0 0.3 163600 6240 ? Ss 14:05 0:00 sshd: root@pts/1 root 2308 0.0 0.0 112724 984 pts/1 R+ 15:30 0:00 grep --color=auto ssh [root@localhost ~]# ps aux |grep [s]sh root 968 0.0 0.2 112908 4312 ? Ss 14:05 0:00 /usr/sbin/sshd -D root 1305 0.0 0.3 163604 6096 ? Ss 14:05 0:00 sshd: root@pts/0 root 1406 0.0 0.3 163600 6240 ? Ss 14:05 0:00 sshd: root@pts/1 ","date":"2025-05-22T23:16:27+08:00","image":"https://bestoko.cc/p/linux-basics-3/linux_hu_50fb11894fe3fd8d.png","permalink":"https://bestoko.cc/p/linux-basics-3/","title":"Linux基础（三）：文件系统管理高级"},{"content":"Linux 的目录结构\r整个系统目录结构是一个树形结构 树根：/\n一切皆文件的设计思想 文件夹是用来组织文件 linux中的文件夹 \u0026mdash;-》目录文件\n绝对路径、相对路径\r绝对路径： 以/开头的路径 特点：当前无论你在哪个文件夹下面，用绝对路径肯定能找到目标文件 /a/b/c/d/1.txt 相对路径： 不是以/开头的路径 特点：基于当前文件夹往后进行查找 cd /a/b/c/ d/1.txt\n特殊符号： .：代表当前目录，例如：./b/c/1.txt ..： 代表上一级目录 ../../../a.txt\n~: 代表的是当前登录用户的家目录 root----》/root 普通----》/home/用户名 [!NOTE] 补充： windows的文件夹不区分大小写 linux的文件夹区分大小写\n文件的种类\r对比windows系统，区分文件，用后缀名区分 a.txt # 文本文件 a.mp4 # 视频文件 a.jpg # 图片文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 ls -l -: 代表的是普通文件，包含文本文件、图片、视频 d：代表的是目录文件，本质就是文件夹 b: 代表的是block块设备文件，例如：ls -l /dev/sda 站在硬盘的角度最小读写单位是一个扇区 站在操作系统的角度最小的读写单位一个block块（默认是由8个扇区） l：代表的是软连接，就相当于windows系统中快捷方式 c 设备文件（字符设备）打印机，例如：终端/dev/tty1 s 套接字文件，例如：/run/chrony/chronyd.sock p 管道文件，例如：/run/systemd/initctl/fifo 1 file /etc/grub.conf Linux 各个目录的作用（⭐）\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 [root@aliyun ~]# ls -l / # /是所有linux操作系统的顶点目录,不像windows,每个分区都有一个顶点目录 total 64 #1、命令相关目录 lrwxrwxrwx. 1 root root 7 Jul 11 2019 bin -\u0026gt; usr/bin # 普通用户使用的命令如ls、date lrwxrwxrwx. 1 root root 8 Jul 11 2019 sbin -\u0026gt; usr/sbin # 管理员使用的命令 #2、启动目录 dr-xr-xr-x. 5 root root 4096 Feb 11 19:06 boot # 存放的启动相关的文件，例如kernel,grub(引导装载程序) #3、系统文件目录 drwxr-xr-x. 13 root root 4096 Jul 11 2019 usr # 系统文件，相当于C:\\Windows lrwxrwxrwx. 1 root root 7 Jul 11 2019 lib -\u0026gt; usr/lib # 库文件Glibc lrwxrwxrwx. 1 root root 9 Jul 11 2019 lib64 -\u0026gt; usr/lib64 # 库文件Glibc #4、用户家目录 drwxr-xr-x. 5 root root 4096 Feb 24 16:42 home # 普通用户家目录 dr-xr-x---. 11 root root 4096 Jul 8 17:03 root # root用户的HOME #5、配置文件目录 drwxr-xr-x. 79 root root 4096 Jul 8 17:04 etc # 配置文件，很重要，系统级服务配置文件都在这里 \u0026#34;\u0026#34;\u0026#34; /etc/sysconfig/network-script/，网络配置文件目录，具体的网卡配置文件rockylinux有变动 /etc/hostname，系统主机名配置文件 /etc/resolv.conf，dns客户端配置文件 /etc/hosts，本地域名解析配置文件 /etc/fstab 系统挂载目录 开机自启动挂载列表 /etc/passwd 系统用户文件 \u0026#34;\u0026#34;\u0026#34; #6、设备目录文件 drwxr-xr-x 19 root root 2960 Feb 15 17:22 dev # 设备文件，/dev/sda /dev/sr0 \u0026#34;\u0026#34;\u0026#34; /dev/cdrom 和/dev/sr0，系统光盘镜像设备 /dev/null，黑洞设备，只进不出。类似于垃圾回收站 /dev/random，生成随机数的设备 /dev/zero，能源源不断地产生数据，类似于取款机，随时随地取钱 /dev/pts/0，虚拟的Bash Shell终端,提供给远程用户使用 0代表第一个终端 1代表第2个终端 以此类推 /dev/stderr，错误输出 /dev/stdin，标准输入 /dev/stdout，标准输出 \u0026#34;\u0026#34;\u0026#34; #7、虚拟文件系统：类似于小汽车的仪表板，能够看到汽车是否有故障，或者是否缺油了。 dr-xr-xr-x 89 root root 0 Feb 15 17:22 proc # 虚拟的文件系统，反映出来的是内核，进程信息或实时状态 \u0026#34;\u0026#34;\u0026#34; 反映系统当前进程的实时状态 /proc/meminfo：内存信息 /proc/cpuinfo：cpu信息 \u0026#34;\u0026#34;\u0026#34; #8、可变的目录与临时目录 drwxr-xr-x. 19 root root 4096 Jul 11 2019 var #存放的是一些变化文件，比如数据库，日志，邮件.... \u0026#34;\u0026#34;\u0026#34; /tmp，系统临时目录(类似于公共厕所)，系统会定时删除该目录下长时间没有访问的文件。 /var，存放一些变化文件，如下 mysql: /var/lib/mysql vsftpd: /var/ftp mail: /var/spool/mail cron: /var/spool/cron log: /var/log 系统日志文件存放目录 /var/log/messages系统日志 /var/log/secure系统登录日志 /var/tmp 临时文件(主要是程序产生的临时文件) \u0026#34;\u0026#34;\u0026#34; #9、设备（主要指存储设备）挂载目录 drwxr-xr-x. 2 root root 4096 Apr 11 2018 media # 移动设备默认的挂载点 drwxr-xr-x. 2 root root 4096 Apr 11 2018 mnt # 手工挂载设备的挂载点 drwxr-xr-x. 2 root root 4096 Apr 11 2018 opt # 早期第三方厂商的软件存放的目录. drwxrwxrwt. 10 root root 4096 Jul 9 15:16 tmp # 临时存放文件，类似于回收站，超过十天自动删除 #10、了解（centos7中） drwx------. 2 root root 16384 Jul 11 2019 lost+found # 孤儿文件，rocklinux中没有 这个目录是使用标准的ext2/ext3档案系统格式才会产生的一个目录，目的在于当档案系统发生错误时， 将一些遗失的片段放置到这个目录下。这个目录通常会在分割槽的最顶层存在， 例如你加装一颗硬盘于/disk中，那在这个系统下就会自动产生一个这样的目录『/disk/lost+found lost+found这个目录一般情况下是空的，当系统非法关机后,如果你丢失了一些文件，在这里能找回来用来存放fsck过程中部分修复的文件的 lost+found：几乎每个被格式化过的Linux分区都会有，意外后找回的文件一般在这里面。 这个目录是储存发生意外后丢失的文件的。只有root用户才能打开 drwxrwxr-x 6 root root 4096 Feb 23 19:24 application drwxr-xr-x 25 root root 660 Jul 8 17:00 run # 存放程序运行后所产生的pid文件 drwxr-xr-x. 2 root root 4096 Apr 11 2018 srv # 物理设备产生的一些文件 dr-xr-xr-x 13 root root 0 Feb 16 01:22 sys # 硬件设备的驱动程序信息 远程连接工具\r服务器上安装服务端程序：openssh-server systemctl status sshd # 配置文件/etc/ssh/sshd_config syst emctl restart sshd # 重启会重新加载配置文件\n在个人电脑要按照一个ssh的客户端程序 ssh的客户端种类：\nwindows： 1、xshell 2、secureCRT 3、putty macOS： 本身就自带ssh客户端 xterm 文件管理相关命令\r基础命令\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 （1）查看当前所在的文件夹 pwd （2）切换目录 cd /etc/sysconfig cd /etc cd sysconfig cd . cd .. cd # 等同于 cd ~ cd - # 切换到上一次所在的文件夹 （3）查看目录层级结构 yum install tree -y tree tree -F # 针对目录会在结尾加/来表示 tree -a # 隐藏文件也会展示 tree -d # 只展示目录 tree -F -a -L 1 /tmp/ # 指定查看的层级 （4）ls 浏览命令 ls -l # 查看的是文件的元数据 ls -lh # 文件大小带着单位 ls -a # 可以查看到点开头的文件这种隐藏文件 ls -dl /tmp # 查看某个目录本身的元数据 ll # 等同于 ls -l --color=auto ls -l 查看出的各部分元数据的含义 1 2 [root@www ~]# ll /tmp/a.txt -rwxr-xr--. 1 root group 1 31457280 4 月 16 14:21 /tmp/a.txt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -：文件的类型 rw-r--r--：权限 .: 代表该文件是在开启selinux的情况下创建 setenforce 0 # 临时关闭selinux vi /etc/sysconfig/selinux # 永久关闭 修改： SELINUX=disabled getenforce 1: 硬链接数\troot: 属主 group1：属组\t31457280： 文件的大小\t4 月 16 14:21：文件的内容修改时间 modify time--》mtime /tmp/a.txt: 文件名 文件的三种时间（mtime、atime、ctime）\r修改时间（mtime, Modification Time） 访问时间（atime, Access Time） 变更时间（ctime, Change Time）\n1 2 3 4 5 stat /tmp/111. txt atime: 查看一次文件内容，atime就会变一次 mtime：文件内容改动，该时间才会变 ctime：文件元数据（权限、属主、属组变化）的变量、文件内容的变化，该时间都会变 文件管理命令\r1 、普通文件、目录文件\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 - 创建 （1）创建普通文件 注意：touch 创建的都是普通文件（包含、图片、视频、文本文件） touch /tmp/222. txt touch /tmp/1. jpg touch /tmp/1. mp 4 touch /tmp/{1..10}.txt touch /tmp/{a..c}.txt touch /tmp/Ego{n,N}.txt （2）创建目录 mkdir -p /tmp/a/b/c/d/e mkdir /tmp/mmm{1..3} - 复制 （1）复制普通文件 cp /etc/hosts /tmp/ 目标/tmp/hosts cp /etc/hosts /tmp/1.txt 目标/tmp/1.txt （2）复制目录 cp -r /etc /tmp cp -r /etc /tmp/xxx - 移动（剪切） (1) 移动普通文件 mv /a/b/c.txt /tmp/ mv /a/b/c.txt /tmp/b.txt （2）移动目录 同上（不需要加-r） （3）改名字 在同一个文件夹下面 mv a.txt b.txt - 删除 rm -rf /tmp/* 删除/tmp下所有的内容 2、文件内容如何操作（文本文件）\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cat /etc/hosts # 查看所有内容 less # 上下键翻页，输入 q 退出 more # 百分比 回车翻页 head -3 /etc/passwd # 查看头几行 tail -3 /etc/passwd # 查看末尾几行 ps aux | head -3 ps aux | tail -3 tail -f /var/log/messages # -f 可以动态查看文件新增的内容 echo 111 \u0026gt; /tmp/a.txt # 覆盖写 echo 111 \u0026gt;\u0026gt; /tmp/a.txt # 追加写 ","date":"2025-05-21T23:30:33+08:00","image":"https://bestoko.cc/p/linux-basics-2/linux_hu_50fb11894fe3fd8d.png","permalink":"https://bestoko.cc/p/linux-basics-2/","title":"Linux基础（二）：文件系统管理基础"},{"content":"Linux 系统构成\r从功能维度划分\r系统调用接口：为上层应用程序准备好的一系列可调用的接口\n内核：负责具体控制硬件的运行\n应用程序本身是无法操作硬件的，但凡想操作硬件都要给系统发请求\n操作系统的两种工作状态：\n用户态: 运行的系统接口代码在与应用程序打交道 内核态：运行的是系统的内核代码在与硬件打交道 从文件维度划分\r操作系统源自 iso 镜像文件，镜像文件本质就是一个压缩包，压缩里放着一系列的系统的文件 这些文件分为两大类：bootfs+rootfs\nBootfs（系统启动前） 包含启动文件（bootloader 程序，不是以文件的形式存在，是直接写入硬盘的第一个扇区/mbr）、内核文件 (/boot/vm\u0026hellip;) Rootfs（系统启动后） 本质就是一堆文件夹/文件 Linux 系统的启动顺序\r程序与进程 程序：就是一个或者一系列代码文件\u0026mdash;》静态 进程：就是一个程序的运行过程\u0026mdash;\u0026mdash;\u0026ndash;》动态\n进程代表的是程序的运行过程，而负责运行整个过程是操作系统，所以进程是操作系统的最核心的概念没有之一\n加电，先启动 bios Bios 负责找到启动盘 Bios 读取启动盘第一块扇区 mbr 主引导记录（放着的是 bootloder 程序）放入内存，让 cpu 来执行，bootloader 成功启动 Bootloader 启动之后，负责从硬盘中找到内核文件读入内存，并启动，此时操作系统就启动起来 操作系统启动起来负责管理一系列进程，这些进程可以分为两大类 内核先启动一个老祖宗程序，pid 为 0\n0号进程负责运行两个顶级程序，产生两个顶级的进程 运行 init 程序，pid 号为 1：是所有用户态进程的祖宗 运行 kthreadd 程序，pid 2：是所有内核态进程的祖宗\nLinux 系统启动级别\n0: 关机 poweroff. target 1:单用户模式 rescue.target 2:多用户模式(没有文件系统，没有网络) multi-user.target 3:多用户模式(命令行) multi-user.target 4:没有被使用 multi-user.target 5:图形化界面 graphical.target 6:重启 reboot.target init 0 关机 Shell 解释器介绍\r在默认启动级别为3的情况下，linux系统启动之后默认会启动一个 命令解释器铺满全屏幕给你去（称之为字符终端），只能在里面敲命令\nLinux系统中的命令解释器称之为shell，翻译为壳，表达了对系统接口封装的思想\n具体来说shell解释器分为很多种类，默认用的bash这种\nShell 交互式环境\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [ ]内各个部分的意思： 第一部分: 登录的用户名 第二部分@： 分割符 第三部分：主机名字 第四部分：当前所在的文件夹 ~： 代表当前用户的个人文件夹/家目录 root用户的家目录/root 普通用户的家目录/home/用户名 [ ]括号外： $ : 当前登录的用户身份是一个普通用户 \\# : 当前登录的用户身份是一个超级管理员 补充： useradd 用户名 passwd 用户名 # 交互式 echo \u0026#34;123\u0026#34; | passwd --stdin egon # 非交互式 Shell 脚本\r脚本就是一个简单的程序（整个程序就是一个文件） 把你执行某个任务需要的 10 条命令扔到一个文件里，该文件就是一个 shell 脚本\nShell 命令基本语法\rls -l /boot 三大组成部分：\nls 命令，代表要做什么事 -l 选项，控制命令具体怎么做（可选） /boot 参数，命令具体操作的目标（可选） bash 解释器交互式环境的一些特性/快捷方式\r1 2 3 4 5 6 7 8 9 10 11 12 ctrl+c: 强制终止当前命令的执行 ctrl+l：清屏，等同于clear命令 ctrl+a 光标移到命令行的最前端 ctrl+e 光标移到命令行的后端 history 查出命令的编号，然后!编号 history -c # 清空历史记录 上下箭头 查出历史命令 !$ # 取上一条命令的参数 tab 键补全 Shell 命令的种类和优先级\rShell 解析命令的顺序：\n带路径 \u0026gt; 别名 \u0026gt; 复合命令 \u0026gt; 函数 \u0026gt; 内置命令 \u0026gt; Hash 缓存 \u0026gt; PATH 查找\n带路径的命令\r绝对路径: 从根目录开始，例如 /bin/ls 相对路径: 相对于当前目录，例如 ./ls 或 b/c/1.txt . 表示当前目录，例如 ./b/c/1.txt 等同于 b/c/1.txt .. 表示上一级目录 别名 alias\r通过 alias 命令定义的快捷命令，优先级高于后续类型\n定义: alias xxx=\u0026quot;ls /etc/sysconfig/network-scripts;echo 123;echo 456\u0026quot; 取消: unalias xxx 复合命令 Compound Commands\r包含循环或条件语句的结构化命令。\n示例:\nfor((i=0;i\u0026lt;3;i++)); do echo 66666; done if 语句 函数 Function\r1 2 3 4 5 6 7 function f() { echo 111 echo 222 echo 333 } f #调用 内置命令 Built-in Commands\rShell 解释器内置的命令，例如 cd、pwd 查看类型: type cd（返回 cd is a shell builtin） hash 缓存\rShell 会缓存最近使用的命令路径到内存，提升下次执行效率。\n示例:\n查看: hash 清空: hash -r 环境变量 PATH\r环境变量：在系统任意位置都能访问到，是全局有效的变量\n当命令不带路径时，Shell 在 PATH 中的目录依次查找 （负责兜底）\nPATH 是一组用冒号分隔的目录，例如 /usr/bin:/bin\n示例:\n查看: echo $PATH 定义全局变量: export name=\u0026ldquo;egon\u0026rdquo; 想要不加前缀去调用自定义脚本 xxx 的方法\n方法一：把该脚本移动到 PATH 的某个文件夹下面 方法二：把该脚本所在的文件夹添加到PATH里 一些简单的常用命令\r设置主机名\n1 hostnamectl set-hostname aliyun #// 退出重新进入即可看到 设置默认启动级别\n1 2 systemctl set-default graphical.target # 图形界面 systemctl set-default multi-user.target # 字符终端 查看ip地址（设置ip地址会在网络配置章节里详细介绍）\n1 2 3 # 查看 ifconfig # rockylinux、ubunt都需要安装net-tools才能用ifconfi ifconfig eth0 # 也可以执行ip a show eth0 用date命令操作时间\n1 2 date --helpdate \u0026#34;+%Y_%m_%d %H-%M-%S\u0026#34; # 查看时间 date -s \u0026#34;2018-05-17 09:51:50\u0026#34; # 设置时间 两种时间 1、系统时间：我们刚刚用 date -s 设置的是系统时间 2、硬件时间：存在 CMOS 中，开机时会读入内存作为系统的初始时间 如果刚 date -s 设置完时系统立即崩溃，系统还没来得及将刚改的时间写入 CMOS 中，则本次设置无效为了解决了改问题，可以在 date -s 之后理解执行 hwclock –w 这个命令强制把系统时间写入 CMOS。\n","date":"2025-05-20T23:23:06+08:00","image":"https://bestoko.cc/p/linux-basics-1/linux_hu_50fb11894fe3fd8d.png","permalink":"https://bestoko.cc/p/linux-basics-1/","title":"Linux基础（一）：初识 Linux "},{"content":"契机\r首先我得承认去年的 wwdc 上 Apple Intelligence（Apple AI）画的大饼确实吸引了我，一直用一加玩机的我也不觉得在各家手机厂商都在积极拥抱ai的情况下，日后折腾的体验会比厂商调教的更顺手。虽然中文苹果智能真正落地兑现还是今年4月的事情，黑五有了优惠后就咬咬牙入了日版的16PM（当然是256G丐版 我可接受不了苹果比金子还贵的存储定价）。至今用了也差不多半年时间，也差不多不带偏见可以写写自己从 Android 换到 iOS 的感受了。\nAndroid\r先来谈谈Android吧。\n我的玩机历史大概要从高一时买的乐视 1手机才算开始。~~（贾老板下周回国吗？）~~应该是国内厂商中最早用type-c接口的了，可惜现在的舆论上被华为摘了桃子，意难平XD。乐视1的硬件在当时确实很好，可惜那个系统真的是难用，还有无法隐藏的自家视频入口。我就折腾起了刷机，后来在XDA上搜到了某人移植的魔趣 mokee rom。接触到魔趣这个差不多算国内 lineageOS 的项目，自然不可避免地去了解哪些手机容易解锁、包比较多。接着就是一加人一加魂，一加5-一加8-一加Ace2Pro，刷过MIUI、flyme各种官改移植，也玩过很多类原生毛坯房。也有大半夜救砖的黑历史。总的来说还是乐趣大于折腾的麻烦。\n这大概就是Android最大的优点了，开放性高，桌面、主题、文件管理等等都有非常多的可选项与调整的可能。再不济可以掀桌子（解锁）刷入别的系统，把手机一点点打造成自己最顺手最喜欢的样子。当然这个过程中最痛苦的是跟各种金融app斗智斗勇了（安全上不可调和的矛盾了属于是）。\n与此同时，在这么多年的过程中我也发现了自认为Android最大的缺点，那就是系统更新的维护性并不积极，甚至可以说是管生不管养。之前爆出的拼多多利用漏洞提权获取Android用户隐私的事，厂商的安全补丁推送却很慢，甚至小厂根本就没有。站在厂商的角度很好理解，东西已经卖出去了，为什么要花那么大力气去维护几年前的老机型，给个两三个大版本的更新推送你就该谢天谢地了。时至今日，某些厂商甚至还有云控恶意降低老机型流畅度来迫使用户换手机的做法，实在是无法接受。\niOS\r主力机换到 iOS 后，第一感觉是精致感。当然我说的不是硬件上的（PM这玩意板砖似的实在称不上有什么好的握持体验）。而是系统上的诸如解锁、打断动画、毛玻璃之类的小细节。尤其是图标，可能是安卓厂商很难去强迫应用去做到一个统一规范，用第三方图标包又难免有遗漏不全的地方，iOS的图标就明显顺眼很多。第二大惊喜的就是续航。本来最担心的是没有快充该怎么适应，结果实际用下来，WiFi 场景下省电情况超乎我的想象。在公司大部分时间都是WiFi的情况下，4800毫安时的苹果甚至可以做到一天一充，跟现在动辄六七千毫安时的国产安卓手机对比也不落下风了。接着就是老生常谈的AppStore了，切换外区商店，购买下载等等都一气呵成，还是很容易有个不错的下载体验的。\n当然我不是变成了luv letter那样的果吹。还是有些地方让我用起来觉得很不方便，或者说能理解为什么这么设计但还是不爽的地方。\n首先是完全不理解的，能做好但不去做的功能。没有一个统一的全局返回手势，Android 上全面屏手势已经基本统一，无论是左滑还是右滑，都可以很轻松的返回上一级菜单。而iOS让我无力吐槽，一部分app可以右滑返回，一部分只能点击左上角返回。右滑返回的体验也不好，如 bilibili 连续点了很多视频下去的话，右滑返回会直接回到首页而非上一个视频。左上角返回更是无力吐槽，那么大的板砖单手握持已经很不舒服了，给到小指很大压力，大拇指再费力去够到左上角实在是糟糕透了。本地化的缺失也是我狂喷的另一个点，再没有换过来之前，我很难想象iOS用户甚至没有官方的法定节假日闹钟。最后也是经典的信号问题，没想到我每天下楼时拿着手机会连不上网，同样的位置同样的手机卡，Android手机从来没有出现过这样的事。\n还有一些可能是因为隐私考虑而导致的不方便。我可以理解，也在尝试自适应。比如通话录音时的提醒音。又比如连续复制时，中途如果没有切换到输入法，是不会记录下来中间的复制文本的，只保留最后一次的结果。 还有通知栏与负一屏小组件状态同步不及时的小毛病。钱包也不能自由录入NFC卡片。没有长截屏等等。\n最后是这个半成品的apple ai，我该夸还是骂呢。有时候通知栏总结还是挺方便的，图片消除也凑合（是的凑合，可能是因为仅本地模型处理的原因）文本的概括也还行，写作我没有尝试，但大部分场景下也就那样吧，与画的智能Siri、多app联动的大饼差远了\u0026hellip;希望真的是未来可期吧: )\n总结\r总的来说体验不能算后悔，但也谈不上有符合预期。好的设计是趋同的，我还是希望iOS能多搬点好用的Android已经成熟的功能过来的。也让我意识到双持才是最好滴。PM已经这么大了，还是再收一台可以解锁的小屏安卓搭配着玩吧。\n","date":"2025-05-01T23:00:00+08:00","image":"https://bestoko.cc/p/androidios/Android2iOS_hu_a9eb156e3f781c6a.jpg","permalink":"https://bestoko.cc/p/androidios/","title":"主力机换到iOS的这半年"},{"content":"公司的网络最近经常抽风，逛小绿书无意间发现了三星有给日本运营商定制过一批随身WIFI，颜值特别高，遂入手配合联通副卡过渡使用。\n外观与配置\r(家附近联通基站信号不好，因此图上是4G，在公司5G使用顺畅)\n接着过一遍完整参数与支持的频段\nMediaTek Dimensity 720 (MT6853)\nAndroid 11 with OneUI 3.0 (w/o Google Play Services)\n2.5GB RAM\n32GB Internal Storage\nWiFi 5\n5000mAH Battery\n5.3\u0026quot; (1480x720) LCD Display\nNetwork bands:\n5G: n28 / n41 / n77 / n78\n4G: LTE FDD: B1 / B3 / B17 / B18 TDD: B41\nDisabled Bands that can be enabled:\n4G: B7 / B38\n其实相较于国内很多随身WiFi的配置，这个性价比并不高，但耐不住颜值戳中我，放着当个日历摆件也好看，黄鱼入手。\n解除SIM 锁 开启5G频段\r点击 关于 \u0026gt;\u0026gt; 状态 \u0026gt;\u0026gt; 手机号码，快速点击10次 点击 10 次，进入 DRParser Mode，此时依次输入 *#0011# 进入到 service mode，再次点击右上角，点击一次 back，再次点击 key input 这时输入 Q 并确认，在此界面等待大概一分钟后，会进入到主菜单界面 点击 [2] UE SETTING \u0026amp; INFO \u0026raquo; [1] SETTING \u0026raquo; [1] PROTOCOL \u0026raquo; [9] NR \u0026raquo; [2] allow list control \u0026raquo; [2] allow list off，显示 APPLY success， 右上角菜单，点击两次 back 回到上层目录，点击 [1]nr5g sa/nsa mode control \u0026raquo; [1] sa/nsa enable，按照提示重启设备 allow list off 即运营商锁，关掉之后我们才可以使用默认日本运营商之外的卡\nsa/nsa enable 默认disable，开启后则可以使用5G\n设置APN\r通信设置 \u0026gt;\u0026gt; APN 里 如图设置即可使用国内移动联通的卡上网。\n电信则需要安装第三方桌面，在安卓原生设置里设置更多APN 参数\n名称：ctlte apn：ctlte 用户名：ctwap@mycdma.cn 密码：vnet.mobi MCC：460 MNC：03 apn类型：* apn协议：IPV4\u0026amp;IPV6 apn漫游协议：IPV4\u0026amp;IPV6 使用感想\r耐用，耐用，还是tm的耐用！\n在阉割了很多不必要的硬件情况下（扬声器等），5000毫安时的电池真是太耐用了，我从上班到下班，一直连着2~3个设备的情况下，还能剩下30+%的电量，确实很舒服。\n看smzdm上的折腾里，能强解BL，但修补boot不能获取root权限，有点遗憾。原来还有想法搞个小猫咪上去，用root 后的VPN热点给一些设备爬墙来着。\n（等网络好了之后再出掉吧）\n","date":"2024-12-15T23:55:00+08:00","image":"https://bestoko.cc/p/scr01/SCR01_hu_8e94c8a6a6e9e63d.png","permalink":"https://bestoko.cc/p/scr01/","title":"三星 SCR01 入手简单折腾 "},{"content":"飞牛私有云\r最近 DIY NAS 圈飞牛私有云的热度很高（不排除很多是商单广告）。我大概看了看，虽然还只是 beta 版本，但基本功能的完成度已经很高了。文件存储、docker、影视、相册、应用中心都已经开箱即用了，另外还有比较方便的外网访问（据说后期会额外收费，或者免费版本限速）。最让我眼馋的还是飞牛的影视功能，我之前辛苦折腾的挂削组件，相互配合之间还老出点小毛病。不过主力NAS unraid 已经使用很久了，数据迁移实在麻烦，决定在上面用虚拟机的方式部署使用。\nUNraid FNOS VM 部署\r首先去官网下载最新的镜像文件 iso https://www.fnnas.com/download\n通过 smb 复制到unraid 的isos 共享文件夹\n接着新建一个 Linux 虚拟机，设置好所分配的 CPU 核心、内存、虚拟硬盘大小，OS INSTALL ISO 选择我们刚上传的系统镜像即可。\n这里我的闲置空间比较多，分配了100G 给 fnos，官方建议是64G 以上，可以根据自己硬件条件来设置。\n修改飞牛IP 挂载媒体库并配置影视应用\r一路按需设置即可，需要注意的是进系统设置的第一个账号默认为有 SSH 权限的且不可删除的管理员账号，DHCP 获取的 IP 地址不满意，可以进系统后手动指定。\n接着简单安装下影视应用，将unraid 里的影音库目录 挂载到飞牛OS，并共享给影视应用。\n进入影视，设置下自己目录对应的媒体分类，稍等片刻，即可挂削完毕\n可以看到飞牛的播放器完成度还是比较高的，个人感觉比 emby 和 jellyfin 的网页版易用点\n核显直通转码\runraid 下直通核显比较简单，首先去Tools - System Devices 找到并勾选核显，Bind selected to VFIO at Boot，并重启。\n接着将暂停飞牛虚拟机，将设置的显卡从 VNC 改成 你的核显重启虚拟机即可\n最后，在飞牛影视里 勾选启用 GPU 加速转码即可\n我们把手机上切成流量，模拟在外面访问家里的nas，需要转码的情况，可以看到已经成功驱动。\n简单总结\r飞牛OS 目前专业性功能还比不上老牌NAS系统如群晖等，但也已经有相对出色的影音体验，足以应对家用非专业用户的使用。安装简单不挑硬件，正版免费也是最大的优势，也许有一天能让黑群晖成为过去式，变成国产DIY NAS 首先推荐的系统。如果有一天我要拆开 unraid，进行存算分离，我可能会考虑买成品NAS或者实体机安装飞牛使用。\n","date":"2024-11-14T21:40:00+08:00","image":"https://bestoko.cc/p/fnos_unraid/FNOS_VM_install6_hu_16c55a139682275a.png","permalink":"https://bestoko.cc/p/fnos_unraid/","title":"Unraid 上部署飞牛OS虚拟机小记"},{"content":"最近在黄鱼捡垃圾时，发现一张散热改装深得我心的 Tesla P4 显卡，虽然已经溢价到598块（年前不带散热改装的还300不到来着T_T），还是拿下了，塞到自己小小的AIO主机里开始折腾，简单记录下在 unraid 上使用这张卡的记录\n简单介绍\rTesla P4 这种卡设计之初都是放到服务器用的，因此都没有设计主动散热，毕竟服务器暴力扇力大砖飞，轻轻松松带走发热。而我们垃圾佬拿来家用时就不得不权衡一下噪音与散热了，因此简单的改装是很有必要的。常见的改装方案是在原装散热器后方3D打印出一个涡轮风扇，显卡长度增加了一截不说，也实在说不上优雅。\n此外我最喜欢的方案是 B站 鸦无量 的替换3D打印盖板，增加3组风扇的散热改装套件了，详细的可以参考视频 BV1oZ421q7qn\n而我这次购入的则是卖家定制不锈钢外壳，纯铜底板铜板散热器，3组风扇的版本，拿在手里沉甸甸的，很有质感，因为已经装进NAS里了，拆装比较麻烦，这里就直接使用卖家的图展示了。\nUNraid 上安装驱动并配置\r首先需要安装 Nvidia-Driver 插件，可以自动检测当前设备上的 Nvidia 显卡并自动下载相应的驱动\n\u0026hellip;.\nPlease make sure to disable and enable Docker if you installed the Nvidia driver for the first time! Settings -\u0026gt;Docker -\u0026gt; Enable Docker \u0026lsquo;No\u0026rsquo; -\u0026gt; Apply -\u0026gt; Enable Docker \u0026lsquo;Yes\u0026rsquo; -\u0026gt; Apply plugin: nvidia-driver.plg installed\n参照安装成功的提示去设置里先停用docker ，再启用docker。\n然后我们打开 plugins - Nvidia Driver, 记录下我们的显卡编号，如图上的GPU-4220501a-f1b0-d74e-ec65-b17844258a75； 并将显卡驱动版本从默认的 latest version 改为 available version 之一，避免 unraid 重启时重新去检测并下载 Nvidia 显卡驱动，导致启动时间拉长甚至在网络环境不佳的情况下无法启动。\n视频转码配置（ jellyfin 为例）\r我们在 jellyfin docker配置额外参数（Extra Parameters）加上 --runtime=nvidia\n并添加两个变量 NVIDIA_VISIBLE_DEVICES 和 NVIDIA_DRIVER_CAPABILITIES , 值分别为上面配置时拿到的 GPU-XXXYYYZZZ 编号和 all\njellyfin - playback - transcoding 选择 Nvidia NVENC 保存并重新启动 docker，选择一个电影测试一下即可。\n这里我以 奥本海默 为例，可以看的已经成功转码播放，unraid 仪表盘也可以看到 P4 的使用情况（需安装 GPU Statistics 插件），以及在使用的APP jellyfin\nAI 画图\r选 P4 的一大原因自然是因为它 8 GB的显存，2560 个 CUDA 核心，不拿来狠狠地 AI 画图也是可惜了: )\nunraid 应用商店搜索 stable diffusion，goolashe/automatic1111-sd-webui 这个整合镜像简单设置下就可以开画了！\n我们将 Nvidia Visible Devices 参数的值填上之前获取的 GPU 编号启动即可\n默认第一次启动时会在 /data/models 目录下载一些配置所需的模型文件，小文件还好，Stable-diffusion 目录下的 Stable-diffusionv1-5-pruned-emaonly.safetensors 可能很难下得动。这时候你可以在docker 的log 里找到 https://huggingface.co/ 开头的模型下载链接，在下载器里将其替换成 https://hf-mirror.com/ （一个国内镜像，速度还是很快的），下载完手动转移到 /data/models/Stable-diffusion 即可，后期你也可以找些别的模型放到这里，webui刷新一下即可调用。\n万事俱备，我们来简单画张猫娘，这里我使用的模型是以前下载的 nordrin_v20\n正向提示词随便写几个 cat_ears,2_girls, cute, young, flowers\n反向提示词 bad hands （对 AI 画的手梁木了 XD）\nSampling method: DPM++2M，Schedule type: Karras ，其余默认，大概花了 17s 生成出来。生成的文件可以在 /output/txt2img里找到。\n此时在仪表盘也可以看到，P4的显存被吃满了。\n其他设置\r静音调整\r说实话，卖家这散热改装效果确实不错，就是声音有点太大了，三风扇满速时还是蛮吵的。于是我从PDD买了个小玩意，手动降速到满意的程度了，基本跟氦气盘读写时的声音差不多，也不怎么影响温度。旋钮在PCI挡板的位置，还是挺方便的\n省电调整\r当我们没有在使用这卡的时候，还是希望尽可能让它的待机功耗小一些的。这里提供一个网上找到的适用于 N卡的脚本，可以使用 user scirpt 插件，设置每小时启动一次。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #!/bin/bash # check for driver command -v nvidia-smi \u0026amp;\u0026gt; /dev/null || { echo \u0026gt;\u0026amp;2 \u0026#34;nvidia driver is not installed you will need to install this from community applications ... exiting.\u0026#34;; exit 1; } echo \u0026#34;Nvidia drivers are installed\u0026#34; echo echo \u0026#34;I can see these Nvidia gpus in your server\u0026#34; echo nvidia-smi --list-gpus echo echo \u0026#34;-------------------------------------------------------------\u0026#34; # set persistence mode for gpus ( When persistence mode is enabled the NVIDIA driver remains loaded even when no active processes, # stops modules being unloaded therefore stops settings changing when modules are reloaded nvidia-smi --persistence-mode=1 #query power state gpu_pstate=$(nvidia-smi --query-gpu=\u0026#34;pstate\u0026#34; --format=csv,noheader); #query running processes by pid using gpu gpupid=$(nvidia-smi --query-compute-apps=\u0026#34;pid\u0026#34; --format=csv,noheader); #check if pstate is zero and no processes are running by checking if any pid is in string if [ \u0026#34;$gpu_pstate\u0026#34; == \u0026#34;P0\u0026#34; ] \u0026amp;\u0026amp; [ -z \u0026#34;$gpupid\u0026#34; ]; then echo \u0026#34;No pid in string so no processes are running\u0026#34; fuser -kv /dev/nvidia* echo \u0026#34;Power state is\u0026#34; echo \u0026#34;$gpu_pstate\u0026#34; # show what power state is else echo \u0026#34;Power state is\u0026#34; echo \u0026#34;$gpu_pstate\u0026#34; # show what power state is fi echo echo \u0026#34;-------------------------------------------------------------\u0026#34; echo echo \u0026#34;Power draw is now\u0026#34; # Check current power draw of GPU nvidia-smi --query-gpu=power.draw --format=csv exit 总结\rTesla P4 虽然溢价不少，但是得益于免额外供电的设计，N卡的 cuda 生态，在 NAS 上的可玩性还是比较高的。\n后续我可能再折腾下 MTPhotos cuda 版本的人脸识别分类等应用，让这张老计算卡继续发光发热~\n","date":"2024-10-27T14:40:00+08:00","image":"https://bestoko.cc/p/teslap4_unraid/TeslaP4_hu_5b8f5f15bc8292b4.jpg","permalink":"https://bestoko.cc/p/teslap4_unraid/","title":"Tesla P4 Unraid 下折腾小记"},{"content":"前言\r三年以前，我用的手机是一加8，彼时经过一加5时期的瞎折腾，初入玩机大门。为方便自查也方便同我一样的小白使用方便，写过一篇\n《一加8的Android 11 折腾指南》 以为挂这里不会有什么人看，没想到竟然也帮到了不少人。\n时过境迁，三年时间过去了，玩机的方式也在不断变换，过去的教程已经不具备多少意义。恰逢一加发布了新的Ace2 Pro，参数方面我非常满意，立刻首发购入开刷。并将此间折腾稍作记录，希望也能对看到这篇文章的你有帮助。\n方向与工具的选择\r我们玩机大部分时间说的指的是使用各种 xposed 模块对不同应用和系统进行修改，达到自己想要的目的。\n在之前我们使用的是 EdXposed 框架，而现在因为种种原因，我们选择更为主流更为先进的 LSPosed 框架\n另外不同于之前我们选择的 Magisk 接管 Root 权限，这次我们选择 KernelSU！\nKernelSU 是 Android GKI 设备的 root 解决方案，它工作在内核模式，并直接在内核空间中为用户空间应用程序授予 root 权限。\n你只需要知道相较于 Magisk 而言，选择 kernelSU 可以大大减少你与app（例如各种银行）斗智斗勇的时间。\n当前就目前使用而言，Magisk delta版本（俗称 狐狸面具🦊） 搭配 shamiko 白名单的情况也基本没什么问题。\n总之，这里就看你个人喜好了。\nKernelSU，启动！\rKernelSU的刷入方式也有很多种，这里我就使用相对不容易出错的一种，方便新手参考。（虽然有点曲线救国）\n大概流程是通过 Magisk 获取 Root 权限后使用内核刷写器刷入 KernelSU 的 AnyKernel 包。 最后再卸载magisk即可\n首先是解锁 bootloader，刷入 magisk ​\t新手可以直接用 @大侠阿木 的 一加全能盒子 解锁及刷入都可以按提示一键完成\n​\t老手可以选择用一加11的 TWRP（同为骁龙8Gen2通用），adb sideload的方式刷入magisk.zip\n​\t（当然这一步刷了 TWRP 后也可以直接在TWRP里刷入对应 AK3 压缩包，直接刷入KernelSU）\n​\t我偷懒这边就直接用盒子一键解锁一键刷入 Magisk 了\n安装 KernelFlasher 并赋予 Root 权限\n在已挂载槽位，点击刷入AK3压缩包，刷入对应的Anykernel3.zip即可。\n一加Ace2 Pro请选择 AnyKernel3-android13-5.15.74 开头的zip\n别的机型请在安装kernelSU apk后查看内核版本，来确定你需要下载的AK3压缩包\nReleases · tiann/KernelSU (github.com)\n接着在KernelSU里 刷入【Zygisk on KernelSU 】和【Zygisk -LSposed】，【shamiko】（可选）\n重启打开 LSPosed ，安装想要的模块即可。\n需要注意的是，部分模块仅仅选好作用域可能无效，需要在 KernelSU 的超级用户页 对作用域的APP 开启Root Profile\nenjoy it\n我使用的部分模块截图\r文中提及资源分享（含9008已授权工具及救砖包）\r链接：https://pan.baidu.com/s/1w1irNJf6ZsCVuSqR3YR6Lg?pwd=toko 提取码：toko\n9008工具来自酷安@秋水105 【理论上一加11 、一加Ace2 Pro 、oppo find x6 pro、realme GT5 通用】\n救砖包来自@大侠阿木\n","date":"2023-08-31T10:10:01+08:00","image":"https://bestoko.cc/p/oneplus_ace2_pro/oneplus-new-logo-scaled_hu_eb45f9453643f585.jpg","permalink":"https://bestoko.cc/p/oneplus_ace2_pro/","title":"2023年该如何愉快的玩机 (一加Ace2 Pro为例)"},{"content":"自从折腾了自组 NAS 后，顺理成章的也入了 PT 的坑，虽然多数时候只要下载保种就完事了，但是遇到了某审核严格的站点（避嫌不说名字了，特色是漫画与轻小说，审核会删除拔作与撞车种子），手动去一个个到 qBittorrent 里挑出来也太麻烦了。\n我才注册了几个月就收到一大堆删种站内信，该说不说，管理也太尽职尽责了\u0026hellip;\n被站点删除的种子在 qBittorrent 里与正常种子不会有什么不同，只有点进去才能看到 torrent not registered with this tracker 字样，Transmission 则会把所有红种、警告标记出来。我去查解决方法的时候甚至看到有说用 IYUU 转种到 Transmission 的建议\u0026hellip;只能说几千多个种子，转完再重新校验，实在有些“不够优雅”\u0026hellip;\n其实，只需要在 qBittorrent 右键列标题，添加tracker 筛选框，并排序即可。被站点删除的种子 tracker 栏是空白，即可批量选中并移除。\n2024.10.10 更新：\n后来发现个更好用的 webui 油猴脚本来标记tracker出错的种子：\nhttps://greasyfork.org/zh-CN/scripts/473088-qb-webui-%E6%A0%87%E8%AE%B0tracker%E5%BC%82%E5%B8%B8\n","date":"2023-06-07T22:42:16+08:00","image":"https://bestoko.cc/p/qbittorrenttips/qBittorrent_hu_d3e09a6691bc74c9.jpg","permalink":"https://bestoko.cc/p/qbittorrenttips/","title":"qBittorrent 批量清理被PT站点删除的种子"},{"content":"你也许在很多书籍影视或者游戏中早已接触过无线电，但是真正亲身在现实中拿起对讲机与别人通联，则另有一番乐趣。\n我大概是在去年在某硬件群内了解到业余无线电以及考证相关的内容，而最近又被一个介绍《我们生活在南京》这本科幻小说的视频勾起了兴趣，赶上南京2023年度第一次业余无线电操作能力考试，3.18考完试，3月24日实体双证都拿到手了，也算是比较快的“速通”了，在此记录一下其中的坑点与技巧。\n概览\r首先要知道的是，想要合法通联，你需要准备的东西有\n业余无线电操作证 符合国家技术标准的无线电发射设备 无线电台执照与呼号 其中，3可以在准备好1和2的情况下，填写 《业余无线电台技术资料申报表》与 《业余无线电台设置(变更)申请表》向当地工信部申请获得，而2的话，一般只需注意买的设备要有核准码即可（可在智谱app查询），因此重点在于通过考试拿到业余无线电操作证。\n而业余无线电操作证分为ABC三个等级，A级最低，C级最高，等级高低影响操作员获准使用的频段和最大功率。操作证只能按A，B，C顺序依次取得。我这次取得的就是A级，购买的设备是泉盛的 UV-K5（性价比很高，推荐入门使用）\n报名\r如果你只对收讯感兴趣，对通联并不感冒，你可以考虑玩软件无线电或者面向无线电爱好者的收音机（例如德生）,并不需要报名考试。\n报名方式分为两种, 这里我选择的是手机APP的方式 小技巧：如果近期没有你所在城市的场次，你可以随便选择一场考试报名，将信息全部填写完成，所需照片和证件上传完成点击保存。这样当你需要报名的生活就可以省去重复填写资料的时间。 ！！某种意义上说，A类考试最难的就是抢到报名资格XD\n（1）网页报名：登录CRAC官网www.crac.org.cn，页面底部右下方选择“能力验证”，选择“考生入口”，进入“业余无线电台操作技术能力验证考核报名及信息管理系统”进行注册报名。\n（2）手机APP报名：应用市场下载“智谱”APP，从手机下方的“特别入口”进入，点击“考试报名”，选择相应的考试场次进行报名。\n考试\r试题范围为中国无线电协会业余无线电工作委员会（CRAC）公布的题库。\n你可以选择按照官方的指南在“业余无线电台操作技术能力验证及信息管理系统”的“资料下载”模块，下载安装“模拟考试软件”或TXT格式题库包，或者在“智谱”APP的“业余无线电移动信息平台”，进行复习和模拟考试。当然也可以像我一样使用更方便的微信小程序刷题，这里我推荐的是业余无线电工具集 或者 HAM模拟考试\n当然，如果嫌单纯的刷题太过枯燥，需要一些记忆方法的话，这里推荐长沙一位前辈（B站@长沙李折腾）的视频，里面有不少应试技巧与口诀，幽默诙谐容易记住。 考试当天一般都是只有一次机会，时间非常充裕，请务必认真答题不要浪费宝贵的报名资格\n设台\r不同地区的规定不同，南京这边考试现场为考试合格考生提供25W以下业余无线电台验机服务，当然也可以选择改日单独送去验机，具体看当地规定。需要注意的是一定要从正规渠道购买有核准码的机型，群里见到有因为买到问题批次的机器没有通过验机的朋友，验机现场也有因为机身上没有核准码标签而差点被拒的朋友。\n一切准备妥当后，到设台当地工信部提交好证明等待即可。首次设台时，管局会给分配一个全球唯一的呼号，这个呼号会伴随你的整个业余无线电生涯。（呼号一般不可自选，但据考试群友反馈某些地方线下办理允许自选一位，有想法的可以线下去问）\n最后\r希望你能够玩得开心，这里是BD4UTT 期待与您空中相遇 73\n","date":"2023-03-25T23:31:05+08:00","image":"https://bestoko.cc/p/amateurradio/wuxiandian_hu_bbf81af4c276b23.jpg","permalink":"https://bestoko.cc/p/amateurradio/","title":"业余无线电拿证(A类)\u0026设台速通指北"},{"content":"OpenAI家的chatGPT 最近的火热不必多说，还有很多墙内的小伙伴由于种种原因不能很方便地使用，正巧我最近在折腾在 NAS 上部署 QQ 机器人，找到一个很方便的将 ChatGPT 接入 QQ 机器人的插件。\n事前准备\r你需要准备：\nkoishi koishi是一个高性能的机器人服务，你可以在官网任选一个合适的方式部署（Windows/macOS/Linux/Android/容器） chatGPT API key 你可以通过 https://platform.openai.com/account/api-keys 获取 （注册openAI 账号的方法不在本文介绍 事实上随便找个国外的接码平台就可以了） 一个 QQ 小号，等级尽可能高一点以免风控 （koishi 事实上支持包括 QQ/discord/telegram/kook/feishu等的部署） 下面，我将在我自己的 NAS 上通过 koishi 容器的方式进行操作，我的 NAS 系统是 unraid 6.11.5 （ Linux 内核 5.19.17）\n操作部署\runraid docker 部署 koishi\r也可通过 unraid 的 docker 配置，具体如下\n在 unraid 上使用推荐后面一种方法，方便设置图标（看着更舒服一点） 效果如下:\nkoishi 以及 chatGPT 插件的配置\r按照你的 QQ 小号设置 adapter-onebot ，设置完后右上角找到启用插件。需要注意的是 protocol 需要选择 ws-reverse。\n接着去插件市场安装 koishi_chatGPT 插件根据提示加载 cache 服务并配置 apiKey ：\napikey 可以在 https://platform.openai.com/account/api-keys 获取。\n然后启用插件\nEnjoy it\r接下来 你就可以和群友们一起好好提(调)问(教) ChatGPT 了 XD\n20220305补充：\n请尽可能的在可信任的朋友的群里使用，我的群友们疑似因为提问了太多不能碰的滑梯，两天用完了免费的 18$ 余额，第三天群也炸了 \u0026hellip;\n","date":"2023-03-01T21:30:00+08:00","image":"https://bestoko.cc/p/koishi-chatgpt/KoishiJS_hu_8b824de320d445d6.png","permalink":"https://bestoko.cc/p/koishi-chatgpt/","title":"从零开始拥有一个属于自己的 ChatGPT QQ机器人"},{"content":"问题\r​\t最近我想用 Windows11 WSL2 上的 Ubuntu 20.04 来折腾我写博客用的 hugo 环境，发现执行 hugo server后并不能在主机的 localhost:1313 成功预览（尽管微软的文档里说的是可以:sweat:）\n一番折腾后找到了解决方法，在 WSL2 别的 Linux 发行版应该也适用\n解决方法\r首先获取 WSL 2 Ubuntu host 的 ip 地址\n1 ipconfig 我这里获取到的是 172.20.3.63\n然后在 hugo 目录下执行\n1 hugo server --bind 172.20.3.63 --baseURL=http://172.20.3.63 接着 Windows 主机的浏览器就可以通过访问 172.20.3.63:1313 成功预览了\n","date":"2022-12-10T23:25:00+08:00","image":"https://bestoko.cc/p/hugo_wsl2/WSL2_hu_85b2e192fc0ffe28.png","permalink":"https://bestoko.cc/p/hugo_wsl2/","title":"Windows11 WSL2 下配置 hugo 环境踩坑 "},{"content":"将下面的代码保存为kernel.py, 加入可执行权限， 执行./kernel.py -i kernel_log -o kernel.txt , 打开kernel.txt 就可以看到（与android logcat -v time一样的）时间戳\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 import time import datetime import sys import getopt import os a_time = None s_second = None s_microsecone = None abs_time = 0.0 inputfile = None outputfile = None def usage(): print(\u0026#39;\u0026#39;\u0026#39;Help Information: -h, --help: Show help information -i, --inputfile: input file to parse -o, --outputfile: output file parsed \u0026#39;\u0026#39;\u0026#39;) def calc_delta(stream): global s_second global s_microsecond global a_time global outfile begin_index = None end_index = None delta_second = 0 delta_mircosecond = 0 delta_time = 0 d_time = None new_line = None if a_time ==None: print(\u0026#34;Can\u0026#39;t convert to android time\u0026#34;) exit(-1) for line in stream: if line: try: begin_index = line.index(\u0026#39;[\u0026#39;) end_index = line[begin_index+1:].index(\u0026#39;]\u0026#39;)+begin_index+1 time_string = line[begin_index + 1 :end_index] [d_second,d_microsecond] = time_string.split(\u0026#39;.\u0026#39;) delta_second = int(int(d_second) - int(s_second)) delta_microsecond = int(int(d_microsecond)-int(s_microsecond)) delta_time = datetime.timedelta(seconds=delta_second,microseconds=delta_microsecond) d_time = a_time + delta_time new_line = d_time.strftime(\u0026#34;%m-%d %H:%M:%S.%f\u0026#34;)+\u0026#39; \u0026#39; + line outputfile.write(new_line) except: outputfile.write(line) def get_atime(stream): global s_second global s_microsecond global a_time a_time_op = None begin_index = None end_index = None for line in stream: if line: a_time_op = line.find(\u0026#39;android time\u0026#39;) if a_time_op\u0026gt;=1: begin_index = line.index(\u0026#39;[\u0026#39;) end_index = line[begin_index+1:].index(\u0026#39;]\u0026#39;)+begin_index+1 date_string = line[a_time_op+13:].strip() abs_time = line[begin_index + 1 :end_index] [s_second,s_microsecond] = abs_time.split(\u0026#39;.\u0026#39;) a_time = datetime.datetime.strptime(date_string, \u0026#34;%Y-%m-%d %H:%M:%S.%f\u0026#34;) break def main(argv): global inputfile global outputfile inputpath = None outputpath = None try: opts, args = getopt.getopt(argv,\u0026#34;hi:o:\u0026#34;,[\u0026#34;help\u0026#34;,\u0026#34;inputfile=\u0026#34;,\u0026#34;outputfile=\u0026#34;]) except getopt.GetoptError: usage() sys.exit(2) for opt, arg in opts: if opt in (\u0026#34;-h\u0026#34;, \u0026#34;--help\u0026#34;): usage() sys.exit() if opt in (\u0026#34;-i\u0026#34;, \u0026#34;--inputfile\u0026#34;): inputpath = arg if opt in (\u0026#34;-o\u0026#34;, \u0026#34;outputfile\u0026#34;): outputpath = arg if inputpath == None: usage() sys.exit() if outputpath == None: outputpath = os.getcwd()+\u0026#34;/out.txt\u0026#34; inputfile = open(inputpath, \u0026#39;r\u0026#39;) outputfile = open(outputpath, \u0026#39;w\u0026#39;) get_atime(inputfile) inputfile.seek(0) calc_delta(inputfile) inputfile.close() outputfile.close() if __name__ == \u0026#34;__main__\u0026#34;: main(sys.argv[1:]) ","date":"2022-06-22T23:00:00+08:00","image":"https://bestoko.cc/p/kernellogaddtime/Linux-Kernel_hu_18640eab2a9d5664.jpg","permalink":"https://bestoko.cc/p/kernellogaddtime/","title":"为Android Kernel Log添加时间戳"},{"content":" Camera 相关模块 代码路径 CameraService frameworks/av/services/camera/libcameraservice/CameraService.cpp CameraHALServer mtkcam3/main/hal/service/service.cpp ICameraProvider mtkcam/main/hal/devicemgr/provider/2.4/CameraProviderImpl.cpp ICameraDevice mtkcam3/main/hal/device/3.x/device/CameraDevice3Impl.cpp ICameraDeviceSession mtkcam3/main/hal/device/3.x/device/CameraDevice3SessionImpl.cpp CameraDeviceManager mtkcam3/main/hal/devicemgr/base/CameraDeviceManagerBase.cpp AppStreamMgr mtkcam3/main/hal/device/3.x/app/AppStreamMgr.cpp PipelineModel mtkcam3/pipeline/model/PipelineModelImpl.cpp CameraSetting mtkcam/middleware/v3/pipeline/CameraSetting/CameraSettingMgr_Imp.cpp MetadataProvider mtkcam/utils/metastore/metadataprovider/MetadataProvider.cpp StreamBuffer mtkcam/pipeline/utils/streambuf/StreamBuffers.cpp Hardware Node mtkcam3/pipeline/hwnode/ FeaturePipe mtkcam3/feature/core/featurePipe/ Pipe Driver mtkcam/drv/src/isp/isp_6s/imageio/pipe Sensor Driver \u0026lt;kernel-x.xx\u0026gt;/drivers/misc/mediatek/imgsensor/src/ EEPROM Driver \u0026lt;kernel-x.xx\u0026gt;/drivers/misc/eeprom/eeprom.c ","date":"2022-06-15T20:00:00+08:00","image":"https://bestoko.cc/p/mtkcamerahal3modules/HAL3_hu_45b5fcfa6bd7e3c9.png","permalink":"https://bestoko.cc/p/mtkcamerahal3modules/","title":"MTK 平台 Camera HAL3 相关模块的代码路径"},{"content":"Ubuntu 20.04如果安装时默认选择英文，使用时会发现在浏览器或者 gedit 等界面上出现部分汉字显示不正常，比如“关”和“复”显示偏小，“门”字中间有一点，如下图：\n其实是因为 CJK 字体日语默认的优先级比较高，这些字显示的是日文字体，解决方法如下：\n1 vim /etc/fonts/conf.d/64-language-selector-prefer.conf 原文件内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE fontconfig SYSTEM \u0026#34;fonts.dtd\u0026#34;\u0026gt; \u0026lt;fontconfig\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;sans-serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK KR\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK HK\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Lohit Devanagari\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK KR\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Lohit Devanagari\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;monospace\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK KR\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK HK\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;/fontconfig\u0026gt; 更改后内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE fontconfig SYSTEM \u0026#34;fonts.dtd\u0026#34;\u0026gt; \u0026lt;fontconfig\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;sans-serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK HK\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK KR\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Lohit Devanagari\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK KR\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Lohit Devanagari\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;monospace\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK HK\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK KR\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;/fontconfig\u0026gt; 效果：\n","date":"2022-05-21T10:30:00+08:00","image":"https://bestoko.cc/p/linux-fonts-size/ubuntu-logo_hu_30356caab35ee7af.png","permalink":"https://bestoko.cc/p/linux-fonts-size/","title":"Ubuntu 20.04 英文环境部分中文字体异形解决方案"},{"content":"​\t对 Linux 用户来说, 一个美观方便的终端可以提高很多工作效率.我所推荐的终端方案是 zsh + oh-my-zsh + Powerlevel10k ,兼顾美观与高效. 我所在的公司开发环境是 Ubuntu 20.04 , 本文就以这此发行版为例进行配置.\nZsh\r安装 zsh\n1 sudo apt install zsh 将 zsh 设置为默认 shell\n1 chsh -s /bin/zsh 你可以用echo $SHELL 指令来查看当前的默认 shell 是否修改成功.\noh-my-zsh\r安装 oh-my-zsh\n1 sh -c \u0026#34;$(curl -fsSL https://gitee.com/shmhlsy/oh-my-zsh-install.sh/raw/master/install.sh)\u0026#34; 安装一些实用插件\n1 2 3 4 5 6 7 8 #自动补齐 git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh}/plugins/zsh-autosuggestions #语法高亮 git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh}/plugins/zsh-syntax-highlighting #自动跳转 sudo apt-get install autojump 配置插件\n1 2 3 4 5 6 7 8 9 10 vim ~/.zshrc #在 plugins 行添加插件名,如: plusgins=(git zsh-autosuggestions zsh-syntax-highlighting) #最后一行添加 . /usr/share/autojump/autojump.sh #使配置生效 source ~/.zshrc Powerlevel10k\r安装 Powerlevel10k\n1 git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k 配置\n1 2 3 vim ~/.zshrc #修改 ZSH_THEME=\u0026#34;powerlevel10k/powerlevel10k\u0026#34; source ~/.zshrc 安装字体 (便于显示各种特殊符号和图表)\n[MesloLGS NF Regular.ttf](https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS NF Regular.ttf) [MesloLGS NF Bold.ttf](https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS NF Bold.ttf) [MesloLGS NF Italic.ttf](https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS NF Italic.ttf) [MesloLGS NF Bold Italic.ttf](https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS NF Bold Italic.ttf) 最后启动终端跟着向导配置,或者 p10k configure 就可以完成配置了.\n","date":"2022-03-08T20:56:36+08:00","image":"https://bestoko.cc/p/zsh/prompt-styles-high-contrast_hu_d9bc8f6e7e41ac09.png","permalink":"https://bestoko.cc/p/zsh/","title":"Ubuntu 20.04 终端插件配置与美化"},{"content":"自用的电脑是Arch Linux和windows10双系统, 今天想着把win10抹掉装win11, 装完后从grub引导界面无法进入windows, 才想起来忘记考虑引导的事情了.\n下面给出一个简单的解决办法:\n1 sudo pacman -S prober 安装 os-prober , 这个工具可以帮助自动发现包含windows的分区\n(如果你的windows分区启用了bitlocker, 你可能还需要先使用dislocker)\n接着:\n1 sudo grub-mkconfig -o /boot/grub/grub.cfg 利用 grub-mkconfig 探测其他已经安装的系统并自动把他们添加到启动菜单.\n如果你得到以下输出：Warning: os-prober will not be executed to detect other bootable partitions，你需要编辑/etc/default/grub并取消下面这一行的注释，如果没有相应注释的话就在文件末尾添加上：\n1 GRUB_DISABLE_OS_PROBER=false ","date":"2022-03-05T19:19:15+08:00","image":"https://bestoko.cc/p/grubfix/fix-grub_hu_275c2eaffdc7ba44.jpg","permalink":"https://bestoko.cc/p/grubfix/","title":"Arch Linux与Win11双系统修复grub引导"},{"content":"平台架构\rhttps://developer.android.com/guide/platform?hl=zh-cn\n从下到上依次分为：\nLinux内核层 硬件抽象层 HAL 系统运行库层 Java API 框架 系统应用 每一层都包含大量的子模块或子系统。\nLinux内核层 (Linux Kernel)\rAndroid 平台的基础是 Linux 内核。例如，Android Runtime (ART) 依靠 Linux 内核来执行底层功能，例如线程和低层内存管理。\n使用 Linux 内核可让 Android 利用主要安全功能，并且允许设备制造商为著名的内核开发硬件驱动程序。\nAndroid平台以Linux内核为基础，避开了直接与硬件打交道，为驱动开发提供了高度扩展性和易用性，大大降低了 Android 系统移植工作的难度。\n硬件抽象层 (Hardware Abstract Layer,HAL)\r硬件抽象层 (HAL) 提供标准界面，向更高级别的 Java API 框架显示设备硬件功能。HAL 包含多个库模块，其中每个模块都为特定类型的硬件组件实现一个界面，例如相机或蓝牙模块。当框架 API 要求访问设备硬件时，Android 系统将为该硬件组件加载库模块。\nLinux内核层与HAL层共同实现了对硬件的支持。其中HAL层运行在用户空间(User Space)，而Linux内核驱动程序运行在内核空间(Kernel Space)。为什么不把它们整合起来放到内核空间呢？技术角度是可以实现的，然而商业角度上会损害硬件厂商的利益。Linux内核源代码版权遵循GNU License(发布产品时必须公布源代码)，而Android源代码版权遵循Apache License(发布产品时无须公布源代码)。\n也就是说，Android放在内核空间的驱动程序对硬件的支持是不完整的，因此被踢出Linux内核主线代码树。\n系统运行库层\r这一层中包含了支撑整个系统正常运行的基础库，由系统类库和Android运行时组成。由于这些库多数由C/C++实现，因此也被一些开发人员称为“C库层”，以区别应用程序框架层。\n原生 C/C++ 库 (Native C/C++ Libraries)\r许多核心 Android 系统组件和服务(例如 ART 和 HAL)构建自原生代码，需要以 C 和 C++ 编写的原生库。Android 平台提供 Java 框架 API 以向应用显示其中部分原生库的功能。例如，您可以通过 Android 框架的 Java OpenGL API 访问 OpenGL ES，以支持在应用中绘制和操作 2D 和 3D 图形。\n如果开发的是需要 C 或 C++ 代码的应用，可以使用 Android NDK 直接从原生代码访问某些原生平台库。\n名称 简介 Webkit 一个开源的Web浏览器引擎 OpenMAX AL 一个不需要授权、跨平台的软件抽象层，以C语言实现的软件接口，用来处理多媒体。 Libc Linux下的ANSI C的函数库 Media Framework 基于PacketVideo的OpenCORE的多媒体库，支持多种常见音视频格式的录制和播放 OpenGL ES 免授权费的，跨平台的，功能完善的2D和3D图形应用程序接口API，主要针对多种嵌入式系统专门设计 Android运行时 (Android Runtime)\r对于运行 Android 5.0(API 级别 21)或更高版本的设备，每个应用都在其自己的进程中运行，并且有其自己的 Android Runtime (ART) 实例。ART 编写为通过执行 DEX 文件在低内存设备上运行多个虚拟机，DEX 文件是一种专为 Android 设计的字节码格式，经过优化，使用的内存很少。编译工具链(例如 Jack)将 Java 源代码编译为 DEX 字节码，使其可在 Android 平台上运行。\nART 的部分主要功能包括：\n预先 (AOT) 和即时 (JIT) 编译\n优化的垃圾回收 (GC)\n在 Android 9(API 级别 28)及更高版本的系统中，支持将应用软件包中的 Dalvik Executable 格式 (DEX) 文件转换为更紧凑的机器代码。\n更好的调试支持，包括专用采样分析器、详细的诊断异常和崩溃报告，并且能够设置观察点以监控特定字段\n在 Android 版本 5.0(API 级别 21)之前，Dalvik 是 Android Runtime。如果您的应用在 ART 上运行效果很好，那么它应该也可在 Dalvik 上运行，但反过来不一定。\nAndroid 还包含一套核心运行时库，可提供 Java API 框架所使用的 Java 编程语言中的大部分功能，包括一些 Java 8 语言功能。\nJava API 框架 (Java API Framework)\r您可通过以 Java 语言编写的 API 使用 Android OS 的整个功能集。这些 API 形成创建 Android 应用所需的构建块，它们可简化核心模块化系统组件和服务的重复使用，包括以下组件和服务：\n丰富、可扩展的视图系统，可用以构建应用的 UI，包括列表、网格、文本框、按钮甚至可嵌入的网络浏览器 资源管理器，用于访问非代码资源，例如本地化的字符串、图形和布局文件 通知管理器，可让所有应用在状态栏中显示自定义提醒 Activity 管理器，用于管理应用的生命周期，提供常见的导航返回栈 内容提供程序，可让应用访问其他应用(例如“联系人”应用)中的数据或者共享其自己的数据 开发者可以完全访问 Android 系统应用使用的框架 API。\n与\u0026quot;C库层\u0026quot;对应，这一层往往被称作“Java库层”。一方面为上层应用层提供API接口，另一方面也是不少系统级服务进程的实现，是与Android应用开发者关系最直接的一层。提供了开发Android应用程序所需的一系列类库，高度封装直接调用。应用框架层的主要实现代码在frameworks/base和frameworks/av目录下。\n系统应用 (System Apps)\rAndroid 随附一套用于电子邮件、短信、日历、互联网浏览和联系人等的核心应用。平台随附的应用与用户可以选择安装的应用一样，没有特殊状态。因此第三方应用可成为用户的默认网络浏览器、短信 Messenger 甚至默认键盘(有一些例外，例如系统的“设置”应用)。\n系统应用可用作用户的应用，以及提供开发者可从其自己的应用访问的主要功能。例如，如果您的应用要发短信，您无需自己构建该功能，可以改为调用已安装的短信应用向您指定的接收者发送消息。\n源码根目录中的packages目录对应着系统应用，其中：\napps 核心应用程序 experimental 第三方应用程序 inputmethods 输入法目录 providers 内容提供者目录 screensavers 屏幕保护 services 通信服务 wallpaper 墙纸 ","date":"2022-03-03T20:00:00+08:00","image":"https://bestoko.cc/p/android-framework/android-logo_hu_28eaa7806da7ed9b.png","permalink":"https://bestoko.cc/p/android-framework/","title":"Android平台架构学习笔记"},{"content":"在extensions.gnome.org上找到个农历扩展Lunar Calendar 农历，直接安装会因为缺少依赖报错，搜到的rpm包也无法正常安装，查了下需要手动编译安装lunar-date。\nFedora35 编译安装lunar-date\rgithub页给的安装指南如下\n1 2 3 meson build --prefix /usr -Ddocs=true -Dintrospection=true -Dvapi=true -Dtests=true ninja -C build/ sudo ninja -C build install meson是用Python语言开发的构建工具，编译需要Ninja（用C++实现）命令。\n所以首先\n1 sudo dnf install meson ninja-build 接着运行指南上第一条指令，如果有依赖缺失会报错，但是提示的依赖名称不能直接用于dnf install,可以在command-not-found.com 查询所需安装指令。以我为例：\n1 sudo dnf install vala gtk-doc 接着重新安装插件就可以正常启用了。\n额外可选设置\r默认情况下当系统语言为中文时扩展可以正常工作，但是像我一样习惯系统语言用英文的话，农历会以拼音形式标注出来（真的很难看），解决办法如下：\n1 cp /usr/share/locale/zh_CN/LC_MESSAGES/lunar-date.mo /usr/share/locale/en_US/LC_MESSAGES/lunar-date.mo ","date":"2021-12-30T09:18:46+08:00","image":"https://bestoko.cc/p/gnome-lunar-calendar/calendar_hu_bc4ab99d8e35ceca.png","permalink":"https://bestoko.cc/p/gnome-lunar-calendar/","title":"Gnome农历插件安装踩坑记录"},{"content":"双系统用了一段时间后，开机黑洞洞的grub界面自然看着不爽 （虽然只有几秒）,于是想着去美化一下，其中遇到了点小坑，记录一下。使用的机器装了Windows11和Fedora35。\n下载主题\r首先下载好你想要的主题文件，我选择的是这个MacOS风格的MacOS Monterey inspired grub theme\n修改/etc/default/grub文件\r首先，注释掉GRUB_TERMINAL_OUTPUT=”console”,接着设置好你的GRUB主题路径。\n1 2 #GRUB_TERMINAL_OUTPUT=”console” GRUB_THEME=\u0026#34;/boot/grub2/montery-grub-theme/theme.txt\u0026#34; 此外这个文件里还有几个常用的设置 GRUB_TIMEOUT=5 可以设置超时时间，设置-1可以取消倒计时 GRUB_DEFAULT=saved saved：光标会默认选择上一个成功进入的启动项，也可以填入数字，以指定启动列表中第x项为启动项，x从0开始计数\n更新Grub2配置\r如果跟我一样使用GPT分区，以UEFI启动方式的话，启动时读取的位置是/boot/efi/EFI/fedora/grub.cfg ，更新命令如下：\n1 sudo grub2-mkconfig -o /boot/efi/EFI/fedora/grub.cfg 而如果是启动方式是Legacy的话，启动时读取的文件是/boot/grub2/grub.cfg，更新命令如下：\n1 sudo grub2-mkconfig -o /boot/grub2/grub.cfg 接着reboot即可看到效果。\n","date":"2021-12-29T18:56:18+08:00","image":"https://bestoko.cc/p/fedora-grub2-theme/grub2_hu_f7c7b8b609f7bcfe.jpg","permalink":"https://bestoko.cc/p/fedora-grub2-theme/","title":"Grub2主题美化踩坑记录"},{"content":"在 Arch Linux 上使用 Virtual Box 制作虚拟机，打开时却出了问题。\n报错信息\rKernel driver not installed (rc=-1908)\nVirtualBox Linux 内核驱动程序未加载或未正确设置。\n解决办法\r执行如下命令，重新安装vboxdrv模块\n1 sudo modprobe vboxdrv 如果不起作用，检查下是否在BIOS/UEFI设置中禁用安全启动（Secure Boot），因为安全启动会阻止加载未签名的模块。\n","date":"2021-12-28T11:21:20+08:00","image":"https://bestoko.cc/p/linux-virtualbox-error/virtualbox-oracle_hu_d3020e592fa2c5b7.jpg","permalink":"https://bestoko.cc/p/linux-virtualbox-error/","title":"Linux上VirtualBox启动时sbin/vboxconfig错误的解决办法"},{"content":"给常用的电脑加了块固态装了Arch linux，结果在切换双系统时出现两个系统时间不一致的现象，是我之前在Surface上单系统所没遇到的。\n为什么时间不一致\r这是因为BIOS硬件时间本身并没有时区概念，但Windows和Linux对Bios硬件时间与时区关系的理解不一样。Linux将BIOS硬件时间视为协调世界时（UTC），即不存在本地时区；而Windows则将BIOS硬件时间视为当地时间，带上了设置后的时区。Windows这样做，一是早期为了兼容MS-DOS/Windows 3.x，二是为了照顾大众，防止用户问为什么BIOS显示的时间和实际不一致。\n中国大陆、中国香港、中国澳门、中国台湾、蒙古国、新加坡、马来西亚、菲律宾、西澳大利亚州的时间与UTC的时差均为+8，也就是UTC+8。\n推荐的解决办法\rWindows 其实也能处理 UTC，需要修改注册表。建议让 Windows 使用 UTC，而非让 Linux 使用地方时。Windows 使用 UTC 后，请记得禁用 Windows 的时间同步功能，以防 Windows 错误设置硬件时间。\nLinux 可以使用NTP服务来在线同步硬件时钟。\n使用 regedit,新建如下 DWORD 值，并将其值设为十六进制的 1。\n1 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation\\RealTimeIsUniversal 也可以用管理员权限启动命令行来完成：\n1 reg add \u0026#34;HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\TimeZoneInformation\u0026#34; /v RealTimeIsUniversal /d 1 /t REG_DWORD /f 如果以上操作不起作用，并且你使用的是 Windows 64位系统，将 DWORD 修改为 QWORD。\n参考：https://wiki.archlinux.org/index.php/System_time#UTC_in_Windows\n","date":"2021-12-27T21:14:01+08:00","image":"https://bestoko.cc/p/linux-windows-time-conflict/linux-windows-time-conflict_hu_8827a2ca50feaab0.png","permalink":"https://bestoko.cc/p/linux-windows-time-conflict/","title":"Linux与Windows双系统时间不一致的解决方法"},{"content":"写在前面\r之前我已经在Surface Pro 上安装了Arch Linux，可是由简入奢易，由奢入艰难，习惯了的二合一设备突然不能正常触屏还是有些不爽（之前买的surface pen也成了摆设），于是我在github上找到了第三方内核。由于是第三方内核，各设备各硬件的适配情况并不完善，具体可以查看这里。\n安装驱动\r导入密钥\r首先我们需要导入用于签名软件包的密钥：\n1 2 $ curl -s https://raw.githubusercontent.com/linux-surface/linux-surface/master/pkg/keys/surface.asc \\ | sudo pacman-key --add - 检查完整性并本地签名\r1 2 $ sudo pacman-key --finger 56C464BAAC421453 $ sudo pacman-key --lsign-key 56C464BAAC421453 添加存储库\r我们需要在/etc/pacman.conf添加如下内容\n1 2 [linux-surface] Server = https://pkg.surfacelinux.com/arch/ 更新存储库数据，安装内核，启用服务\r我们需要更新存储库数据，以安装linux-surface内核及其依赖项，接着启用iptsd服务以使用触摸屏。\n1 2 3 $ sudo pacman -Syu $ sudo pacman -S linux-surface linux-surface-headers iptsd $ sudo systemctl enable iptsd 重启以后就完工了，屏幕触摸也支持了。\n","date":"2021-12-16T01:48:01+08:00","image":"https://bestoko.cc/p/surface-linux/surface_hu_b9d4c22978b6deaa.jpg","permalink":"https://bestoko.cc/p/surface-linux/","title":"Surface设备在Arch Linux下驱动问题的解决方案"},{"content":"写在前面\r在安装了基本的ArchLinux后，我们还需要一些配置、安装一些组件，来扩展系统功能，使其更符合我们日常使用习惯。\n配置网络\r我们使用\n1 nmtui 选择Edit a connection，\n选择Add菜单，选择WI-FI，\nDevice 里输入 无线网卡的名字，SSID里输入WI-FI的名字，Security选择WPA \u0026amp;WPA2 Personal，OK-BACK-Quit退出。\n注：使用以下命令查看无线网卡名称\n1 ip link show 重命名主机\r1 vim /etc/hostname 保存想要的名字后退出。\n接下来把主机名、域名以及ip地址进行映射\n1 vim /etc/hosts 输入：(以下archlinux为上文所保存的主机名)\n1 2 3 127.0.0.1\tlocalhost ::1\tlocalhost 127.0.0.1 archlinux.localdomain\tarchlinux 设置系统时间\r1 2 timedatectl set-timezone Asia/shanghai timedatectl set-ntp true 第二行设置为让本机时间与ntp同步。\n配置环境变量\r1 vim /etc/skel/.bashrc 添加以下内容\n1 2 3 4 5 6 7 8 export EDITOR=vim alias grep=\u0026#39;grep ==color=auto\u0026#39; alias egrep=\u0026#39;egrep ==color=auto\u0026#39; alias fgrep=\u0026#39;fgrep ==color=auto\u0026#39; [ ！ -e ~/.dircolors ] \u0026amp;\u0026amp; eval $(dircolors -p \u0026gt; ~/.dircolors) [ ！ -e /bin/dircolors ] \u0026amp;\u0026amp; eval $(dircolors -b \u0026gt; ~/.dircolors) 将bash shell 默认的文本编辑器设置为vim\n为grep，egrep，fgrep搜索出的内容添加颜色\n为看到的文件以及文件夹添加颜色\n1 cp -a . ~ 新建标准用户\r1 2 3 useradd --create-home username passwd username usermod -aG wheel,users,storage,power,lp,adm,optical username 其中username替换为你所使用的名字，在创建时同时在/home目录下会创建一个与用户名同名的文件夹。家目录有一个别名是~，你可以在任何地方使用~来代替家目录路径。\n配置sudo\r1 visudo 将# %wheel ALL=(ALL) ALL 前的#号去除（去注释），保存退出。\n中英字体和图形界面的安装\r安装Xorg\rXorg是Linux下的一个著名的开源图形服务，我们的桌面环境需要Xorg的支持。\n1 pacman -S xorg 显卡驱动的安装\r参照如上表格安装相应的包，以Surface Pro 为例，需要安装intel的集成显卡驱动\n1 pacman -S xf86-video-intel 安装字体\r1 vim /etc/locales.gen 将en_US.UTF-8 UTF8 zh_CN.UTF-8 UTF8前的#删除（去注释），保存退出。\n1 vim /etc/locale.conf 输入\n1 LANG=en_US.UTF-8 如果想生成中文，就改成LANG=zh_TW.UTF-8\n接着生成字体\n1 locale-gen 接下来安装英文字体\n1 pacman -S ttf-dejavu ttf-droid ttf-hack ttf-font-awesome otf-font-awesome ttf-lato ttf-liberation ttf-linux-libertine ttf-opensans ttf-roboto ttf-ubuntu-font-family 再然后是安装中文字体\n1 pacman -S ttf-hanom noto-fonts noto-fonts noto-fonts-extra not-fonts-emoji noto-fonts-cjk adobe-source-code-pro-fonts adobe-source-sans-fonts adobe-source-serif-fonts adobe-source-han-sans-cn-fonts adobe-source-han-sans-hk-fonts adobe-source-han-sans-tw-fonts adobe-source-han-serif-cn-fonts wqy-zenhei wqy-microhei 打开freetype2字体引擎\n1 vim /etc/profile.d/freetype2.sh 将最后一行去注释后保存退出。\n安装桌面环境\rLinux下有很多桌面环境如Xfce、KDE(Plasma)、Gnome、Unity、Deepin等等，它们的外观、操作、设计理念等各方面都有所不同，这里我们选择Gnome为例，进行安装。\n1 pacman -S gnome gnome-extra gdm 安装好了桌面环境包以后，我们需要安装一个图形化的桌面管理器来帮助我们登录并且选择我们使用的桌面环境，这里我使用上面的gdm\n1 systemctl enable gdm.service 安装声音以及打印机系统\r1 pacman -S alsa-utils pulseaudio pulseaudio-bluetooth cups 清楚安装缓存以及无用源\r1 pacman -Scc 接着重启即可进入Gnome桌面\n小结\r至此，ArchLinux基本安装与必要设置和图形界面都已经安装完毕。\n","date":"2021-12-15T09:00:01+08:00","image":"https://bestoko.cc/p/archinstallextra/ArchLinux_hu_3be57f10dd1b69c1.jpg","permalink":"https://bestoko.cc/p/archinstallextra/","title":"Arch Linux安装备忘录（二）"},{"content":"写在前面\r安装Arch最好最全面的教程就是官方的 Installation guide。但是Wiki上的介绍更偏向文档，而不是新手习惯的那种按步骤编排的教程，加上中文Wiki的翻译往往落后于英文版，缺乏预备Linux知识的新手经常无从下手。\n笔者也是初学者，本篇文章仅作为自己在Surface Pro 2017从0开始安装配置Arch的记录。\n安装准备\r磁盘准备\r我们需要准备一块有空闲区域（没有被分区）的磁盘留给系统的安装。笔者只准备安装Arch单系统，因此在PE里用磁盘管理工具把Surface的磁盘0各个分区全部删除。你也可以在Windows下找到磁盘管理，自行划分一个区域留给安装使用。\n安装介质\rhttps://www.archlinux.org/download/ 建议从下面的中国镜像下载iso文件\nhttps://rufus.ie/ 我们用Rufus来制作引导盘，此步需要用到一个空闲U盘。需要注意的是写入方式选择DD，分区类型选择GPT而非默认的MBR。\n设置启动顺序\r接下来需要进入个人电脑的BIOS里把制作的U盘启动设置为第一位，笔者的Surface额外需要先关闭security boot，不同电脑进入BIOS的按键略有不同，Surface是开机键和音量+键，其他型号电脑请查阅搜索引擎。\n安装过程\r正确设置好启动顺序后，启动时会看到ArchLinux的界面，按Enter键选择 Boot Arch Linux ，等待加载完成后会进入一个有命令提示符的界面。我们接下来将在这个界面执行一系列命令来讲Arch安装到之前准备的磁盘上。\n*网络连接\rArch的安装需要联网，如果你使用的是有线连接，可以跳过此部分，笔者这里使用无线连接继续安装。\n输入\n1 iwctl 进入iwd模式，输入\n1 device list 查看你的网卡名字，这里假设是wlan0，输入\n1 station wlan0 scan 检查扫描网络，输入\n1 station wlan0 get-networks 查看网络名字，假设名字叫XXX，输入\n1 station wlan0 connect XXX 接着输入密码（如果有密码的话），输入\n1 exit 退出iwd模式\n我们可以用ping命令来检验下是否连接成功\n1 ping -c 4 baidu.com 接下来我们需要让安装介质里的数据库保持与官方一致的最新版本，因此需要同步一下，在此之前，我们可以配置下最新的镜像来保证下载速度。\n1 reflector --country China --age 24 --sort rate --portocol https --save /etc/pacman.d/mirrorlist country 限定国家 age 24 限定下更新时间为24小时内的源 portocol https 选择https协议更安全 执行完毕后，可以用vim查看\n1 vim /etc/pacman.d/mirrorlist 磁盘分区\r检查磁盘\n1 lsblk 用gdisk命令进行分区\n1 gdisk /dev/nvme0n1 其中nvme01 为你之前准备的磁盘。\n一路默认回车到Last sector 部分，因为我们准备用作启动分区，准备分配512M，所以输入+512M回车，接着输入分区编号ef00。这样第一个分区完成，接着第二个分区笔者分配了+235G，并使用默认的分区编号8300（Linux filesystem），最后剩下2G左右空间一路默认，分区编号输入8200（Linux swap）。确认无误后，w保存quit退出。\n接着格式化我们的三个分区，将nvme01p1格式化为vfat\n1 mkfs.vfat /dev/nvme01p1 将nvme01p2格式化为ext4或者xfs（推荐）\n1 mkfs.xfs /dev/nvme01p2 最后\n1 mkswap /dev/nvme01p3 挂载分区\r1 mount /dev/nvme01p2 /mnt 1 mkdir -p /mnt/boot/efi 1 mount /dev/nvme01p1 /mnt/boot/efi 1 swapon /dev/nvme01p3 安装基本包\r1 pacstrap /mnt base base-devel linux linux-firmware linux-headers vim bash-completion 配置Fstab\r1 genfstab -U /mnt \u0026gt;\u0026gt; /mnt/etc/fstab 1 cat /mnt/etc/fstab 确认下是否挂载无误\nchroot\rChroot意为Change root，相当于把操纵权交给我们新安装（或已经存在）的Linux系统，执行了这步以后，我们的操作都相当于在磁盘上新装的系统中进行。\n1 arch-chroot /mnt 安装必须软件包\r现在我们已经Chroot到了新的系统中，只有一些最基本的包（组件），这时候我们就需要自己安装新的包。ArchLinux有非常强大的包管理工具pacman，大部分情况下，一行命令就可以搞定包与依赖的问题。\n安装包的命令格式为pacman -S 包名，pacman会自动检查这个包所需要的其他包（即为依赖）并一起装上。下面我们就通过pacman来安装一些包，这些包在之后会用上，在这里先提前装好。\n执行如下命令（注意大小写，大小写错误会导致包无法找到）：\n1 pacman -S grub efibootmgr efivar networkmanager intel-ucode AMD用户请将intel-ucode替换成amd-ucode\n安装Bootloader\r部署grub\n1 grub-install /dev/nvme01 修改配置\n1 vim /etc/default/grub 将GRUB_TIMEOUT=5改成GRUB_TIMEOUT=2\n将GRUB_CMDLINE_LINUX_DEFAULT=\u0026quot;loglevel=3 quiet\u0026quot; 的quiet字段删除，这样登录的时候会有日志，如果出现错误可以查看日志文件。\n接着将GRUB_GFXMODE=auto修改为你的分辨率，以我的surface为例，改为GRUB_GFXMODE=2736x1824\n接着生成grub的配置文件\n1 grub-mkconfig -o /boot/grub/grub.cfg 设置NetworkManager开机自动启动\r1 systemctl enable NetworkManager 为root用户设置密码\r1 passwd 卸载分区 拔除介质\r1 2 umount /mnt/boot/efi umount /mnt 拔除介质重新启动\n1 reboot 小结\r至此，我们成功安装了ArchLinux，然而此时系统处于非常精简的状态，距离日常使用还需要一些配置，安装一些需要的组件，下一部分我们将安装图形界面、配置显卡驱动、安装桌面环境\u0026hellip;.以及一些实用软件包。\n","date":"2021-12-14T09:00:01+08:00","image":"https://bestoko.cc/p/archinstall/ArchLinux_hu_3be57f10dd1b69c1.jpg","permalink":"https://bestoko.cc/p/archinstall/","title":"Arch Linux安装备忘录（一）"},{"content":"准备工作\r解锁Bootloader且打开USB调试的一加8\n氢OS Android11 Rom包\nPayload Dumber\nplatform-tools\n打包下载： pan.baidu.com/s/1afSr1snXan4LoBLX9l0Urg 【pcge】\n刷入Magisk\r制作magisk_patched.img\r将官方包内的payload.bin 解压并放入Payload Dumber 的payload_input目录\n打开payload_dumper.exe（看到boot解压出来就可以关闭了）\n打开payload_output目录，将解压出的boot.img复制到手机根目录\n下载并安装Magisk最新版本 (https://github.com/topjohnwu/Magisk/releases)\n选择安装Magisk-选择并修补一个文件，选中放在根目录的boot.img ，等待修补完成\n将手机download目录下的修补完成的magisk_patched.img复制到电脑\n工具刷入mgisk_patched.img\r将mgisk_patched.img放入 platform-tools 目录下\n运行\n1 打开CMD命令行.bat adb reboot bootloader fastboot flash boot_a magisk_patched.img fastboot flash boot_b magisk_patched.img fastboot reboot 刷入EdXposed\r刷入Riru - Core模块 刷入Riru - EdXposed(YAHFA) 或Riru - EdXposed(SandHook)模块 安装最新的Edxposed Manager 总结与注意事项\r制作mgisk_patched.img时要用最新的 v8.0.x版本，不能使用以往的v21.0版本\n刷写mgisk_patched.img时 a/b分区都要\n如果因刷入不兼容的模块导致无法开机，可以尝试\n卸载全部magisk模块\nadb shell magisk --remove-modules adb reboot ","date":"2020-10-28T09:00:01+08:00","image":"https://bestoko.cc/p/oneplus8/onepluslogo_hu_ee3a2ee97fe12241.jpg","permalink":"https://bestoko.cc/p/oneplus8/","title":"一加8的Android 11 折腾指南"},{"content":"前情提要\r为什么要水这么一篇文章\n在把switch借给朋友玩的这段时间，我把目光投向了吃灰已久的3ds\u0026hellip;.\n我想要在实机上游玩gba游戏，但是3ds上的模拟器又有各种各样的兼容性问题，达不到eshop里VC金银流畅的游玩体验；宣称能游玩GBA的DSTWO PLUS烧录卡早已停产，某宝/闲鱼的价格居高不下\u0026hellip;经过一番摸索，我找到了可能是现今最好的解决方案。\n准备工作\r一台BOOT9STARP(B9S)破解的3ds\n参考3ds破解手册或者一只火狐大佬整理的教程(推荐)\n嫌麻烦的同学可以交给热心摊主处理\nUltimate GBA VC Injector for 3DS\n汉化版下载链接\n你想要在3ds上运行的GBA游戏ROM文件\n这里以漆黑的魅影为例（很棒的GBA宝可梦改版，我一直想在实机上玩）\nGBA 转CIA\r打开软件并导入下载好的.gba文件，ROM大小和存档类型会自动确认(汉化版ROM往往是数据库未找到该游戏，请确保选择的正确无误以免影响存档) 填写要转换的VC图标和名称(因为3ds字库的原因建议不要使用中文XD)，设置3D横幅(就是选中这个游戏时3ds上屏的画面)\n设置VC参数并导出CIA文件(注意当转换多个.cia文件时，确保每个文件的产品代码及项目ID都不一样)\n在3ds上安装转换好的.cia文件\n关于如何B9S如何安装cia文件这里不再赘述(实在懒得截图了)\n大功告成~\n备注事项\r据说部分老款3ds对这种方式转换的.cia支持不好，会出现黑屏情况(我的美版老小三反正测试是没问题啦) 港版不支持港版不支持港版不支持 存档类型一定要设置正确 ","date":"2020-03-30T09:00:01+08:00","image":"https://bestoko.cc/p/gba2cia/3ds_hu_aec8d595fd02055d.jpg","permalink":"https://bestoko.cc/p/gba2cia/","title":"GBA文件转CIA文件，在3ds上游玩GBA游戏的解决方案"},{"content":" Git 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。\nGit 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。\nGit 与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持。\n常用指令\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 $ git init # 在当前目录新建一个 Git 代码库 $ git clone [url] # 下载一个项目和它的整个代码历史 $ git config --list # 显示当前的 Git 配置 $ git config -e [--global] # 编辑 Git 配置文件 $ git add # 添加指定文件到暂存区 $ git rm # 删除工作区文件，并且将这次删除放入暂存区 $ git commit -m [message] # 提交暂存区到仓库区 $ git commit -a # 提交工作区自上次 commit 之后的变化，直接到仓库区 $ git commit --amend -m [message] # 使用一次新的 commit，替代上一次提交 如果代码没有任何新变化，则用来改写上一次 commit 的提交信息 $ git commit --amend [file1] [file2] ... # 重做上一次 commit，并包括指定文件的新变化 # 分支相关 $ git branch # 列出所有本地分支 $ git branch -r # 列出所有远程分支 $ git branch [branch-name] # 新建一个分支，但依然停留在当前分支 $ git checkout [branch-name] # 切换到指定分支，并更新工作区 $ git checkout -b [branch] # 新建一个分支，并切换到该分支 $ git branch [branch] [commit] # 新建一个分支，指向指定 commit $ git checkout -b [branch] [tag] # 新建一个分支，指向某个 tag $ git branch --track [branch] [remote-branch] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --set-upstream [branch] [remote-branch] # 建立追踪关系，在现有分支与指定的远程分支之间 $ git merge [branch] # 合并指定分支到当前分支 $ git cherry-pick [commit] # 选择一个 commit，合并进当前分支 $ git branch -d [branch-name] # 删除分支 $ git push origin --delete [branch-name] # 删除远程分支 $ git branch -dr [remote/branch] # 删除远程分支 # 标签 $ git tag # 列出所有 tag $ git tag [tag] # 新建一个 tag 在当前 commit $ git tag [tag] [commit] # 新建一个 tag 在指定 commit $ git show [tag] # 查看 tag 信息 $ git push [remote] [tag] # 提交指定 tag $ git push [remote] --tags # 提交所有 tag # 查看 $ git status # 显示有变更的文件 $ git log # 显示当前分支的版本历史 $ git log --stat # 显示 commit 历史，以及每次 commit 发生变更的文件 $ git log --follow [file] # 显示某个文件的版本历史，包括文件改名 $ git log -p [file] # 显示指定文件相关的每一次 diff $ git blame [file] # 显示指定文件是什么人在什么时间修改过 $ git diff # 显示暂存区和工作区的差异 $ git diff --cached [file] # 显示暂存区和上一个 commit 的差异 $ git diff HEAD # 显示工作区与当前分支最新 commit 之间的差异 $ git diff [first-branch]...[second-branch] # 显示两次提交之间的差异 $ git show [commit] # 显示某次提交的元数据和内容变化 $ git show --name-only [commit] # 显示某次提交发生变化的文件 $ git show [commit]:[filename] # 显示某次提交时，某个文件的内容 $ git reflog # 显示当前分支的最近几次提交 # 远程 $ git fetch [remote] # 下载远程仓库的所有变动 $ git remote -v # 显示所有远程仓库 $ git remote show [remote] # 显示某个远程仓库的信息 $ git remote add [shortname] [url] # 增加一个新的远程仓库，并命名 $ git pull [remote] [branch] # 取回远程仓库的变化，并与本地分支合并 $ git push [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] --force # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --all # 推送所有分支到远程仓库 # 撤销 $ git checkout [file] # 恢复暂存区的指定文件到工作区 $ git checkout [commit] [file] # 恢复某个 commit 的指定文件到工作区 $ git checkout . # 恢复上一个 commit 的所有文件到工作区 $ git reset [file] # 重置暂存区的指定文件，与上一次 commit 保持一致，但工作区不变 $ git reset --hard # 重置暂存区与工作区，与上一次 commit 保持一致 $ git reset [commit] # 重置当前分支的指针为指定 commit，同时重置暂存区，但工作区不变 $ git reset --hard [commit] # 重置当前分支的 HEAD 为指定 commit，同时重置暂存区和工作区，与指定 commit 一致 $ git reset --keep [commit] # 重置当前 HEAD 为指定 commit，但保持暂存区和工作区不变 $ git revert [commit] # 新建一个 commit，用来撤销指定 commit，后者的所有变化都将被前者抵消，并且应用到当前分支 学习资源\rgit - 简明指南 pro git（中文版） Git 教程 Git 参考手册 Git 指南 Learn Git Branching ","date":"2020-03-23T09:00:01+08:00","image":"https://bestoko.cc/p/gitnotes/git_logo_hu_dd05a4ea6938ea0c.jpg","permalink":"https://bestoko.cc/p/gitnotes/","title":"Git学习笔记"},{"content":" Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。\n以下是Markdown的基础语法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 ~~删除线~~ *斜体* _斜体第二种方法_ **加粗** __加粗的第二种方法__ ___粗斜体___ 两个enter是换行，或者用\u0026lt;/br\u0026gt;标签表示换行 用一行的=或者-表示一级标题和二级标题。如： 一级标题 ======= 二级标题 -------- 也可以在前面加上一到六个#表示标题的1级到6级，标题前加一个空格。如： # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 无序列表：在前面加上 * 或者 + 或者 - 然后加个空格： * ABC * DEF * GHI + JKL + MNO + PQR - STU - VWX - YZZ 有序列表：数字+英文句点+空格。如下： 1. 呵呵 2. 哈哈 3. 嘿嘿 4. 哼哼 \u0026amp;lt; // 会显示为”\u0026lt;“ \u0026amp;amp; // 会显示为”\u0026amp;“：在 href 属性里面，必须将 \u0026amp; 转变为 \u0026amp;amp; \\. // 为了防止产生\u0026#34;1.\u0026#34;变为有序列表，则可以写成\u0026#34;1\\.\u0026#34; * _ // 如果 * 和 _ 两边都有空白的话，它们就只会被当成普通的符号。 \u0026gt;只在整个段落的第一行最前面加上大于号可以显示引用（此时出现引用形式，并且为斜体）。但是引言内如果要断行，那个空行也必须在前面加上大于号。就像下面写的酱紫： \u0026gt;\u0026gt;区块引言也可以有级别，在前面加上不同数量的大于号即可。比如说这就是一个二级引言。 \u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt;这是一个三级引言。格式会显示为字体更小了。 建立分割线的方法有： * * * ***** - - - ------------------- 超级链接：[超级链接显示的文字](超级链接的网址，可以是绝对路径、相对路径) 也支持HTML格式的超级链接\u0026lt;a href=\u0026#34;https://www.baidu.com/\u0026#34;\u0026gt;百度\u0026lt;/a\u0026gt; 如果要标记一小段行内程序代码，可以用反引号把它包起来，像这样： Use the `printf()` function. 插入图片：![图片的替换文字](图片的地址或路径) ![风景区图片](/Snip20160202_227.png) Email邮件： \u0026lt;123456789@qq.com\u0026gt; 锚点：(能够链接到某个一级标题) [想要显示的名称](#锚点的名称) ","date":"2020-03-12T09:00:01+08:00","image":"https://bestoko.cc/p/markdwonnotes/markdown_hu_2ef534b3af681939.jpg","permalink":"https://bestoko.cc/p/markdwonnotes/","title":"Markdown学习笔记"}]